<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Quarto CRC Book - 1&nbsp; BUSINESS UNDERSTANDING</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./PSD_Mubessirul Ummah_210411100140_Water Quality.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">**<center>Proyek Sains Data: Water Quality</center>**</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Quarto CRC Book</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PSD_Mubessirul Ummah_210411100140_Water Quality.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">**</span> <span class="hidden" data-render-id="quarto-int-sidebar:/summary.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Summary</span></span> <span class="hidden" data-render-id="quarto-int-sidebar:/references.html">References</span> <span class="hidden" data-render-id="quarto-breadcrumbs-bfe8cf65ae918c1a8eae62db62e8c487"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">**</span></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#determine-business-objectives-menentukan-tujuan-bisnis" id="toc-determine-business-objectives-menentukan-tujuan-bisnis" class="nav-link active" data-scroll-target="#determine-business-objectives-menentukan-tujuan-bisnis"><span class="header-section-number">1.1</span> Determine Business Objectives (Menentukan Tujuan Bisnis)</a></li>
  <li><a href="#access-situation-menilai-situasi" id="toc-access-situation-menilai-situasi" class="nav-link" data-scroll-target="#access-situation-menilai-situasi"><span class="header-section-number">1.2</span> Access Situation (Menilai Situasi)</a></li>
  <li><a href="#determine-data-mining-goals-menentukan-tujuan-data-mining" id="toc-determine-data-mining-goals-menentukan-tujuan-data-mining" class="nav-link" data-scroll-target="#determine-data-mining-goals-menentukan-tujuan-data-mining"><span class="header-section-number">1.3</span> Determine Data Mining Goals (Menentukan Tujuan Data Mining)</a></li>
  <li><a href="#produce-project-plan-menghasilkan-rencana-proyek" id="toc-produce-project-plan-menghasilkan-rencana-proyek" class="nav-link" data-scroll-target="#produce-project-plan-menghasilkan-rencana-proyek"><span class="header-section-number">1.4</span> Produce Project Plan (Menghasilkan Rencana Proyek)</a></li>
  <li><a href="#data-understanding" id="toc-data-understanding" class="nav-link" data-scroll-target="#data-understanding"><span class="header-section-number">2</span> DATA UNDERSTANDING</a>
  <ul class="collapse">
  <li><a href="#deskripsi-dataset" id="toc-deskripsi-dataset" class="nav-link" data-scroll-target="#deskripsi-dataset"><span class="header-section-number">2.1</span> Deskripsi Dataset</a></li>
  <li><a href="#deskripsi-fitur-dataset" id="toc-deskripsi-fitur-dataset" class="nav-link" data-scroll-target="#deskripsi-fitur-dataset"><span class="header-section-number">2.2</span> Deskripsi Fitur Dataset</a></li>
  <li><a href="#deskripsi-tipe-data-fitur" id="toc-deskripsi-tipe-data-fitur" class="nav-link" data-scroll-target="#deskripsi-tipe-data-fitur"><span class="header-section-number">2.3</span> Deskripsi Tipe Data Fitur</a></li>
  <li><a href="#identifikasi-missing-value" id="toc-identifikasi-missing-value" class="nav-link" data-scroll-target="#identifikasi-missing-value"><span class="header-section-number">2.4</span> Identifikasi Missing Value</a></li>
  <li><a href="#identifikasi-data-duplicated" id="toc-identifikasi-data-duplicated" class="nav-link" data-scroll-target="#identifikasi-data-duplicated"><span class="header-section-number">2.5</span> Identifikasi Data Duplicated</a></li>
  <li><a href="#identifikasi-sebaran-kelas-data" id="toc-identifikasi-sebaran-kelas-data" class="nav-link" data-scroll-target="#identifikasi-sebaran-kelas-data"><span class="header-section-number">2.6</span> Identifikasi Sebaran Kelas Data</a></li>
  <li><a href="#identifikasi-outlier" id="toc-identifikasi-outlier" class="nav-link" data-scroll-target="#identifikasi-outlier"><span class="header-section-number">2.7</span> Identifikasi Outlier</a></li>
  <li><a href="#eksplorasi-data" id="toc-eksplorasi-data" class="nav-link" data-scroll-target="#eksplorasi-data"><span class="header-section-number">2.8</span> Eksplorasi Data</a></li>
  </ul></li>
  <li><a href="#pre-procesing" id="toc-pre-procesing" class="nav-link" data-scroll-target="#pre-procesing"><span class="header-section-number">3</span> 3. Pre-Procesing</a>
  <ul class="collapse">
  <li><a href="#handling-missing-data" id="toc-handling-missing-data" class="nav-link" data-scroll-target="#handling-missing-data"><span class="header-section-number">3.1</span> Handling Missing Data</a></li>
  <li><a href="#data-cleaning" id="toc-data-cleaning" class="nav-link" data-scroll-target="#data-cleaning"><span class="header-section-number">3.2</span> Data Cleaning</a></li>
  <li><a href="#handling-imbalanced-data" id="toc-handling-imbalanced-data" class="nav-link" data-scroll-target="#handling-imbalanced-data"><span class="header-section-number">3.3</span> Handling Imbalanced Data</a>
  <ul class="collapse">
  <li><a href="#perbandingan-kelas-data-awal" id="toc-perbandingan-kelas-data-awal" class="nav-link" data-scroll-target="#perbandingan-kelas-data-awal"><span class="header-section-number">3.3.1</span> Perbandingan kelas data awal</a></li>
  <li><a href="#proses-balancing-data" id="toc-proses-balancing-data" class="nav-link" data-scroll-target="#proses-balancing-data"><span class="header-section-number">3.3.2</span> Proses Balancing Data</a></li>
  </ul></li>
  <li><a href="#feature-scaling" id="toc-feature-scaling" class="nav-link" data-scroll-target="#feature-scaling"><span class="header-section-number">3.4</span> Feature Scaling</a></li>
  <li><a href="#splitting-data" id="toc-splitting-data" class="nav-link" data-scroll-target="#splitting-data"><span class="header-section-number">3.5</span> Splitting Data</a></li>
  <li><a href="#pycaret-seleksi-model" id="toc-pycaret-seleksi-model" class="nav-link" data-scroll-target="#pycaret-seleksi-model"><span class="header-section-number">3.6</span> Pycaret Seleksi Model</a>
  <ul class="collapse">
  <li><a href="#light-gradient-boosting-machine" id="toc-light-gradient-boosting-machine" class="nav-link" data-scroll-target="#light-gradient-boosting-machine"><span class="header-section-number">3.6.1</span> Light Gradient Boosting Machine</a></li>
  <li><a href="#gradient-boosting-classifier" id="toc-gradient-boosting-classifier" class="nav-link" data-scroll-target="#gradient-boosting-classifier"><span class="header-section-number">3.6.2</span> Gradient Boosting Classifier</a></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest"><span class="header-section-number">3.6.3</span> Random Forest</a></li>
  <li><a href="#decision-tree-clasifier" id="toc-decision-tree-clasifier" class="nav-link" data-scroll-target="#decision-tree-clasifier"><span class="header-section-number">3.6.4</span> Decision Tree Clasifier</a></li>
  <li><a href="#ada-boost-classifier" id="toc-ada-boost-classifier" class="nav-link" data-scroll-target="#ada-boost-classifier"><span class="header-section-number">3.6.5</span> Ada Boost Classifier</a></li>
  </ul></li>
  <li><a href="#feature-selection" id="toc-feature-selection" class="nav-link" data-scroll-target="#feature-selection"><span class="header-section-number">3.7</span> Feature Selection</a>
  <ul class="collapse">
  <li><a href="#pencarian-fitur-terbaik-light-gradient-boosting-machine" id="toc-pencarian-fitur-terbaik-light-gradient-boosting-machine" class="nav-link" data-scroll-target="#pencarian-fitur-terbaik-light-gradient-boosting-machine"><span class="header-section-number">3.7.1</span> Pencarian Fitur Terbaik Light Gradient Boosting Machine</a></li>
  <li><a href="#pencarian-fitur-terbaik-gradient-boosting-classifier" id="toc-pencarian-fitur-terbaik-gradient-boosting-classifier" class="nav-link" data-scroll-target="#pencarian-fitur-terbaik-gradient-boosting-classifier"><span class="header-section-number">3.7.2</span> Pencarian Fitur Terbaik Gradient Boosting Classifier</a></li>
  <li><a href="#pencarian-fitur-terbaik-random-forest" id="toc-pencarian-fitur-terbaik-random-forest" class="nav-link" data-scroll-target="#pencarian-fitur-terbaik-random-forest"><span class="header-section-number">3.7.3</span> Pencarian Fitur Terbaik Random Forest</a></li>
  <li><a href="#decision-tree-clasifier-1" id="toc-decision-tree-clasifier-1" class="nav-link" data-scroll-target="#decision-tree-clasifier-1"><span class="header-section-number">3.7.4</span> Decision Tree Clasifier</a></li>
  <li><a href="#ada-boost-classifier-1" id="toc-ada-boost-classifier-1" class="nav-link" data-scroll-target="#ada-boost-classifier-1"><span class="header-section-number">3.7.5</span> Ada Boost Classifier</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#modeling" id="toc-modeling" class="nav-link" data-scroll-target="#modeling"><span class="header-section-number">4</span> Modeling</a>
  <ul class="collapse">
  <li><a href="#light-gradient-boosting-machine-1" id="toc-light-gradient-boosting-machine-1" class="nav-link" data-scroll-target="#light-gradient-boosting-machine-1"><span class="header-section-number">4.1</span> Light Gradient Boosting Machine</a></li>
  <li><a href="#gradient-boosting-classifier-1" id="toc-gradient-boosting-classifier-1" class="nav-link" data-scroll-target="#gradient-boosting-classifier-1"><span class="header-section-number">4.2</span> Gradient Boosting Classifier</a></li>
  <li><a href="#random-forest-1" id="toc-random-forest-1" class="nav-link" data-scroll-target="#random-forest-1"><span class="header-section-number">4.3</span> Random Forest</a></li>
  <li><a href="#decision-tree-clasifier-2" id="toc-decision-tree-clasifier-2" class="nav-link" data-scroll-target="#decision-tree-clasifier-2"><span class="header-section-number">4.4</span> Decision Tree Clasifier</a></li>
  <li><a href="#ada-boost-classifier-2" id="toc-ada-boost-classifier-2" class="nav-link" data-scroll-target="#ada-boost-classifier-2"><span class="header-section-number">4.5</span> Ada Boost Classifier</a></li>
  <li><a href="#perbandingan-metode" id="toc-perbandingan-metode" class="nav-link" data-scroll-target="#perbandingan-metode"><span class="header-section-number">4.6</span> Perbandingan Metode</a></li>
  </ul></li>
  <li><a href="#evaluasi" id="toc-evaluasi" class="nav-link" data-scroll-target="#evaluasi"><span class="header-section-number">5</span> Evaluasi</a>
  <ul class="collapse">
  <li><a href="#light-gradient-boosting-machine-2" id="toc-light-gradient-boosting-machine-2" class="nav-link" data-scroll-target="#light-gradient-boosting-machine-2"><span class="header-section-number">5.1</span> Light Gradient Boosting Machine</a></li>
  <li><a href="#gradient-boosting-classifier-2" id="toc-gradient-boosting-classifier-2" class="nav-link" data-scroll-target="#gradient-boosting-classifier-2"><span class="header-section-number">5.2</span> Gradient Boosting Classifier</a></li>
  <li><a href="#random-forest-2" id="toc-random-forest-2" class="nav-link" data-scroll-target="#random-forest-2"><span class="header-section-number">5.3</span> Random Forest</a></li>
  <li><a href="#decision-tree-clasifier-3" id="toc-decision-tree-clasifier-3" class="nav-link" data-scroll-target="#decision-tree-clasifier-3"><span class="header-section-number">5.4</span> Decision Tree Clasifier</a></li>
  <li><a href="#ada-boost-classifier-3" id="toc-ada-boost-classifier-3" class="nav-link" data-scroll-target="#ada-boost-classifier-3"><span class="header-section-number">5.5</span> Ada Boost Classifier</a></li>
  </ul></li>
  <li><a href="#deployment" id="toc-deployment" class="nav-link" data-scroll-target="#deployment"><span class="header-section-number">6</span> Deployment</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">BUSINESS UNDERSTANDING</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

**
<center>
Proyek Sains Data: Water Quality
</center>
<p>**</p>
<hr>

<table>
<tbody><tr>
<td>
Nama
</td>
<td>
:
</td>
<td>
Mubessirul Ummah
</td>
</tr>
<tr>
<td>
NIM
</td>
<td>
:
</td>
<td>
210411100140
</td>
</tr>
<tr>
<td>
Kelas
</td>
<td>
:
</td>
<td>
Proyek Sains Data IF-5B
</td>
</tr>

</tbody></table>
<p><img src="Water-Sampling-scaled.jpg" alt="Logo"></p>
<p>Tahapan business understanding merupakan tahap awal dari sebuah proyek data analytics. Tahapan ini akan dapat menghasilkan perencanaan sebuah proyek data analytics yang jelas tujuannya dan pemahaman menyeluruh tentang proses bisnis, seperti membuat peta rute untuk memastikan rencana yang baik. Berikut Business Understanding dari proyek saya kali ini :</p>
<section id="determine-business-objectives-menentukan-tujuan-bisnis" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="determine-business-objectives-menentukan-tujuan-bisnis"><span class="header-section-number">1.1</span> Determine Business Objectives (Menentukan Tujuan Bisnis)</h2>
<p>Air merupakan salah satu sumber daya alam esensial untuk kelangsungan hidup seluruh makhluk hidup di dunia ini. Kita memerlukan air untuk kebutuhan kita sehari-hari, begitu juga dengan tanaman dan hewan yang memerlukan air untuk kelangsungan hidupnya. Menurut data dari World Health Organization (WHO), diperkirakan sebanyak 1.1 Miliar orang tidak memiliki akses untuk mendapatkan air yang layak minum dan 2.6 Miliar lainnya tidak mendapatkan fasilitas sanitasi yang baik. <i>Pengolahan data ini bertujuan untuk menilai dan mengategorikan kualitas air sebagai “aman” atau “tidak aman” menggunakan teknik klasifikasi</i>. Ini sejalan dengan tujuan lebih besar untuk memastikan air minum yang aman bagi masyarakat. Dalam pengolahan data kali ini akan dilakukan pencarian terhadap metode klasifikasi dan Apa fitur utama yang paling signifikan berkontribusi pada klasifikasi air sebagai aman atau tidak aman?</p>
</section>
<section id="access-situation-menilai-situasi" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="access-situation-menilai-situasi"><span class="header-section-number">1.2</span> Access Situation (Menilai Situasi)</h2>
<p>Setelah memahami dengan lebih spesifik tujuan bisnis terkait penilaian kualitas air, langkah berikutnya adalah melakukan assessment yang mencakup ketersediaan sumber daya, mitigasi risiko, dan terutama ketersediaan data kualitas air. Data mengenai kualitas air dapat bervariasi tergantung pada sumbernya, dan metode analitika data yang akan diterapkan akan sangat dipengaruhi oleh ketersediaan data tersebut. Dalam konteks kualitas air, pertanyaan yang muncul adalah, “Apa fitur utama yang paling signifikan berkontribusi pada klasifikasi air sebagai aman atau tidak aman?” Untuk menjawab pertanyaan ini, metode klasifikasi atau estimasi dapat diterapkan. Misalnya, algoritma machine learning seperti Random Forest atau Logistic Regression dapat digunakan untuk mengidentifikasi faktor-faktor utama yang membedakan air aman dan tidak aman.</p>
</section>
<section id="determine-data-mining-goals-menentukan-tujuan-data-mining" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="determine-data-mining-goals-menentukan-tujuan-data-mining"><span class="header-section-number">1.3</span> Determine Data Mining Goals (Menentukan Tujuan Data Mining)</h2>
<p>Tujuan Data Mining kali ini yakni untuk mengembangkan model klasifikasi yang dapat mengidentifikasi apakah suatu sampel air aman atau tidak aman berdasarkan parameter-parameter tertentu. Air minum yang layak konsumsi harus memenuhi beberapa kriteria, seperti tidak berwarna, tidak berbau, dan tidak mengandung zat berbahaya. Kriteria ini penting untuk diketahui agar terhindar dari masalah kesehatan akibat konsumsi air minum yang tidak layak. dalam menilai suatu air dikategorikan layak atau tidak layak di konsumsi jika berdasarkan kandungan zat yang ada di dalam air, maka berikut ini beberapa ciri atau kandungan air yang mempengaruhi kualitas air: 1. aluminium berbahaya jika lebih besar dari 2,8 2. ammonia berbahaya jika lebih besar dari 32,5 3. arsenic berbahaya jika lebih besar dari 0,01 4. barium berbahaya jika lebih besar dari 2 5. cadmium berbahaya jika lebih besar dari 0,005 6. chloramine berbahaya jika lebih besar dari 4 7. chromium berbahaya jika lebih besar dari 0,1 8. copper berbahaya jika lebih besar dari 1,3 9. flouride berbahaya jika lebih besar dari 1,5 10. bacteria berbahaya jika lebih besar dari 0 11. viruses berbahaya jika lebih besar dari 0 12. lead berbahaya jika lebih besar dari 0,015 13. nitrates berbahaya jika lebih besar dari 10 14. nitrites berbahaya jika lebih besar dari 1 15. mercury erbahaya jika lebih besar dari 0,002 16. perchlorate berbahaya jika lebih besar dari 56 17. radium berbahaya jika lebih besar dari 5 18. selenium berbahaya jika lebih besar dari 0,5 19. silver berbahaya jika lebih besar dari 0,1 20. uranium berbahaya jika lebih besar dari 0,3</p>
<p>Kemudian berdasarkan ciri-ciri di atas, suatu air bisa dikategorikan menjadi kelas 1 (safe atau aman) dan 0 (not safe atau tidak aman).</p>
</section>
<section id="produce-project-plan-menghasilkan-rencana-proyek" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="produce-project-plan-menghasilkan-rencana-proyek"><span class="header-section-number">1.4</span> Produce Project Plan (Menghasilkan Rencana Proyek)</h2>
<p>Langkah-langkah Proyek sebagai berikut : <img src="skema.jpg" alt="Logo"> - Menentukan bussiness understanding - Mengumpulkan dataset kualitas air yang mencakup informasi parameter-parameter yang sesuai. - Melakukan data understanding untuk memahami sebuah data sepert jumlahnya, daftar kolom, tipe data kolom, banayknya kelas, dan mengetahui data tersebut perlu atau tidak untuk dilakukan preprocessing. - Melakukan preprocessing terhadap dataset sebelum diterapkan teknik klasifikasi. - Membagi dataset menjadi set pelatihan (training set) dan set pengujian (testing set). - Menentukan teknik klasifikasi yang paling sesuai untuk proyek ini. - Mengembangkan, melatih, dan mengevaluasi model klasifikasi menggunakan set pelatihan. - Mengukur performa model menggunakan set pengujian. - Melakukan evaluasi terhadap model yang telah dikembangkan. - Mengimplementasikan model dalam aplikasi streamlit untuk mengetahui kualitas air.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> IPython</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_validate</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># from keras.models import Sequential</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># from keras.layers import Dense</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostClassifier</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostClassifier</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> mutual_info_classif</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> RandomOverSampler</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SelectKBest, f_classif</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> joblib</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-understanding" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> DATA UNDERSTANDING</h1>
<p>Data Understanding adalah tahap yang fokus pada eksplorasi dan pemahaman awal terhadap data yang akan digunakan dalam suatu proyek analisis data. Tahap ini merupakan langkah untuk memahami karakteristik, struktur, dan konten atau isi dari data sebelum melakukan analisis lebih lanjut. data understanding dipakai untuk memeriksa data sehingga dapat mengidentifikasi masalah pada data yang kita dapatkan.</p>
<section id="deskripsi-dataset" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="deskripsi-dataset"><span class="header-section-number">2.1</span> Deskripsi Dataset</h2>
<p>Datasest waterquality merupakan kumpulan data yang dibuat dari data imajiner kualitas air di lingkungan perkotaan. Dataset ini mencakup data kadar mikroorganisme yang terkandung di dalam air seperti kadar aluminium, ammonia, arsenic, barium, cadmium, chloramine, chromium, copper, flouride, bacteria, viruses, lead, nitrates, nitrites, mercury, perchlorate, radium, selenium, silver, dan uranium. Data tersebut berisi 21 atribut dan 7999 record, record tersebut diberi label dengan variabel kelas is_safe, yang memungkinkan klasifikasi data menggunakan nilai 1 (safe atau aman) dan 0 (not_safe atau tidak aman) dikonsumsi. data ini saya dapatkan dari Kaggel dengan link berikut : https://www.kaggle.com/datasets/mssmartypants/water-quality/.</p>
<p>dataset tersebut berisi “synthetic water quality data” atau “simulated water quality data” atau dengan kata lain sample dari data yang bersifat fiktif atau imajiner yang dibuat untuk keperluan pendidikan dan latihan.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca data dari file csv</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'waterQuality1.csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7994</td>
<td>0.05</td>
<td>7.78</td>
<td>0.00</td>
<td>1.95</td>
<td>0.040</td>
<td>0.10</td>
<td>0.03</td>
<td>0.03</td>
<td>1.37</td>
<td>0.00</td>
<td>...</td>
<td>0.197</td>
<td>14.29</td>
<td>1.00</td>
<td>0.005</td>
<td>3.57</td>
<td>2.13</td>
<td>0.09</td>
<td>0.06</td>
<td>0.03</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7995</td>
<td>0.05</td>
<td>24.22</td>
<td>0.02</td>
<td>0.59</td>
<td>0.010</td>
<td>0.45</td>
<td>0.02</td>
<td>0.02</td>
<td>1.48</td>
<td>0.00</td>
<td>...</td>
<td>0.031</td>
<td>10.27</td>
<td>1.00</td>
<td>0.001</td>
<td>1.48</td>
<td>1.11</td>
<td>0.09</td>
<td>0.10</td>
<td>0.08</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7996</td>
<td>0.09</td>
<td>6.85</td>
<td>0.00</td>
<td>0.61</td>
<td>0.030</td>
<td>0.05</td>
<td>0.05</td>
<td>0.02</td>
<td>0.91</td>
<td>0.00</td>
<td>...</td>
<td>0.182</td>
<td>15.92</td>
<td>1.00</td>
<td>0.000</td>
<td>1.35</td>
<td>4.84</td>
<td>0.00</td>
<td>0.04</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7997</td>
<td>0.01</td>
<td>10</td>
<td>0.01</td>
<td>2.00</td>
<td>0.000</td>
<td>2.00</td>
<td>0.00</td>
<td>0.09</td>
<td>0.00</td>
<td>0.00</td>
<td>...</td>
<td>0.000</td>
<td>0.00</td>
<td>0.00</td>
<td>0.000</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7998</td>
<td>0.04</td>
<td>6.85</td>
<td>0.01</td>
<td>0.70</td>
<td>0.030</td>
<td>0.05</td>
<td>0.01</td>
<td>0.03</td>
<td>1.00</td>
<td>0.00</td>
<td>...</td>
<td>0.182</td>
<td>15.92</td>
<td>1.00</td>
<td>0.000</td>
<td>1.35</td>
<td>4.84</td>
<td>0.00</td>
<td>0.04</td>
<td>0.05</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>7999 rows × 21 columns</p>
</div>
</div>
</div>
<p>Kode di atas digunakan untuk membuka file csv dan menampilkan visual isi dari dataset.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Banyaknya data : "</span>, df.shape[<span class="dv">0</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Banyaknya kolom : "</span>, df.shape[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Banyaknya data :  7999
Banyaknya kolom :  21</code></pre>
</div>
</div>
<p>fungs shape sendiri digunakan untuk mengetahui dimensi dari dataframe atau ukuran baris dan kolomnya. df.shape[0]: Ini mencetak jumlah baris (data points) dalam DataFrame df. Dalam hal ini, jumlah barisnya adalah 7999. df.shape[1]: Ini mencetak jumlah kolom (fitur atau variabel) dalam DataFrame df. Dalam hal ini, jumlah kolomnya adalah 21. Dengan kata lain, DataFrame Anda memiliki 7999 baris dan 21 kolom.</p>
</section>
<section id="deskripsi-fitur-dataset" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="deskripsi-fitur-dataset"><span class="header-section-number">2.2</span> Deskripsi Fitur Dataset</h2>
<ol type="1">
<li><strong>Aluminium</strong> : Merupakan kandungan aluminium dalam air. berbahaya jika lebih besar dari 2,8. kandungan aluminium yang berlebihan dapat menyebabkan masalah kesehatan, terutama pada sistem saraf.</li>
<li><strong>Ammonia</strong> : Kandungan ammonia (NH3) dalam air. Amonia adalah gas dengan bau yang tajam dan beracun dalam konsentrasi tinggi. berbahaya jika lebih besar dari 32,5. Kandungan ammonia yang tinggi dalam air dapat menyebabkan kerusakan organisme akuatik dan merusak kualitas air minum.</li>
<li><strong>Arsenic</strong> : Kandungan arsenik dalam air. Arsenic adalah unsur kimia dalam tabel periodik dengan simbol As dan nomor atom 33. Arsenic dapat ditemukan secara alami di dalam kerak bumi dan digunakan dalam berbagai aplikasi industri, termasuk pembuatan kayu tahan air. arsenic berbahaya jika lebih besar dari 0,01. Kandungan arsenik yang tinggi dalam air minum dapat menyebabkan keracunan dan meningkatkan risiko kanker.</li>
<li><strong>Barium</strong>: Kandungan barium dalam air. Barium adalah unsur kimia dengan simbol Ba dan nomor atom 56. Barium digunakan dalam industri minyak dan gas, serta dalam radiografi medis. berbahaya jika lebih besar dari 2. Pemaparan jangka panjang terhadap barium dapat menyebabkan kerusakan organ dalam tubuh manusia.</li>
<li><strong>Cadmium</strong> : Kandungan kadmium dalam air. Cadmium adalah unsur kimia dengan simbol Cd dan nomor atom 48. Cadmium digunakan dalam baterai, cat, dan plastik. berbahaya jika lebih besar dari 0,005. Pemaparan cadmium dapat menyebabkan masalah kesehatan serius, termasuk kerusakan ginjal dan kanker.</li>
<li><strong>Chloramine</strong> : Kandungan chloramine dalam air. Chloramine adalah senyawa kimia yang terbentuk dari klorin dan amonia. Ini digunakan sebagai desinfektan dalam air minum. berbahaya jika lebih besar dari 4. Paparan kloramine dalam jumlah yang tinggi dapat menyebabkan iritasi mata dan tenggorokan.</li>
<li><strong>Chromium</strong> : Kandungan kromium dalam air. berbahaya jika lebih besar dari 0,1. Pemaparan kromium VI dapat menyebabkan kerusakan paru-paru, penyakit pernapasan, dan kanker.</li>
<li><strong>Copper</strong> : Kandungan tembaga dalam air. Copper adalah unsur kimia dengan simbol Cu dan nomor atom 29. Copper digunakan dalam instalasi listrik, pipa, dan peralatan masak. berbahaya jika lebih besar dari 1,3. Kandungan tembaga yang berlebihan dalam air minum dapat menyebabkan gangguan pencernaan dan masalah hati.</li>
<li><strong>Fluoride</strong> : Kandungan fluoride dalam air. Fluoride adalah ion anorganik yang penting untuk kesehatan gigi. berbahaya jika lebih besar dari 1,5. konsumsi fluoride dalam jumlah yang berlebihan dapat menyebabkan masalah kesehatan gigi dan tulang.</li>
<li><strong>Bacteria</strong> : Indikator keberadaan bakteri dalam air. Bakteri adalah mikroorganisme yang dapat ditemukan dalam air. berbahaya jika lebih besar dari 0.</li>
<li><strong>Viruses</strong> : Indikator keberadaan virus dalam air. berbahaya jika lebih besar dari 0</li>
<li><strong>Lead</strong> : Kandungan timbal dalam air. Lead adalah logam berat yang dapat menyebabkan keracunan, terutama pada anak-anak. berbahaya jika lebih besar dari 0,015. Pemaparan timbal dapat menyebabkan kerusakan otak dan sistem saraf.</li>
<li><strong>Nitrates</strong> : Kandungan nitrat dalam air. Nitrates adalah senyawa kimia yang dapat ditemukan dalam pupuk dan limbah industriberbahaya jika lebih besar dari 10. Kandungan nitrates yang tinggi dalam air dapat menyebabkan masalah kesehatan, terutama pada bayi.</li>
<li><strong>Nitrites</strong> : Kandungan nitrit dalam air. nitrites adalah senyawa kimia yang dapat ditemukan dalam pupuk dan limbah industriberbahaya jika lebih besar dari 1. Kandungan nitrites yang tinggi dalam air dapat menyebabkan masalah kesehatan, terutama pada bayi.</li>
<li><strong>Mercury</strong> : Kandungan merkuri dalam air. Mercury adalah logam berat yang dapat mengakumulasi dalam organisme hidup dan menyebabkan keracunan. berbahaya jika lebih besar dari 0,002. Pemaparan merkuri dapat merusak otak, ginjal, dan sistem saraf.</li>
<li><strong>Perchlorate</strong> : Kandungan perchlorate dalam air. Perchlorate adalah senyawa kimia yang digunakan dalam bahan peledak dan propelan roket. Pemaparan perchlorate dapat mengganggu fungsi tiroid. berbahaya jika lebih besar dari 56</li>
<li><strong>Radium</strong> : Kandungan radium dalam air. Radium adalah unsur radioaktif yang dapat ditemukan secara alami dalam tanah dan air. Paparan radium dapat meningkatkan risiko kanker. berbahaya jika lebih besar dari 5</li>
<li><strong>Selenium</strong> : Kandungan selenium dalam air. berbahaya jika lebih besar dari 0,5. konsumsi selenium yang berlebihan dapat menyebabkan masalah kesehatan, termasuk kerusakan saraf.</li>
<li><strong>Silver</strong> : Kandungan perak dalam air. berbahaya jika lebih besar dari 0,1. Konsumsi perak dalam jumlah yang berlebihan dapat menyebabkan argyria, kondisi di mana kulit manusia berubah menjadi warna biru keabu-abuan.</li>
<li><strong>Uranium</strong> : Kandungan uranium dalam air. Uranium adalah unsur radioaktif yang dapat ditemukan secara alami dalam batuan dan air. Paparan uranium dapat meningkatkan risiko kanker dan masalah ginjal. berbahaya jika lebih besar dari 0,3</li>
<li><strong>Is_safe</strong> : Kolom ini adalah label atau target variabel yang menunjukkan apakah sampel air tersebut aman untuk dikonsumsi atau tidak. class attribute {0 - not safe, 1 - safe}</li>
</ol>
<p>fitur di atas ini mencerminkan kandungan berbagai mikroorganisme dalam air. Dalam setiap fitur atau kandungan yang ada dalam air tersebut memiliki batasan aman. jika kandungan mikroorganisme melebihi nilai-nilai batasan ini, air dianggap tidak aman untuk konsumsi manusia.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',
       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',
       'silver', 'uranium', 'is_safe'],
      dtype='object')</code></pre>
</div>
</div>
<p>fungsi columns digunakan untuk menampilkan nama-nama kolom pada dataframe. yang mana dataset water quality ini terdiri dari 21 kolom, yakni aluminium, ammonia, arsenic, barium, cadmium, chloramine, chromium, copper, flouride, bacteria, viruses, lead, nitrates, nitrites, mercury, perchlorate, radium, selenium, silver, uranium, dan is_safe.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">viruses</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
<td>7999.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>0.666158</td>
<td>0.161445</td>
<td>1.567715</td>
<td>0.042806</td>
<td>2.176831</td>
<td>0.247226</td>
<td>0.805857</td>
<td>0.771565</td>
<td>0.319665</td>
<td>0.328583</td>
<td>0.099450</td>
<td>9.818822</td>
<td>1.329961</td>
<td>0.005194</td>
<td>16.460299</td>
<td>2.920548</td>
<td>0.049685</td>
<td>0.147781</td>
<td>0.044673</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1.265145</td>
<td>0.252590</td>
<td>1.216091</td>
<td>0.036049</td>
<td>2.567027</td>
<td>0.270640</td>
<td>0.653539</td>
<td>0.435373</td>
<td>0.329485</td>
<td>0.378096</td>
<td>0.058172</td>
<td>5.541331</td>
<td>0.573219</td>
<td>0.002967</td>
<td>17.687474</td>
<td>2.323009</td>
<td>0.028770</td>
<td>0.143551</td>
<td>0.026904</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>0.040000</td>
<td>0.030000</td>
<td>0.560000</td>
<td>0.008000</td>
<td>0.100000</td>
<td>0.050000</td>
<td>0.090000</td>
<td>0.405000</td>
<td>0.000000</td>
<td>0.002000</td>
<td>0.048000</td>
<td>5.000000</td>
<td>1.000000</td>
<td>0.003000</td>
<td>2.170000</td>
<td>0.820000</td>
<td>0.020000</td>
<td>0.040000</td>
<td>0.020000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>0.070000</td>
<td>0.050000</td>
<td>1.190000</td>
<td>0.040000</td>
<td>0.530000</td>
<td>0.090000</td>
<td>0.750000</td>
<td>0.770000</td>
<td>0.220000</td>
<td>0.008000</td>
<td>0.102000</td>
<td>9.930000</td>
<td>1.420000</td>
<td>0.005000</td>
<td>7.740000</td>
<td>2.410000</td>
<td>0.050000</td>
<td>0.080000</td>
<td>0.050000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>0.280000</td>
<td>0.100000</td>
<td>2.480000</td>
<td>0.070000</td>
<td>4.240000</td>
<td>0.440000</td>
<td>1.390000</td>
<td>1.160000</td>
<td>0.610000</td>
<td>0.700000</td>
<td>0.151000</td>
<td>14.610000</td>
<td>1.760000</td>
<td>0.008000</td>
<td>29.480000</td>
<td>4.670000</td>
<td>0.070000</td>
<td>0.240000</td>
<td>0.070000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>5.050000</td>
<td>1.050000</td>
<td>4.940000</td>
<td>0.130000</td>
<td>8.680000</td>
<td>0.900000</td>
<td>2.000000</td>
<td>1.500000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>0.200000</td>
<td>19.830000</td>
<td>2.930000</td>
<td>0.010000</td>
<td>60.010000</td>
<td>7.990000</td>
<td>0.100000</td>
<td>0.500000</td>
<td>0.090000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Fungsi describe() digunakan untuk menampilkan statistik deskriptif dari data frame atau series. Output dari fungsi ini berisi rangkuman central tendency dan sebaran dari dataset. Fungsi describe() membantu kita untuk mendapatkan overview dari dataset. Di bawah ini adalah penjelasan hasil yang diberikan:</p>
<ul>
<li><p>Count (Jumlah): Menunjukkan jumlah data yang ada dalam setiap kolom. Misalnya, pada kolom “aluminium”, terdapat 7999 data.</p></li>
<li><p>Mean (Rata-rata): Menunjukkan nilai rata-rata dari setiap kolom. Misalnya, rata-rata kandungan aluminium adalah sekitar 0.666158.</p></li>
<li><p>Std (Standar Deviasi): Menunjukkan sejauh mana nilai-nilai dalam kolom tersebar dari rata-rata. Semakin tinggi standar deviasi, semakin besar variabilitasnya dari rata-rata. Misalnya, standar deviasi kandungan aluminium adalah sekitar 1.265145.</p></li>
<li><p>Min (Minimum): Menunjukkan nilai terkecil dalam setiap kolom. Misalnya, nilai minimum kandungan arsenik adalah 0.0.</p></li>
<li><p>25% (Kuartil Pertama): Menunjukkan nilai yang membagi 25% data terendah dari nilai-nilai lainnya. Misalnya, pada kolom “aluminium”, 25% data berada di bawah 0.040000.</p></li>
<li><p>50% (Median atau Kuartil Kedua): Menunjukkan nilai yang membagi dataset menjadi dua bagian setara, atau median. Misalnya, median kandungan aluminium adalah 0.070000.</p></li>
<li><p>75% (Kuartil Ketiga): Menunjukkan nilai yang membagi 75% data terendah dari nilai-nilai lainnya. Misalnya, pada kolom “aluminium”, 75% data berada di bawah 0.280000.</p></li>
<li><p>Max (Maksimum): Menunjukkan nilai tertinggi dalam setiap kolom. Misalnya, nilai maksimum kandungan aluminium adalah 5.050000.</p></li>
</ul>
</section>
<section id="deskripsi-tipe-data-fitur" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="deskripsi-tipe-data-fitur"><span class="header-section-number">2.3</span> Deskripsi Tipe Data Fitur</h2>
<p>Berikut adalah analisis tipe data untuk setiap kolom beserta alasannya:</p>
<ol type="1">
<li><p>aluminium: Tipe data rasio. Kandungan aluminium dalam air memiliki nol yang bermakna, dan perbandingan antara dua nilai memiliki arti yang jelas (misalnya, 2 kali lipat).</p></li>
<li><p>ammonia: Tipe data rasio. Kandungan ammonia dalam air juga memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>arsenic: Tipe data rasio. Kandungan arsenik dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>barium: Tipe data rasio. Kandungan barium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>cadmium: Tipe data rasio. Kandungan cadmium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>chloramine: Tipe data rasio. Kandungan chloramine dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>chromium: Tipe data rasio. Kandungan chromium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>copper: Tipe data rasio. Kandungan copper dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>flouride: Tipe data rasio. Kandungan flouride dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>bacteria: Tipe data rasio. Kandungan bakteri dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>viruses: Tipe data rasio. Kandungan virus dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>lead: Tipe data rasio. Kandungan lead dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>nitrates: Tipe data rasio. Kandungan nitrates dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>nitrites: Tipe data rasio. Kandungan nitrites dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>mercury: Tipe data rasio. Kandungan mercury dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>perchlorate: Tipe data rasio. Kandungan perchlorate dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>radium: Tipe data rasio. Kandungan radium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>selenium: Tipe data rasio. Kandungan selenium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>silver: Tipe data rasio. Kandungan silver dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>uranium: Tipe data rasio. Kandungan uranium dalam air memiliki nol yang bermakna dan perbandingan antara dua nilai memiliki arti yang jelas.</p></li>
<li><p>is_safe: Tipe data nominal. Variabel target ini merupakan label kategori yang menunjukkan apakah air layak diminum atau tidak. Ini merupakan tipe data kategorikal dengan dua kategori yang bersifat nominal.</p></li>
</ol>
</section>
<section id="identifikasi-missing-value" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="identifikasi-missing-value"><span class="header-section-number">2.4</span> Identifikasi Missing Value</h2>
<p>(Dataset ini memiliki 3 missing value pada kolom amonia dan is_safe) penjelasannya sebagai berikut :</p>
<p>Identifikasi missing value adalah proses mengenali dan menentukan lokasi di mana nilai-nilai yang hilang (missing value) terdapat dalam dataset. untuk mencari missing value kita bisa menggunakan fungsi info(). Fungsi info() digunakan untuk menampilkan informasi detail tentang dataframe, seperti jumlah baris data, nama-nama kolom berserta jumlah data dan tipe datanya, dan sebagainya. Dimana didapat bahwa dataset tersebut nampaknya tidak memiliki nilai yang missing karena nilai non-null setiap kolomnya sebanyak 7999 sama dengan jumlah dataset sebenarnya. akan tetapi perlu di telisik lebih dalam karena bisa jadi valuenya terdapat kerusakan seperti yang awalnya berupa angka, akan tetapi berubah menjadi stringg atau object, dimana itu terdeteksi pada kolom amonia dan is_safe.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 7999 entries, 0 to 7998
Data columns (total 21 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   aluminium    7999 non-null   float64
 1   ammonia      7999 non-null   object 
 2   arsenic      7999 non-null   float64
 3   barium       7999 non-null   float64
 4   cadmium      7999 non-null   float64
 5   chloramine   7999 non-null   float64
 6   chromium     7999 non-null   float64
 7   copper       7999 non-null   float64
 8   flouride     7999 non-null   float64
 9   bacteria     7999 non-null   float64
 10  viruses      7999 non-null   float64
 11  lead         7999 non-null   float64
 12  nitrates     7999 non-null   float64
 13  nitrites     7999 non-null   float64
 14  mercury      7999 non-null   float64
 15  perchlorate  7999 non-null   float64
 16  radium       7999 non-null   float64
 17  selenium     7999 non-null   float64
 18  silver       7999 non-null   float64
 19  uranium      7999 non-null   float64
 20  is_safe      7999 non-null   object 
dtypes: float64(19), object(2)
memory usage: 1.3+ MB</code></pre>
</div>
</div>
<p>Kita akan mengecek apakah sebuah data mengandung Pesan “#NUM!”. #NUM! mungkin muncul karena adanya kesalahan atau format yang tidak tepat dalam dataset, terutama pada kolom yang seharusnya berisi nilai numerik. Tanda ini seringkali menunjukkan bahwa suatu sel atau entri dalam dataset tidak dapat diuraikan sebagai nilai numerik yang valid.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung apakah ada nilai '#NUM!' dalam setiap kolom</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>contains_num <span class="op">=</span> df.eq(<span class="st">'#NUM!'</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Apakah ada nilai '#NUM!' dalam setiap kolom:"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(contains_num.<span class="bu">any</span>())</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung jumlah nilai '#NUM!' untuk setiap kolom</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>num_count_per_column <span class="op">=</span> contains_num.<span class="bu">sum</span>()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah nilai '#NUM!' untuk setiap kolom:"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(num_count_per_column)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Apakah ada nilai '#NUM!' dalam setiap kolom:
aluminium      False
ammonia         True
arsenic        False
barium         False
cadmium        False
chloramine     False
chromium       False
copper         False
flouride       False
bacteria       False
viruses        False
lead           False
nitrates       False
nitrites       False
mercury        False
perchlorate    False
radium         False
selenium       False
silver         False
uranium        False
is_safe         True
dtype: bool
Jumlah nilai '#NUM!' untuk setiap kolom:
aluminium      0
ammonia        3
arsenic        0
barium         0
cadmium        0
chloramine     0
chromium       0
copper         0
flouride       0
bacteria       0
viruses        0
lead           0
nitrates       0
nitrites       0
mercury        0
perchlorate    0
radium         0
selenium       0
silver         0
uranium        0
is_safe        3
dtype: int64</code></pre>
</div>
</div>
<p>Kode di atas ini digunakan untuk mengakumulasi dengan melakukan pengecekan apakah terdapat nilai yang hilang (NaN) dalam kolom yang ada dalam DataFrame (df). - Fungsi eq (singkatan dari “equal”) pada Pandas digunakan untuk membandingkan elemen-elemen dalam suatu DataFrame atau Series dengan nilai tertentu dan mengembalikan DataFrame atau Series baru yang berisi nilai True jika elemennya sama dengan nilai yang dibandingkan, dan False jika tidak. - Fungsi any() fungsi any() pada Pandas digunakan untuk menentukan apakah setidaknya satu elemen dalam suatu DataFrame atau Series memiliki nilai True. Jika ada setidaknya satu nilai True, maka fungsi any() akan mengembalikan True; sebaliknya, jika semua nilai adalah False, maka akan mengembalikan False. - fungsi sum() fungsi sum() pada pandas digunakan untuk menjumlahkan suatu data, dimana fungsi ini digunakan untuk menghitung jumlah nilai True (jumlah nilai ‘#NUM!’) dalam setiap kolom dan menyimpannya dalam suatu variable untuk kemudian ditampilkan.</p>
<p>Berdasarkan identifikasi lebih dalam maka didapati nilai yang hilang berupa #NUM! Dalam dataset water quality ini memiliki 3 missing value pada kolom amonia dan is_safe.</p>
</section>
<section id="identifikasi-data-duplicated" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="identifikasi-data-duplicated"><span class="header-section-number">2.5</span> Identifikasi Data Duplicated</h2>
<p>Identifikasi data duplikat merujuk pada proses menemukan dan menandai baris atau entri dalam dataset yang memiliki nilai yang sama di semua kolomnya. Dengan kata lain, data duplikat adalah duplikat persis dari baris lainnya dalam dataset. Dalam dataset water Quality ini tidak ditemukannya data duplikat.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>jumlah_duplikat <span class="op">=</span> df.duplicated().<span class="bu">sum</span>()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan jumlah data yang duplikat</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah data yang duplikat:"</span>, jumlah_duplikat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah data yang duplikat: 0</code></pre>
</div>
</div>
<p>Kode diatas yakni digunakan untuk mengidentifikasi dan menghitung jumlah data duplikat dalam DataFrame (df). Menggunakan metode duplicated() untuk menghasilkan keterangan boolean yang menunjukkan apakah setiap baris dalam DataFrame adalah duplikat dari baris sebelumnya atau tidak (True atau False). Kemudian, metode sum() digunakan untuk menghitung jumlah total nilai True, yang merupakan jumlah total data duplikat. Dalam dataset saya, tidak ada data yang mengalami duplikasi data.</p>
<p>Contoh deteksi duplikat data : | A | B | |—|——–| | 1 | apple | | 2 | banana | | 3 | apple | | 2 | banana | | 4 | orange |</p>
<p>Baris-baris yang merupakan duplikat: - 0 False - 1 False - 2 False - 3 True - 4 False</p>
</section>
<section id="identifikasi-sebaran-kelas-data" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="identifikasi-sebaran-kelas-data"><span class="header-section-number">2.6</span> Identifikasi Sebaran Kelas Data</h2>
<p>identifikasi ini digunakan untuk melihat sejauh mana perbedaan jumlah kedua kelas yakni kelas 0 atau tidak aman, dan kelas 1 atau aman. Dalam dataset Water Quality ini mengalamni unbalance data, dimana terdapat perbedaan yang cukup signifikan dalam jumlah data tiap kelasnya. Data dengan kelas 0 atau tidak aman berjumlah 7084 berbanding cukup jauh dengan data dengan kelas 1 yang hanya berkisar 912 data saja. Oleh karena itu, perlu dilakukan pre-processing untuk menyamaratakan jumlah data setiap kelasnya.</p>
<p>Menurut He dan Edwardo (2009) sebuah himpunan data dikatakan imbalanced jika terdapat salah satu kelas yang direpresentasikan dalam jumlah yang tidak sebanding dengan kelas yang lain. Kondisi imbalanced data menjadi masalah dalam klasifikasi karena classifier learning akan condong memprediksi ke kelas data yang banyak (mayoritas) dibanding dengan kelas yang sedikit (minoritas). Akibatnya, dihasilkan akurasi prediksi yang baik terhadap kelas data training yang banyak (kelas mayoritas) sedangkan untuk kelas data training yang sedikit (kelas minoritas) akan dihasilkan akurasi prediksi yang buruk.</p>
<p>Imbalanced data dapat diatasi dengan beberapa cara, antara lain dengan pengambilan sampel pada setiap kelas dan strategi sampling seperti oversampling atau undersampling.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'waterQuality1.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">'is_safe'</span>].unique())</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.is_safe.value_counts())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['1' '0' '#NUM!']
0        7084
1         912
#NUM!       3
Name: is_safe, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Menggunakan seaborn untuk membuat countplot</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">"whitegrid"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.countplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'is_safe'</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Menambahkan label pada sumbu y</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Jumlah Data'</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Menambahkan judul plot</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribusi Kelas'</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan jumlah data untuk masing-masing kelas di atas batangnya</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p <span class="kw">in</span> ax.patches:</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    ax.annotate(<span class="ss">f'</span><span class="sc">{</span>p<span class="sc">.</span>get_height()<span class="sc">}</span><span class="ss">'</span>, (p.get_x() <span class="op">+</span> p.get_width() <span class="op">/</span> <span class="fl">2.</span>, p.get_height()),</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>                ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, xytext<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">10</span>), textcoords<span class="op">=</span><span class="st">'offset points'</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan plot</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Kode diatas menggunakan seaborn dan matplotlib untuk membuat countplot dari kolom ‘is_safe’ dalam DataFrame df. Hasilnya adalah visualisasi distribusi kelas ‘is_safe’ dengan jumlah data di setiap kategori.</p>
</section>
<section id="identifikasi-outlier" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="identifikasi-outlier"><span class="header-section-number">2.7</span> Identifikasi Outlier</h2>
<p>Identifikasi Outlier kali ini menggunakan Metode Local Outlier Factor. Local Outlier Factor (LOF) adalah metode yang digunakan untuk mendeteksi outlier dalam dataset. Data dalam dataset water quality yang mengalami outlier adalah sebanyak 1999 data.</p>
<p>Metode Local Outlier Factor (LOF) membandingkan kerapatan suatu titik data dengan kerapatan titik-titik di sekitarnya. LOF mengukur sejauh mana suatu titik data dianggap anomali atau outlier berdasarkan perbedaan kerapatan. Metode ini dikembangkan oleh Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, dan Jörg Sander pada tahun 2000. <a href="https://en.wikipedia.org/wiki/Local_outlier_factor">Sumber</a></p>
<p>Berikut adalah langkah-langkah Local Outlier Factor (LOF): 1. Hitung jarak antar titik dan tetangga - Rumus jarak euclidean antara dua titik p dan 1 dalam dimensi n: <span class="math display">\[\begin{equation}
\text{Euclidean Distance} (P, Q) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2}
\end{equation}\]</span> <span class="math display">\[\begin{equation}
\text{Euclidean Distance} (P, Q) = \sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2}
\end{equation}\]</span></p>
<ol start="2" type="1">
<li>Hitung kepadatan lokasi</li>
</ol>
<ul>
<li>Kepadatan lokal suatu titik p: <span class="math display">\[\begin{equation}
\text{Density}_p = \frac{1}{{\text{k-th distance}_p}}
\end{equation}\]</span> <span class="math display">\[\begin{equation}
{{\text{Dimana k-th distance adalah jarak ke titik tetangga ke-k}_p}}
\end{equation}\]</span></li>
</ul>
<ol start="3" type="1">
<li>Hitung Local Reachability Density (LRD)</li>
</ol>
<ul>
<li>Local Reachability Density (LRD) suatu titik p: <span class="math display">\[\begin{equation}
\text{LRD}_p = \left(\text{Density}_p\right)^{\frac{1}{\alpha}}
\end{equation}\]</span> di mana α adalah parameter untuk menyesuaikan sensitivitas terhadap fluktuasi kecil dalam kepadatan.</li>
</ul>
<ol start="4" type="1">
<li>Hitung Local Outlier Factor (LOF)</li>
</ol>
<ul>
<li>Local Outlier Factor (LOF) suatu titik p: <span class="math display">\[\begin{equation}
\text{LOF}_p = \frac{\left|\text{Neighbors}_p\right|}{\sum_{o \in \text{Neighbors}_p} \frac{\text{LRD}_o}{\text{LRD}_p}}
\end{equation}\]</span> di mana Neighborsp adalah himpunan tetangga dari titik p.</li>
</ul>
<ol start="5" type="1">
<li>Identifikasi Outlier: Tentukan threshold, dan labeli titik-titik yang memiliki LOF di atas threshold sebagai outlier. Pada umumnya, jika LOF(p) &gt; Threshold, maka titik p dianggap sebagai outlier.</li>
</ol>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'waterQuality1.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Mengganti '#NUM!' dengan NaN dan mengonversi kolom ke tipe float</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>df.replace(<span class="st">'#NUM!'</span>, <span class="bu">float</span>(<span class="st">'nan'</span>), inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.<span class="bu">apply</span>(pd.to_numeric, errors<span class="op">=</span><span class="st">'coerce'</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter DataFrame untuk nilai yang bukan NaN (numerik)</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>df_numeric <span class="op">=</span> df.dropna()</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Contamination values yang ingin diuji</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>contamination_values <span class="op">=</span> [<span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.25</span>]</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Inisialisasi variabel untuk menyimpan hasil terbaik</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>max_outliers <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> {<span class="st">'n_neighbors'</span>: <span class="va">None</span>, <span class="st">'contamination'</span>: <span class="va">None</span>}</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop untuk nilai n_neighbors dari 1 hingga 50</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n_neighbors <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">51</span>):</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> contamination <span class="kw">in</span> contamination_values:</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        lof <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span>n_neighbors, contamination<span class="op">=</span>contamination)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        outlier_labels <span class="op">=</span> lof.fit_predict(df_numeric)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        num_outliers <span class="op">=</span> <span class="bu">sum</span>(outlier_labels <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>)  <span class="co"># Menghitung jumlah outlier yang dideteksi</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Memperbarui hasil terbaik jika ditemukan jumlah outlier yang lebih banyak</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_outliers <span class="op">&gt;</span> max_outliers:</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>            max_outliers <span class="op">=</span> num_outliers</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>            best_params[<span class="st">'n_neighbors'</span>] <span class="op">=</span> n_neighbors</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>            best_params[<span class="st">'contamination'</span>] <span class="op">=</span> contamination</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Mencetak hasil terbaik</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Parameter terbaik:"</span>)</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah data outlier :"</span>, max_outliers)</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah data tanpa outlier :"</span>, (df.shape[<span class="dv">0</span>])<span class="op">-</span>max_outliers)</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"n_neighbors ="</span>, best_params[<span class="st">'n_neighbors'</span>])</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"contamination ="</span>, best_params[<span class="st">'contamination'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\Lenovo\anaconda3\Lib\site-packages\joblib\externals\loky\backend\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:
found 0 physical cores &lt; 1
Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.
  warnings.warn(
  File "C:\Users\Lenovo\anaconda3\Lib\site-packages\joblib\externals\loky\backend\context.py", line 282, in _count_physical_cores
    raise ValueError(f"found {cpu_count_physical} physical cores &lt; 1")</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Parameter terbaik:
Jumlah data outlier : 1999
Jumlah data tanpa outlier : 6000
n_neighbors = 1
contamination = 0.25</code></pre>
</div>
</div>
<p>Pada kode di atas, saya menerapkan grid search untuk mencari parameter yang bagus guna mendeteksi outlier, dimana parameter yang terpilih yakni dengan n_neighbors 1 dan contaminationsnya 0,25</p>
</section>
<section id="eksplorasi-data" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="eksplorasi-data"><span class="header-section-number">2.8</span> Eksplorasi Data</h2>
<p>Pada eksplorasi data kali ini saya akan menampilkan data ke dalam bentuk grafik-grafik seperti histogram, dan matrix. Visualisasi ini agar memudahkan untuk mengambil informasi penting dari sebuah data.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca data dari file csv</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'waterQuality1.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><h3 id="histogram-sebaran-frekuensi-data-setiap-kolom" data-number="2.8.1" class="anchored"><span class="header-section-number">2.8.1</span> Histogram Sebaran Frekuensi Data Setiap Kolom</h3></li>
</ul>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#distribution data</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>df.hist(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">14</span>))</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Kode diatas bertujuan untuk memberikan visualisasi distribusi data dari dataframe df menggunakan histogram. Histogram adalah grafik yang membagi rentang data ke dalam interval dan menghitung jumlah data yang jatuh dalam setiap interval tersebut. Ini membantu untuk memahami pola distribusi data dan melihat sebaran nilai-nilai dalam dataset.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">'whitegrid'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot histograms for the distribution of all columns</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">15</span>))</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>data_columns <span class="op">=</span> df.columns.tolist()</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>data_columns.remove(<span class="st">'is_safe'</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust the number of rows and columns in the subplot grid for better visualization</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>num_rows <span class="op">=</span> <span class="bu">len</span>(data_columns) <span class="op">//</span> <span class="dv">2</span> <span class="op">+</span> <span class="bu">len</span>(data_columns) <span class="op">%</span> <span class="dv">2</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, column <span class="kw">in</span> <span class="bu">enumerate</span>(data_columns):</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    plt.subplot(num_rows, num_cols, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    sns.histplot(df[column], kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">'orange'</span>, bins<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'Distribusi kolom </span><span class="sc">{</span>column<span class="sc">}</span><span class="ss">'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">''</span>)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Kepadatan'</span>)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Distribusi Data"</span>)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Kode di atas mengatur gaya plot, kemudian memplot histogram untuk distribusi semua kolom pada DataFrame. Setiap subplot menunjukkan distribusi nilai dari satu kolom, dan garis halus (kernel density estimation) ditambahkan untuk memberikan representasi kepadatan distribusi data.</p>
<ul>
<li><h3 id="matrix-korelasi" data-number="2.8.2" class="anchored"><span class="header-section-number">2.8.2</span> Matrix Korelasi</h3></li>
</ul>
<p>Kode berikut dibawah ini menghasilkan sebuah matriks korelasi dengan menggunakan fungsi corr() dari pandas pada DataFrame df. Matriks korelasi ini merepresentasikan hubungan linier antara semua pasangan variabel dalam dataset. Setiap sel dalam matriks menunjukkan nilai korelasi antara dua variabel.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> df.corr()</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">15</span>))</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>sns.heatmap(correlation_matrix, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, center<span class="op">=</span><span class="dv">0</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Correlation Plot of Water Quality Parameters"</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\Lenovo\AppData\Local\Temp\ipykernel_13180\1987230932.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = df.corr()</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-18-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Cara membaca matriks korelasi:</p>
<p>Skala Nilai Korelasi: - 1.0: Korelasi sempurna positif. Artinya, jika satu variabel naik, yang lain juga naik secara linear. - -1.0: Korelasi sempurna negatif. Artinya, jika satu variabel naik, yang lain turun secara linear. - 0.0: Tidak ada korelasi linier antara variabel tersebut.</p>
<p>Warna Sel pada Heatmap digunakan untuk memvisualisasikan matriks korelasi. Sel-sel dengan warna yang lebih terang atau lebih gelap menunjukkan nilai korelasi yang lebih tinggi, sementara warna yang lebih netral menunjukkan korelasi yang lebih rendah.</p>
<ul>
<li><h3 id="diagram-lingkaran-perbandingan-jumlah-data-kelas" data-number="2.8.3" class="anchored"><span class="header-section-number">2.8.3</span> Diagram Lingkaran perbandingan jumlah data kelas</h3></li>
</ul>
<p>ini digunakan untuk menggambarkan persentasi perbandingan distribusi data setiap kelas yakni kelas 0 (tidak aman) dan kelas 1 (aman)</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghapus baris dengan nilai '#NUM!'</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>df_cleaned <span class="op">=</span> df[df <span class="op">!=</span> <span class="st">'#NUM!'</span>].dropna()</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung jumlah data untuk setiap kelas</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>class_counts <span class="op">=</span> df_cleaned[<span class="st">'is_safe'</span>].value_counts()</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Membuat plot pie chart</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>plt.pie(class_counts, labels<span class="op">=</span>class_counts.index, autopct<span class="op">=</span><span class="st">'</span><span class="sc">%1.1f%%</span><span class="st">'</span>, startangle<span class="op">=</span><span class="dv">90</span>, colors<span class="op">=</span>[<span class="st">'lightgreen'</span>, <span class="st">'lightcoral'</span>])</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribusi Kelas (is_safe)'</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="pre-procesing" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> 3. Pre-Procesing</h1>
<p>Preprocessing (pra-pemrosesan) adalah tahap dalam analisis data yang bertujuan untuk membersihkan, mengorganisir, dan menyesuaikan data sehingga dapat digunakan secara efektif untuk pemodelan atau analisis lebih lanjut.</p>
<section id="handling-missing-data" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="handling-missing-data"><span class="header-section-number">3.1</span> Handling Missing Data</h2>
<p>Mengidentifikasi dan menangani nilai-nilai yang hilang dalam dataset. Cara penanganannya bisa berupa menghapus baris/kolom yang mengandung nilai yang hilang atau mengisi nilai yang hilang dengan suatu nilai (misalnya, rata-rata, median, atau nilai yang paling sering muncul).</p>
<p>Sebelumnya telah teridentifikasi bahwa dataset water quality ini memiliki 3 nilai yang hilang atau berupa #NUM! pada kolom amonia dan is_safe, selain itu kolom tersebut yang masih berupa object bukan numeric. oleh karena itu perlu dilakukan penanganan dengan cara menghapus kolom yang memiliki nilai yang hilang tersebut.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca data dari file csv</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'waterQuality1.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Pertama kita ganti nilai #NUM! menjadi NaN. Fungsi replace() digunakan untuk mengganti sebuah nilai pada dataframe. Misalnya disini kita mengganti nilai #NUM! yang ada di dataframe dengan NaN.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>df.replace(<span class="st">"#NUM!"</span>, pd.NA, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Selanjutnya menseleksi dataframe yang kolom amonia-nya tidak mengandung missing value atau NaN. artinya kolom yang hilang tadi dilakukan penghapusan data.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">'ammonia'</span>].notna()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Lalu dilakukan penggantian tipe data kolom amonia dan is_safe yang sebelumnya berupa object atau string menjadi tipe data numeric menggunakan fungsi to_numeric().</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'ammonia'</span>] <span class="op">=</span> pd.to_numeric(df[<span class="st">'ammonia'</span>])</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'is_safe'</span>] <span class="op">=</span> pd.to_numeric(df[<span class="st">'is_safe'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>selanjutnya dilakukan pengecekan kembali terhadap dataset apakah missing value telah dihapus atau belum, dan melihat tipe data dari setiap kolomnya apakah sudah menjadi numeric semua.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung apakah ada nilai yang hilang dalam setiap kolom</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>missing_values <span class="op">=</span> df.isna().<span class="bu">any</span>()</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Apakah ada nilai yang hilang dalam setiap kolom:"</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_values)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>nan_kolom <span class="op">=</span> df.isna().<span class="bu">sum</span>()</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah nilai yang hilang (NA) untuk setiap kolom:"</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(nan_kolom)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Apakah ada nilai yang hilang dalam setiap kolom:
aluminium      False
ammonia        False
arsenic        False
barium         False
cadmium        False
chloramine     False
chromium       False
copper         False
flouride       False
bacteria       False
viruses        False
lead           False
nitrates       False
nitrites       False
mercury        False
perchlorate    False
radium         False
selenium       False
silver         False
uranium        False
is_safe        False
dtype: bool
Jumlah nilai yang hilang (NA) untuk setiap kolom:
aluminium      0
ammonia        0
arsenic        0
barium         0
cadmium        0
chloramine     0
chromium       0
copper         0
flouride       0
bacteria       0
viruses        0
lead           0
nitrates       0
nitrites       0
mercury        0
perchlorate    0
radium         0
selenium       0
silver         0
uranium        0
is_safe        0
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 7996 entries, 0 to 7998
Data columns (total 21 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   aluminium    7996 non-null   float64
 1   ammonia      7996 non-null   float64
 2   arsenic      7996 non-null   float64
 3   barium       7996 non-null   float64
 4   cadmium      7996 non-null   float64
 5   chloramine   7996 non-null   float64
 6   chromium     7996 non-null   float64
 7   copper       7996 non-null   float64
 8   flouride     7996 non-null   float64
 9   bacteria     7996 non-null   float64
 10  viruses      7996 non-null   float64
 11  lead         7996 non-null   float64
 12  nitrates     7996 non-null   float64
 13  nitrites     7996 non-null   float64
 14  mercury      7996 non-null   float64
 15  perchlorate  7996 non-null   float64
 16  radium       7996 non-null   float64
 17  selenium     7996 non-null   float64
 18  silver       7996 non-null   float64
 19  uranium      7996 non-null   float64
 20  is_safe      7996 non-null   int64  
dtypes: float64(20), int64(1)
memory usage: 1.3 MB</code></pre>
</div>
</div>
<p>Melalui pengecekan ini, didapati bahwa missing value telah dihapus, dan tipe data kolom sudah menjadi numeric dan bukan object. Selanjutnya kita bisa simpang hasil data yang sudah tidak ada missing value dengan nama datanomissing.csv</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">'datanomissing.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-cleaning" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="data-cleaning"><span class="header-section-number">3.2</span> Data Cleaning</h2>
<p>Data cleaning kali ini akan Mendeteksi dan mengatasi noise atau outlier dalam data. Noise dapat muncul sebagai nilai yang ekstrim atau tidak sesuai dengan distribusi umum data. Dalam data cleaning ini saya akan menggunakan metode Local Outlier Factor. Didapati pada data understanding dimana outlier terdeteksi sebanyak 1999 data dan perlu dilakukan penghapusan data tersebut.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca data dari file csv</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'datanomissing.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Kita coba gambarkan data dan sebarannya melalui BoxPlot untuk mengetahui seperti apa data outlier dalam setiap kolom.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of numerical features and plot them</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>list_of_num_features <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">'is_safe'</span>])  <span class="co"># DataFrame of numerical features</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>palette_features <span class="op">=</span> [<span class="st">'#E68753'</span>, <span class="st">'#409996'</span>]</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(rc<span class="op">=</span>{<span class="st">'axes.facecolor'</span>:<span class="st">'#ECECEC'</span>})</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Mengatur tata letak subplot</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>num_rows <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(num_rows, num_cols, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">14</span>), sharex<span class="op">=</span><span class="va">False</span>, sharey<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten array of subplots for ease of indexing</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.flatten()</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, feature <span class="kw">in</span> <span class="bu">enumerate</span>(list_of_num_features.columns):</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> axes[idx]  <span class="co"># Mengambil subplot yang sesuai</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    sns.boxplot(x<span class="op">=</span><span class="st">'is_safe'</span>, y<span class="op">=</span>feature, data<span class="op">=</span>df, palette<span class="op">=</span>palette_features, ax<span class="op">=</span>ax)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    ax.set_title(feature, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, ha<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Sembunyikan subplot yang tidak digunakan</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(list_of_num_features.columns), num_rows <span class="op">*</span> num_cols):</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>    fig.delaxes(axes[i])</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Atur tata letak dan tampilkan plot</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Kita coba kembali menggunakan local outlier factor untuk mendeteksi jumlah data outlier di dalam data menggunakan fungsi LocalOutlierFactor dengan parameter n_neigbors yakni 1 dan contamination yakni 0,25. Parameter ini didapat dari pencarian menggunakan grid search pada data undestanding di atas. Selanjutnya baris data yang terdeteksi sebagai outlier akan diberikan label -1 sedangkan yang bukan outlier akan diberi label 1</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Menggunakan Local Outlier Factor</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>lof <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">1</span>, contamination<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>outlier_labels <span class="op">=</span> lof.fit_predict(df)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Outlier'</span>] <span class="op">=</span> outlier_labels</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
<th data-quarto-table-cell-role="th">Outlier</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7991</td>
<td>0.05</td>
<td>7.78</td>
<td>0.00</td>
<td>1.95</td>
<td>0.040</td>
<td>0.10</td>
<td>0.03</td>
<td>0.03</td>
<td>1.37</td>
<td>0.00</td>
<td>...</td>
<td>14.29</td>
<td>1.00</td>
<td>0.005</td>
<td>3.57</td>
<td>2.13</td>
<td>0.09</td>
<td>0.06</td>
<td>0.03</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7992</td>
<td>0.05</td>
<td>24.22</td>
<td>0.02</td>
<td>0.59</td>
<td>0.010</td>
<td>0.45</td>
<td>0.02</td>
<td>0.02</td>
<td>1.48</td>
<td>0.00</td>
<td>...</td>
<td>10.27</td>
<td>1.00</td>
<td>0.001</td>
<td>1.48</td>
<td>1.11</td>
<td>0.09</td>
<td>0.10</td>
<td>0.08</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7993</td>
<td>0.09</td>
<td>6.85</td>
<td>0.00</td>
<td>0.61</td>
<td>0.030</td>
<td>0.05</td>
<td>0.05</td>
<td>0.02</td>
<td>0.91</td>
<td>0.00</td>
<td>...</td>
<td>15.92</td>
<td>1.00</td>
<td>0.000</td>
<td>1.35</td>
<td>4.84</td>
<td>0.00</td>
<td>0.04</td>
<td>0.05</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7994</td>
<td>0.01</td>
<td>10.00</td>
<td>0.01</td>
<td>2.00</td>
<td>0.000</td>
<td>2.00</td>
<td>0.00</td>
<td>0.09</td>
<td>0.00</td>
<td>0.00</td>
<td>...</td>
<td>0.00</td>
<td>0.00</td>
<td>0.000</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00</td>
<td>1</td>
<td>-1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7995</td>
<td>0.04</td>
<td>6.85</td>
<td>0.01</td>
<td>0.70</td>
<td>0.030</td>
<td>0.05</td>
<td>0.01</td>
<td>0.03</td>
<td>1.00</td>
<td>0.00</td>
<td>...</td>
<td>15.92</td>
<td>1.00</td>
<td>0.000</td>
<td>1.35</td>
<td>4.84</td>
<td>0.00</td>
<td>0.04</td>
<td>0.05</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>7996 rows × 22 columns</p>
</div>
</div>
</div>
<p>Selanjutnya menghitung jumlah outlier di dalam dataset water quality atau data yang memiliki label -1, dan menemukan sebanyak 1999 data termasuk data outlier.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung jumlah outlier</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>total_outliers <span class="op">=</span> (df[<span class="st">'Outlier'</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Total Jumlah Outlier:"</span>, total_outliers)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung jumlah outlier</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>total_no_outliers <span class="op">=</span> (df[<span class="st">'Outlier'</span>] <span class="op">==</span> <span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Total Data Tanpa Outlier:"</span>, total_no_outliers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total Jumlah Outlier: 1999
Total Data Tanpa Outlier: 5997</code></pre>
</div>
</div>
<p>Selanjutnya dilakukan penghapusan data terhadap data outlier, kemudian hasil data yang bebas outlier saya simpan sebagai csv dengan nama data_no_outlier.csv. Pada data yang bersih atau bebas outlier, didapati bahwa kelas 0 sebanyak 5265 sedangkan kelas 1 yakni sebanyak 732 data.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>df_no_outliers <span class="op">=</span> df[df[<span class="st">'Outlier'</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>df_no_outliers <span class="op">=</span> df_no_outliers.drop(columns<span class="op">=</span>[<span class="st">'Outlier'</span>])</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>df_no_outliers.to_csv(<span class="st">'data_no_outliers.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_no_outliers.csv'</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung jumlah target pada data tanpa outlier</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>classnooutlier <span class="op">=</span> df[<span class="st">'is_safe'</span>].value_counts()</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah target pada data tanpa outlier:"</span>)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classnooutlier)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah target pada data tanpa outlier:
0    5236
1     761
Name: is_safe, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="handling-imbalanced-data" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="handling-imbalanced-data"><span class="header-section-number">3.3</span> Handling Imbalanced Data</h2>
<p>Balancing kelas pada dataset ini menggunakan teknik Random Over-Sampling With imblearn. Random Over-Sampling With imblearn adalah salah satu teknik yang digunakan untuk menangani ketidakseimbangan kelas. Dalam metode ini, jumlah sampel dalam kelas minoritas ditingkatkan dengan menambahkan salinan acak dari sampel yang sudah ada dalam kelas tersebut. Metode Random Over-Sampling memungkinkan untuk mengatasi ketidakseimbangan kelas tanpa menghapus data dari kelas mayoritas, sehingga tidak ada informasi yang hilang dalam prosesnya.</p>
<p>Sebelum dilakukan preprocessing, data dengan kelas 0 sejumlah 7084 dan kelas 1 sebanyak 912. Akan tetapi setelah dilakukan preprocesing data dengan kelas 0 hanya sebanyak 5265 dan kelas 1 hanya 732 data. Meskipun begitu masih perlu dilakukan balancing kelas agar kelas menjadi proporsional satu sama lain.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_no_outliers.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="perbandingan-kelas-data-awal" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="perbandingan-kelas-data-awal"><span class="header-section-number">3.3.1</span> Perbandingan kelas data awal</h3>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>sns.countplot(data <span class="op">=</span> df, x <span class="op">=</span> <span class="st">'is_safe'</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># sebaran class</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>class_0 <span class="op">=</span> df[df[<span class="st">'is_safe'</span>] <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>class_1 <span class="op">=</span> df[df[<span class="st">'is_safe'</span>] <span class="op">==</span> <span class="dv">1</span>]</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'class 0 (Not Safe) :'</span>, class_0.shape)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'class 1 (Safe)     :'</span>, class_1.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>class 0 (Not Safe) : (5236, 21)
class 1 (Safe)     : (761, 21)</code></pre>
</div>
</div>
</section>
<section id="proses-balancing-data" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="proses-balancing-data"><span class="header-section-number">3.3.2</span> Proses Balancing Data</h3>
<p>Proses Random Over Sampling adalah sebagai berikut: <img src="ProsesRandomOverSampling.png"> - Identifikasi Kelas Minoritas dengan menentukan kelas yang memiliki jumlah sampel lebih sedikit dan dianggap sebagai kelas minoritas.</p>
<ul>
<li><p>Hitung selisih antara jumlah sampel di kelas mayoritas dan kelas minoritas.</p></li>
<li><p>Pilih Sampel Acak Dari kelas minoritas, pilih sampel secara acak sebanyak selisih yang dihitung.</p></li>
<li><p>Duplikasi sampel acak yang telah dipilih dan tambahkan ke dataset. Dengan kata lain, kita menambahkan kembali sampel-sampel ini ke kelas minoritas.</p></li>
</ul>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate features (X) and target variable (y)</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'is_safe'</span>]</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print original class distribution</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Sebaran Data :'</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Sebaran Data Kelas Awal:'</span>, Counter(y))</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize RandomOverSampler</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>ros <span class="op">=</span> RandomOverSampler(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Random Over-Sampling to balance the classes</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>X_ros, y_ros <span class="op">=</span> ros.fit_resample(X, y)</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Print resampled class distribution</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Sebaran Data Kelas Setelah Balancing:'</span>, Counter(y_ros))</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan jumlah data setelah balancing sampling</span></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Jumlah keseluruhan data setelah balancing sampling :'</span>)</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Features (X_ros) shape:'</span>, X_ros.shape)</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Target (y_ros) shape:'</span>, y_ros.shape)</span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a><span class="co">#visualisasi perbandingan data kelas</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot original class distribution</span></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>sns.countplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'is_safe'</span>)</span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Original Class'</span>)</span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot resampled class distribution after Random Over-Sampling</span></span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a>sns.countplot(data<span class="op">=</span>pd.DataFrame({<span class="st">'is_safe'</span>: y_ros}), x<span class="op">=</span><span class="st">'is_safe'</span>)</span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Random Over-Sampling With imblearn'</span>)</span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sebaran Data :
Sebaran Data Kelas Awal: Counter({0: 5236, 1: 761})
Sebaran Data Kelas Setelah Balancing: Counter({1: 5236, 0: 5236})

Jumlah keseluruhan data setelah balancing sampling :
Features (X_ros) shape: (10472, 20)
Target (y_ros) shape: (10472,)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-34-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Dan didapat data setelah dilakukan over sampling kedua kelas yakni 0 dan 1 menjadi sama sama sebanyak 5265 data. sehingga jumlah data keseluruhan menjadi 10530 data. Hasil data yang telah dilakukan balancing ini kemudian disimpan ke dalam file dengan nama data_balancing.csv</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mengonversi array NumPy ke DataFrame pandas</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>df_X_ros <span class="op">=</span> pd.DataFrame(X_ros, columns<span class="op">=</span>X.columns)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>df_y_ros <span class="op">=</span> pd.DataFrame(y_ros, columns<span class="op">=</span>[<span class="st">'is_safe'</span>])</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Menggabungkan DataFrame X_ros dan y_ros</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>df_resampled <span class="op">=</span> pd.concat([df_X_ros, df_y_ros], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan DataFrame ke dalam file Excel</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>df_resampled.to_csv(<span class="st">'data_balancing.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>df_resampled</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10467</td>
<td>1.55</td>
<td>11.30</td>
<td>0.02</td>
<td>3.14</td>
<td>0.007</td>
<td>7.52</td>
<td>0.03</td>
<td>0.10</td>
<td>1.38</td>
<td>0.00</td>
<td>...</td>
<td>0.033</td>
<td>7.43</td>
<td>1.55</td>
<td>0.007</td>
<td>19.77</td>
<td>2.42</td>
<td>0.09</td>
<td>0.26</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10468</td>
<td>0.05</td>
<td>29.28</td>
<td>0.06</td>
<td>0.40</td>
<td>0.030</td>
<td>0.07</td>
<td>0.02</td>
<td>1.05</td>
<td>0.81</td>
<td>0.00</td>
<td>...</td>
<td>0.066</td>
<td>4.62</td>
<td>0.90</td>
<td>0.000</td>
<td>2.08</td>
<td>1.80</td>
<td>0.07</td>
<td>0.09</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10469</td>
<td>0.39</td>
<td>28.28</td>
<td>0.44</td>
<td>1.74</td>
<td>0.120</td>
<td>5.14</td>
<td>0.05</td>
<td>0.03</td>
<td>1.29</td>
<td>0.43</td>
<td>...</td>
<td>0.108</td>
<td>9.90</td>
<td>1.86</td>
<td>0.004</td>
<td>29.06</td>
<td>2.12</td>
<td>0.07</td>
<td>0.07</td>
<td>0.01</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10470</td>
<td>3.12</td>
<td>18.12</td>
<td>0.03</td>
<td>3.98</td>
<td>0.006</td>
<td>1.87</td>
<td>0.07</td>
<td>0.66</td>
<td>0.04</td>
<td>0.32</td>
<td>...</td>
<td>0.028</td>
<td>8.02</td>
<td>1.07</td>
<td>0.002</td>
<td>40.27</td>
<td>1.16</td>
<td>0.00</td>
<td>0.35</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10471</td>
<td>1.14</td>
<td>17.45</td>
<td>0.35</td>
<td>1.32</td>
<td>0.040</td>
<td>1.45</td>
<td>0.38</td>
<td>0.41</td>
<td>0.72</td>
<td>0.00</td>
<td>...</td>
<td>0.020</td>
<td>1.27</td>
<td>1.55</td>
<td>0.010</td>
<td>45.06</td>
<td>2.97</td>
<td>0.06</td>
<td>0.10</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>10472 rows × 21 columns</p>
</div>
</div>
</div>
</section>
</section>
<section id="feature-scaling" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="feature-scaling"><span class="header-section-number">3.4</span> Feature Scaling</h2>
<p>Feature scaling (skala fitur) adalah teknik khusus di dalam data transformation yang mengubah nilai-nilai variabel ke dalam rentang tertentu, sehingga memastikan bahwa seluruh fitur memiliki skala yang serupa. Feature scaling sendiri bisa disebut dengan normalisasi data. dalam feature scaling kali ini saya akan memilih menggunakan metode robust scaler.</p>
<p>Metode Normalisasi Robust Scaler adalah salah satu teknik normalisasi data yang tahan terhadap outlier.<br>
Robust Scaler mengubah setiap nilai dalam suatu fitur dengan menggunakan rumus berikut: <span class="math display">\[\begin{equation}
X_{\text{scaled}} = \frac{{X - \text{median}}}{{Q_3 - Q_1}}
\end{equation}\]</span> Dimana : - Xscaled : adalah nilai yang telah diubah skala, - X : adalah nilai asli, - Q1 : adalah kuartil pertama (25th percentile), - Q3 : adalah kuartil ketiga (75th percentile), - Median : Nilai Tengah.</p>
<p>Berikut adalah proses normalisasi menggunakan Robust Scaler dan contoh kasusnya:</p>
<p>Proses Normalisasi menggunakan Robust Scaler: 1. Hitung Median dan Kuartil: - Median (Q2): Nilai tengah dari set data. - Kuartil 1 (Q1): Nilai tengah antara nilai terkecil dan median. - Kuartil 3 (Q3): Nilai tengah antara median dan nilai terbesar. 2. Hitung Rentang Interkuartil (IQR): - IQR = Q3 - Q1. 3. Hitung Skala Robust: - Skala Robust = (X - Median) / IQR. Contoh Kasus: Misalkan kita memiliki dataset sebagai berikut:</p>
<p>[10, 15, 20, 25, 30, 100]</p>
<p>Langkah-langkah Normalisasi menggunakan Robust Scaler: 1. Hitung Median (Q2): Median = 22.5 2. Hitung Kuartil 1 (Q1): Q1 = 15 3. Hitung Kuartil 3 (Q3): Q3 = 30 4. Hitung IQR: IQR = Q3 - Q1 = 15 5. Hitung Skala Robust: Skala Robust = (X - Median) / IQR - Untuk nilai 10: (10 - 22.5) / 15 = -0.8333 - Untuk nilai 15: (15 - 22.5) / 15 = -0.5 - Untuk nilai 20: (20 - 22.5) / 15 = -0.3333 - Untuk nilai 25: (25 - 22.5) / 15 = 0.1667 - Untuk nilai 30: (30 - 22.5) / 15 = 0.5 - Untuk nilai 100: (100 - 22.5) / 15 = 4.5</p>
<p>Sehingga, dataset yang telah dinormalisasi menggunakan Robust Scaler adalah:</p>
<p>[-0.8333, -0.5, -0.3333, 0.1667, 0.5, 4.5]</p>
<ul>
<li>Metode Robust Scaler ini memiliki keuntungan:
<ul>
<li>Tahan terhadap outlier: Robust Scaler lebih tahan terhadap outlier karena menggunakan informasi dari kuartil, yang kurang dipengaruhi oleh nilai ekstrem.</li>
<li>Konservatif: Dengan menggunakan median dan IQR, metode ini dapat menghasilkan normalisasi yang lebih konservatif daripada Min-Max Scaling.</li>
</ul></li>
<li>Metode Robust Scaler Cocok Digunakan Jika:
<ul>
<li>Data mengandung nilai ekstrem atau outlier.</li>
<li>Distribusi data tidak terdistribusi normal.</li>
<li>Skala fitur bervariasi secara signifikan.</li>
</ul></li>
<li>Perbandingan dengan Min-Max Scaling dan Z-Score Scaling:
<ul>
<li>Min-Max Scaling: Rentang nilai diubah menjadi 0 hingga 1. Rentang ini dapat sangat dipengaruhi oleh nilai outlier. Jika outlier signifikan, rentang nilai mungkin menjadi terlalu sempit.</li>
<li>Z-Score Scaling (Standardization): Data diubah sehingga memiliki rata-rata 0 dan deviasi standar 1. Metode ini sensitif terhadap nilai ekstrem dan tidak sebaik Robust Scaler ketika ada outlier.</li>
</ul></li>
</ul>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_balancing.csv'</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'is_safe'</span>]</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Inisialisasi RobustScaler</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>RobustScaler <span class="op">=</span> RobustScaler()</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit dan transformasi data menggunakan RobustScaler</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>df_scaled <span class="op">=</span> RobustScaler.fit_transform(X)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Membuat DataFrame baru dengan data yang telah diubah skala</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>X.columns)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> pd.DataFrame(y, columns<span class="op">=</span>[<span class="st">'is_safe'</span>])</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>datascled <span class="op">=</span> pd.concat([X, y], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>df_normalized <span class="op">=</span> pd.DataFrame(datascled)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>df_normalized.to_csv(<span class="st">'data_normalisasi.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil</span></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Original Data:"</span>)</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original Data:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="35">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10467</td>
<td>1.55</td>
<td>11.30</td>
<td>0.02</td>
<td>3.14</td>
<td>0.007</td>
<td>7.52</td>
<td>0.03</td>
<td>0.10</td>
<td>1.38</td>
<td>0.00</td>
<td>...</td>
<td>0.033</td>
<td>7.43</td>
<td>1.55</td>
<td>0.007</td>
<td>19.77</td>
<td>2.42</td>
<td>0.09</td>
<td>0.26</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10468</td>
<td>0.05</td>
<td>29.28</td>
<td>0.06</td>
<td>0.40</td>
<td>0.030</td>
<td>0.07</td>
<td>0.02</td>
<td>1.05</td>
<td>0.81</td>
<td>0.00</td>
<td>...</td>
<td>0.066</td>
<td>4.62</td>
<td>0.90</td>
<td>0.000</td>
<td>2.08</td>
<td>1.80</td>
<td>0.07</td>
<td>0.09</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10469</td>
<td>0.39</td>
<td>28.28</td>
<td>0.44</td>
<td>1.74</td>
<td>0.120</td>
<td>5.14</td>
<td>0.05</td>
<td>0.03</td>
<td>1.29</td>
<td>0.43</td>
<td>...</td>
<td>0.108</td>
<td>9.90</td>
<td>1.86</td>
<td>0.004</td>
<td>29.06</td>
<td>2.12</td>
<td>0.07</td>
<td>0.07</td>
<td>0.01</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10470</td>
<td>3.12</td>
<td>18.12</td>
<td>0.03</td>
<td>3.98</td>
<td>0.006</td>
<td>1.87</td>
<td>0.07</td>
<td>0.66</td>
<td>0.04</td>
<td>0.32</td>
<td>...</td>
<td>0.028</td>
<td>8.02</td>
<td>1.07</td>
<td>0.002</td>
<td>40.27</td>
<td>1.16</td>
<td>0.00</td>
<td>0.35</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10471</td>
<td>1.14</td>
<td>17.45</td>
<td>0.35</td>
<td>1.32</td>
<td>0.040</td>
<td>1.45</td>
<td>0.38</td>
<td>0.41</td>
<td>0.72</td>
<td>0.00</td>
<td>...</td>
<td>0.020</td>
<td>1.27</td>
<td>1.55</td>
<td>0.010</td>
<td>45.06</td>
<td>2.97</td>
<td>0.06</td>
<td>0.10</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>10472 rows × 21 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Normalized Data (Robust Scaling):"</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>df_normalized</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Normalized Data (Robust Scaling):</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="36">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10467</td>
<td>1.55</td>
<td>11.30</td>
<td>0.02</td>
<td>3.14</td>
<td>0.007</td>
<td>7.52</td>
<td>0.03</td>
<td>0.10</td>
<td>1.38</td>
<td>0.00</td>
<td>...</td>
<td>0.033</td>
<td>7.43</td>
<td>1.55</td>
<td>0.007</td>
<td>19.77</td>
<td>2.42</td>
<td>0.09</td>
<td>0.26</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10468</td>
<td>0.05</td>
<td>29.28</td>
<td>0.06</td>
<td>0.40</td>
<td>0.030</td>
<td>0.07</td>
<td>0.02</td>
<td>1.05</td>
<td>0.81</td>
<td>0.00</td>
<td>...</td>
<td>0.066</td>
<td>4.62</td>
<td>0.90</td>
<td>0.000</td>
<td>2.08</td>
<td>1.80</td>
<td>0.07</td>
<td>0.09</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10469</td>
<td>0.39</td>
<td>28.28</td>
<td>0.44</td>
<td>1.74</td>
<td>0.120</td>
<td>5.14</td>
<td>0.05</td>
<td>0.03</td>
<td>1.29</td>
<td>0.43</td>
<td>...</td>
<td>0.108</td>
<td>9.90</td>
<td>1.86</td>
<td>0.004</td>
<td>29.06</td>
<td>2.12</td>
<td>0.07</td>
<td>0.07</td>
<td>0.01</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10470</td>
<td>3.12</td>
<td>18.12</td>
<td>0.03</td>
<td>3.98</td>
<td>0.006</td>
<td>1.87</td>
<td>0.07</td>
<td>0.66</td>
<td>0.04</td>
<td>0.32</td>
<td>...</td>
<td>0.028</td>
<td>8.02</td>
<td>1.07</td>
<td>0.002</td>
<td>40.27</td>
<td>1.16</td>
<td>0.00</td>
<td>0.35</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10471</td>
<td>1.14</td>
<td>17.45</td>
<td>0.35</td>
<td>1.32</td>
<td>0.040</td>
<td>1.45</td>
<td>0.38</td>
<td>0.41</td>
<td>0.72</td>
<td>0.00</td>
<td>...</td>
<td>0.020</td>
<td>1.27</td>
<td>1.55</td>
<td>0.010</td>
<td>45.06</td>
<td>2.97</td>
<td>0.06</td>
<td>0.10</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>10472 rows × 21 columns</p>
</div>
</div>
</div>
</section>
<section id="splitting-data" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="splitting-data"><span class="header-section-number">3.5</span> Splitting Data</h2>
<p>Memisahkan dataset menjadi set pelatihan dan set pengujian untuk evaluasi model.</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_normalisasi.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'is_safe'</span>]</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="pycaret-seleksi-model" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="pycaret-seleksi-model"><span class="header-section-number">3.6</span> Pycaret Seleksi Model</h2>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pycaret.regression <span class="im">import</span> <span class="op">*</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pycaret.classification <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> setup(df, target<span class="op">=</span><span class="st">'is_safe'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_bb8f5_row8_col1 {
  background-color: lightgreen;
}
</style>

<table id="T_bb8f5" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_bb8f5_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Description</th>
<th id="T_bb8f5_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_bb8f5_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_bb8f5_row0_col0" class="data row0 col0">Session id</td>
<td id="T_bb8f5_row0_col1" class="data row0 col1">6165</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_bb8f5_row1_col0" class="data row1 col0">Target</td>
<td id="T_bb8f5_row1_col1" class="data row1 col1">is_safe</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_bb8f5_row2_col0" class="data row2 col0">Target type</td>
<td id="T_bb8f5_row2_col1" class="data row2 col1">Binary</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_bb8f5_row3_col0" class="data row3 col0">Original data shape</td>
<td id="T_bb8f5_row3_col1" class="data row3 col1">(10472, 21)</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_bb8f5_row4_col0" class="data row4 col0">Transformed data shape</td>
<td id="T_bb8f5_row4_col1" class="data row4 col1">(10472, 21)</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_bb8f5_row5_col0" class="data row5 col0">Transformed train set shape</td>
<td id="T_bb8f5_row5_col1" class="data row5 col1">(7330, 21)</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_bb8f5_row6_col0" class="data row6 col0">Transformed test set shape</td>
<td id="T_bb8f5_row6_col1" class="data row6 col1">(3142, 21)</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_bb8f5_row7_col0" class="data row7 col0">Numeric features</td>
<td id="T_bb8f5_row7_col1" class="data row7 col1">20</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_bb8f5_row8_col0" class="data row8 col0">Preprocess</td>
<td id="T_bb8f5_row8_col1" class="data row8 col1">True</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_bb8f5_row9_col0" class="data row9 col0">Imputation type</td>
<td id="T_bb8f5_row9_col1" class="data row9 col1">simple</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">10</td>
<td id="T_bb8f5_row10_col0" class="data row10 col0">Numeric imputation</td>
<td id="T_bb8f5_row10_col1" class="data row10 col1">mean</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">11</td>
<td id="T_bb8f5_row11_col0" class="data row11 col0">Categorical imputation</td>
<td id="T_bb8f5_row11_col1" class="data row11 col1">mode</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row12" class="row_heading level0 row12" data-quarto-table-cell-role="th">12</td>
<td id="T_bb8f5_row12_col0" class="data row12 col0">Fold Generator</td>
<td id="T_bb8f5_row12_col1" class="data row12 col1">StratifiedKFold</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row13" class="row_heading level0 row13" data-quarto-table-cell-role="th">13</td>
<td id="T_bb8f5_row13_col0" class="data row13 col0">Fold Number</td>
<td id="T_bb8f5_row13_col1" class="data row13 col1">10</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row14" class="row_heading level0 row14" data-quarto-table-cell-role="th">14</td>
<td id="T_bb8f5_row14_col0" class="data row14 col0">CPU Jobs</td>
<td id="T_bb8f5_row14_col1" class="data row14 col1">-1</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row15" class="row_heading level0 row15" data-quarto-table-cell-role="th">15</td>
<td id="T_bb8f5_row15_col0" class="data row15 col0">Use GPU</td>
<td id="T_bb8f5_row15_col1" class="data row15 col1">False</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row16" class="row_heading level0 row16" data-quarto-table-cell-role="th">16</td>
<td id="T_bb8f5_row16_col0" class="data row16 col0">Log Experiment</td>
<td id="T_bb8f5_row16_col1" class="data row16 col1">False</td>
</tr>
<tr class="even">
<td id="T_bb8f5_level0_row17" class="row_heading level0 row17" data-quarto-table-cell-role="th">17</td>
<td id="T_bb8f5_row17_col0" class="data row17 col0">Experiment Name</td>
<td id="T_bb8f5_row17_col1" class="data row17 col1">clf-default-name</td>
</tr>
<tr class="odd">
<td id="T_bb8f5_level0_row18" class="row_heading level0 row18" data-quarto-table-cell-role="th">18</td>
<td id="T_bb8f5_row18_col0" class="data row18 col0">USI</td>
<td id="T_bb8f5_row18_col1" class="data row18 col1">f125</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> clf.compare_models()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_14404 th {
  text-align: left;
}
#T_14404_row0_col0, #T_14404_row0_col2, #T_14404_row0_col3, #T_14404_row1_col0, #T_14404_row1_col1, #T_14404_row1_col3, #T_14404_row1_col4, #T_14404_row1_col5, #T_14404_row1_col6, #T_14404_row1_col7, #T_14404_row2_col0, #T_14404_row2_col1, #T_14404_row2_col2, #T_14404_row2_col4, #T_14404_row2_col5, #T_14404_row2_col6, #T_14404_row2_col7, #T_14404_row3_col0, #T_14404_row3_col1, #T_14404_row3_col2, #T_14404_row3_col3, #T_14404_row3_col4, #T_14404_row3_col5, #T_14404_row3_col6, #T_14404_row3_col7, #T_14404_row4_col0, #T_14404_row4_col1, #T_14404_row4_col2, #T_14404_row4_col3, #T_14404_row4_col4, #T_14404_row4_col5, #T_14404_row4_col6, #T_14404_row4_col7, #T_14404_row5_col0, #T_14404_row5_col1, #T_14404_row5_col2, #T_14404_row5_col3, #T_14404_row5_col4, #T_14404_row5_col5, #T_14404_row5_col6, #T_14404_row5_col7, #T_14404_row6_col0, #T_14404_row6_col1, #T_14404_row6_col2, #T_14404_row6_col3, #T_14404_row6_col4, #T_14404_row6_col5, #T_14404_row6_col6, #T_14404_row6_col7, #T_14404_row7_col0, #T_14404_row7_col1, #T_14404_row7_col2, #T_14404_row7_col3, #T_14404_row7_col4, #T_14404_row7_col5, #T_14404_row7_col6, #T_14404_row7_col7, #T_14404_row8_col0, #T_14404_row8_col1, #T_14404_row8_col2, #T_14404_row8_col3, #T_14404_row8_col4, #T_14404_row8_col5, #T_14404_row8_col6, #T_14404_row8_col7, #T_14404_row9_col0, #T_14404_row9_col1, #T_14404_row9_col2, #T_14404_row9_col3, #T_14404_row9_col4, #T_14404_row9_col5, #T_14404_row9_col6, #T_14404_row9_col7, #T_14404_row10_col0, #T_14404_row10_col1, #T_14404_row10_col2, #T_14404_row10_col3, #T_14404_row10_col4, #T_14404_row10_col5, #T_14404_row10_col6, #T_14404_row10_col7, #T_14404_row11_col0, #T_14404_row11_col1, #T_14404_row11_col2, #T_14404_row11_col3, #T_14404_row11_col4, #T_14404_row11_col5, #T_14404_row11_col6, #T_14404_row11_col7, #T_14404_row12_col0, #T_14404_row12_col1, #T_14404_row12_col2, #T_14404_row12_col3, #T_14404_row12_col4, #T_14404_row12_col5, #T_14404_row12_col6, #T_14404_row12_col7, #T_14404_row13_col0, #T_14404_row13_col1, #T_14404_row13_col2, #T_14404_row13_col3, #T_14404_row13_col4, #T_14404_row13_col5, #T_14404_row13_col6, #T_14404_row13_col7 {
  text-align: left;
}
#T_14404_row0_col1, #T_14404_row0_col4, #T_14404_row0_col5, #T_14404_row0_col6, #T_14404_row0_col7, #T_14404_row1_col2, #T_14404_row2_col3 {
  text-align: left;
  background-color: yellow;
}
#T_14404_row0_col8, #T_14404_row1_col8, #T_14404_row2_col8, #T_14404_row3_col8, #T_14404_row4_col8, #T_14404_row5_col8, #T_14404_row6_col8, #T_14404_row7_col8, #T_14404_row8_col8, #T_14404_row10_col8, #T_14404_row11_col8, #T_14404_row12_col8, #T_14404_row13_col8 {
  text-align: left;
  background-color: lightgrey;
}
#T_14404_row9_col8 {
  text-align: left;
  background-color: yellow;
  background-color: lightgrey;
}
</style>

<table id="T_14404" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_14404_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Model</th>
<th id="T_14404_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Accuracy</th>
<th id="T_14404_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">AUC</th>
<th id="T_14404_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Recall</th>
<th id="T_14404_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">Prec.</th>
<th id="T_14404_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">F1</th>
<th id="T_14404_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">Kappa</th>
<th id="T_14404_level0_col7" class="col_heading level0 col7" data-quarto-table-cell-role="th">MCC</th>
<th id="T_14404_level0_col8" class="col_heading level0 col8" data-quarto-table-cell-role="th">TT (Sec)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_14404_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">et</td>
<td id="T_14404_row0_col0" class="data row0 col0">Extra Trees Classifier</td>
<td id="T_14404_row0_col1" class="data row0 col1">0.9854</td>
<td id="T_14404_row0_col2" class="data row0 col2">0.9991</td>
<td id="T_14404_row0_col3" class="data row0 col3">0.9937</td>
<td id="T_14404_row0_col4" class="data row0 col4">0.9775</td>
<td id="T_14404_row0_col5" class="data row0 col5">0.9855</td>
<td id="T_14404_row0_col6" class="data row0 col6">0.9708</td>
<td id="T_14404_row0_col7" class="data row0 col7">0.9710</td>
<td id="T_14404_row0_col8" class="data row0 col8">2.1500</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">rf</td>
<td id="T_14404_row1_col0" class="data row1 col0">Random Forest Classifier</td>
<td id="T_14404_row1_col1" class="data row1 col1">0.9839</td>
<td id="T_14404_row1_col2" class="data row1 col2">0.9996</td>
<td id="T_14404_row1_col3" class="data row1 col3">0.9967</td>
<td id="T_14404_row1_col4" class="data row1 col4">0.9718</td>
<td id="T_14404_row1_col5" class="data row1 col5">0.9841</td>
<td id="T_14404_row1_col6" class="data row1 col6">0.9678</td>
<td id="T_14404_row1_col7" class="data row1 col7">0.9682</td>
<td id="T_14404_row1_col8" class="data row1 col8">2.7610</td>
</tr>
<tr class="odd">
<td id="T_14404_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">lightgbm</td>
<td id="T_14404_row2_col0" class="data row2 col0">Light Gradient Boosting Machine</td>
<td id="T_14404_row2_col1" class="data row2 col1">0.9835</td>
<td id="T_14404_row2_col2" class="data row2 col2">0.9989</td>
<td id="T_14404_row2_col3" class="data row2 col3">0.9984</td>
<td id="T_14404_row2_col4" class="data row2 col4">0.9696</td>
<td id="T_14404_row2_col5" class="data row2 col5">0.9837</td>
<td id="T_14404_row2_col6" class="data row2 col6">0.9670</td>
<td id="T_14404_row2_col7" class="data row2 col7">0.9674</td>
<td id="T_14404_row2_col8" class="data row2 col8">1.7530</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">dt</td>
<td id="T_14404_row3_col0" class="data row3 col0">Decision Tree Classifier</td>
<td id="T_14404_row3_col1" class="data row3 col1">0.9798</td>
<td id="T_14404_row3_col2" class="data row3 col2">0.9798</td>
<td id="T_14404_row3_col3" class="data row3 col3">0.9978</td>
<td id="T_14404_row3_col4" class="data row3 col4">0.9632</td>
<td id="T_14404_row3_col5" class="data row3 col5">0.9802</td>
<td id="T_14404_row3_col6" class="data row3 col6">0.9596</td>
<td id="T_14404_row3_col7" class="data row3 col7">0.9603</td>
<td id="T_14404_row3_col8" class="data row3 col8">0.1410</td>
</tr>
<tr class="odd">
<td id="T_14404_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">gbc</td>
<td id="T_14404_row4_col0" class="data row4 col0">Gradient Boosting Classifier</td>
<td id="T_14404_row4_col1" class="data row4 col1">0.9524</td>
<td id="T_14404_row4_col2" class="data row4 col2">0.9897</td>
<td id="T_14404_row4_col3" class="data row4 col3">0.9744</td>
<td id="T_14404_row4_col4" class="data row4 col4">0.9335</td>
<td id="T_14404_row4_col5" class="data row4 col5">0.9534</td>
<td id="T_14404_row4_col6" class="data row4 col6">0.9048</td>
<td id="T_14404_row4_col7" class="data row4 col7">0.9058</td>
<td id="T_14404_row4_col8" class="data row4 col8">14.4960</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">ada</td>
<td id="T_14404_row5_col0" class="data row5 col0">Ada Boost Classifier</td>
<td id="T_14404_row5_col1" class="data row5 col1">0.8774</td>
<td id="T_14404_row5_col2" class="data row5 col2">0.9541</td>
<td id="T_14404_row5_col3" class="data row5 col3">0.8707</td>
<td id="T_14404_row5_col4" class="data row5 col4">0.8825</td>
<td id="T_14404_row5_col5" class="data row5 col5">0.8765</td>
<td id="T_14404_row5_col6" class="data row5 col6">0.7547</td>
<td id="T_14404_row5_col7" class="data row5 col7">0.7549</td>
<td id="T_14404_row5_col8" class="data row5 col8">4.4750</td>
</tr>
<tr class="odd">
<td id="T_14404_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">qda</td>
<td id="T_14404_row6_col0" class="data row6 col0">Quadratic Discriminant Analysis</td>
<td id="T_14404_row6_col1" class="data row6 col1">0.8308</td>
<td id="T_14404_row6_col2" class="data row6 col2">0.9030</td>
<td id="T_14404_row6_col3" class="data row6 col3">0.8701</td>
<td id="T_14404_row6_col4" class="data row6 col4">0.8068</td>
<td id="T_14404_row6_col5" class="data row6 col5">0.8372</td>
<td id="T_14404_row6_col6" class="data row6 col6">0.6617</td>
<td id="T_14404_row6_col7" class="data row6 col7">0.6638</td>
<td id="T_14404_row6_col8" class="data row6 col8">0.1070</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">knn</td>
<td id="T_14404_row7_col0" class="data row7 col0">K Neighbors Classifier</td>
<td id="T_14404_row7_col1" class="data row7 col1">0.8267</td>
<td id="T_14404_row7_col2" class="data row7 col2">0.8966</td>
<td id="T_14404_row7_col3" class="data row7 col3">0.9460</td>
<td id="T_14404_row7_col4" class="data row7 col4">0.7641</td>
<td id="T_14404_row7_col5" class="data row7 col5">0.8453</td>
<td id="T_14404_row7_col6" class="data row7 col6">0.6535</td>
<td id="T_14404_row7_col7" class="data row7 col7">0.6730</td>
<td id="T_14404_row7_col8" class="data row7 col8">0.2130</td>
</tr>
<tr class="odd">
<td id="T_14404_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">lda</td>
<td id="T_14404_row8_col0" class="data row8 col0">Linear Discriminant Analysis</td>
<td id="T_14404_row8_col1" class="data row8 col1">0.7917</td>
<td id="T_14404_row8_col2" class="data row8 col2">0.8640</td>
<td id="T_14404_row8_col3" class="data row8 col3">0.7905</td>
<td id="T_14404_row8_col4" class="data row8 col4">0.7928</td>
<td id="T_14404_row8_col5" class="data row8 col5">0.7914</td>
<td id="T_14404_row8_col6" class="data row8 col6">0.5834</td>
<td id="T_14404_row8_col7" class="data row8 col7">0.5837</td>
<td id="T_14404_row8_col8" class="data row8 col8">0.1850</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">ridge</td>
<td id="T_14404_row9_col0" class="data row9 col0">Ridge Classifier</td>
<td id="T_14404_row9_col1" class="data row9 col1">0.7906</td>
<td id="T_14404_row9_col2" class="data row9 col2">0.0000</td>
<td id="T_14404_row9_col3" class="data row9 col3">0.7812</td>
<td id="T_14404_row9_col4" class="data row9 col4">0.7965</td>
<td id="T_14404_row9_col5" class="data row9 col5">0.7886</td>
<td id="T_14404_row9_col6" class="data row9 col6">0.5812</td>
<td id="T_14404_row9_col7" class="data row9 col7">0.5816</td>
<td id="T_14404_row9_col8" class="data row9 col8">0.0470</td>
</tr>
<tr class="odd">
<td id="T_14404_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">nb</td>
<td id="T_14404_row10_col0" class="data row10 col0">Naive Bayes</td>
<td id="T_14404_row10_col1" class="data row10 col1">0.7831</td>
<td id="T_14404_row10_col2" class="data row10 col2">0.8283</td>
<td id="T_14404_row10_col3" class="data row10 col3">0.8226</td>
<td id="T_14404_row10_col4" class="data row10 col4">0.7624</td>
<td id="T_14404_row10_col5" class="data row10 col5">0.7913</td>
<td id="T_14404_row10_col6" class="data row10 col6">0.5662</td>
<td id="T_14404_row10_col7" class="data row10 col7">0.5681</td>
<td id="T_14404_row10_col8" class="data row10 col8">0.0790</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">lr</td>
<td id="T_14404_row11_col0" class="data row11 col0">Logistic Regression</td>
<td id="T_14404_row11_col1" class="data row11 col1">0.7791</td>
<td id="T_14404_row11_col2" class="data row11 col2">0.8607</td>
<td id="T_14404_row11_col3" class="data row11 col3">0.7528</td>
<td id="T_14404_row11_col4" class="data row11 col4">0.7950</td>
<td id="T_14404_row11_col5" class="data row11 col5">0.7731</td>
<td id="T_14404_row11_col6" class="data row11 col6">0.5583</td>
<td id="T_14404_row11_col7" class="data row11 col7">0.5594</td>
<td id="T_14404_row11_col8" class="data row11 col8">2.4650</td>
</tr>
<tr class="odd">
<td id="T_14404_level0_row12" class="row_heading level0 row12" data-quarto-table-cell-role="th">svm</td>
<td id="T_14404_row12_col0" class="data row12 col0">SVM - Linear Kernel</td>
<td id="T_14404_row12_col1" class="data row12 col1">0.6879</td>
<td id="T_14404_row12_col2" class="data row12 col2">0.0000</td>
<td id="T_14404_row12_col3" class="data row12 col3">0.5977</td>
<td id="T_14404_row12_col4" class="data row12 col4">0.7870</td>
<td id="T_14404_row12_col5" class="data row12 col5">0.6204</td>
<td id="T_14404_row12_col6" class="data row12 col6">0.3759</td>
<td id="T_14404_row12_col7" class="data row12 col7">0.4159</td>
<td id="T_14404_row12_col8" class="data row12 col8">0.1510</td>
</tr>
<tr class="even">
<td id="T_14404_level0_row13" class="row_heading level0 row13" data-quarto-table-cell-role="th">dummy</td>
<td id="T_14404_row13_col0" class="data row13 col0">Dummy Classifier</td>
<td id="T_14404_row13_col1" class="data row13 col1">0.4993</td>
<td id="T_14404_row13_col2" class="data row13 col2">0.5000</td>
<td id="T_14404_row13_col3" class="data row13 col3">0.5000</td>
<td id="T_14404_row13_col4" class="data row13 col4">0.2497</td>
<td id="T_14404_row13_col5" class="data row13 col5">0.3330</td>
<td id="T_14404_row13_col6" class="data row13 col6">0.0000</td>
<td id="T_14404_row13_col7" class="data row13 col7">0.0000</td>
<td id="T_14404_row13_col8" class="data row13 col8">0.0760</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
<section id="light-gradient-boosting-machine" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="light-gradient-boosting-machine"><span class="header-section-number">3.6.1</span> Light Gradient Boosting Machine</h3>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>lightgbm <span class="op">=</span> create_model(<span class="st">'lightgbm'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_cf9a2_row10_col0, #T_cf9a2_row10_col1, #T_cf9a2_row10_col2, #T_cf9a2_row10_col3, #T_cf9a2_row10_col4, #T_cf9a2_row10_col5, #T_cf9a2_row10_col6 {
  background: yellow;
}
</style>

<table id="T_cf9a2" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_cf9a2_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Accuracy</th>
<th id="T_cf9a2_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">AUC</th>
<th id="T_cf9a2_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Recall</th>
<th id="T_cf9a2_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Prec.</th>
<th id="T_cf9a2_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">F1</th>
<th id="T_cf9a2_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">Kappa</th>
<th id="T_cf9a2_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">MCC</th>
</tr>
<tr class="odd">
<th class="index_name level0" data-quarto-table-cell-role="th">Fold</th>
<th class="blank col0" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col1" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col2" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col3" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col4" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col5" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col6" data-quarto-table-cell-role="th">&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_cf9a2_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_cf9a2_row0_col0" class="data row0 col0">0.9850</td>
<td id="T_cf9a2_row0_col1" class="data row0 col1">0.9991</td>
<td id="T_cf9a2_row0_col2" class="data row0 col2">1.0000</td>
<td id="T_cf9a2_row0_col3" class="data row0 col3">0.9709</td>
<td id="T_cf9a2_row0_col4" class="data row0 col4">0.9852</td>
<td id="T_cf9a2_row0_col5" class="data row0 col5">0.9700</td>
<td id="T_cf9a2_row0_col6" class="data row0 col6">0.9704</td>
</tr>
<tr class="even">
<td id="T_cf9a2_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_cf9a2_row1_col0" class="data row1 col0">0.9768</td>
<td id="T_cf9a2_row1_col1" class="data row1 col1">0.9978</td>
<td id="T_cf9a2_row1_col2" class="data row1 col2">1.0000</td>
<td id="T_cf9a2_row1_col3" class="data row1 col3">0.9557</td>
<td id="T_cf9a2_row1_col4" class="data row1 col4">0.9774</td>
<td id="T_cf9a2_row1_col5" class="data row1 col5">0.9536</td>
<td id="T_cf9a2_row1_col6" class="data row1 col6">0.9546</td>
</tr>
<tr class="odd">
<td id="T_cf9a2_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_cf9a2_row2_col0" class="data row2 col0">0.9795</td>
<td id="T_cf9a2_row2_col1" class="data row2 col1">0.9997</td>
<td id="T_cf9a2_row2_col2" class="data row2 col2">1.0000</td>
<td id="T_cf9a2_row2_col3" class="data row2 col3">0.9607</td>
<td id="T_cf9a2_row2_col4" class="data row2 col4">0.9800</td>
<td id="T_cf9a2_row2_col5" class="data row2 col5">0.9591</td>
<td id="T_cf9a2_row2_col6" class="data row2 col6">0.9599</td>
</tr>
<tr class="even">
<td id="T_cf9a2_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_cf9a2_row3_col0" class="data row3 col0">0.9823</td>
<td id="T_cf9a2_row3_col1" class="data row3 col1">0.9993</td>
<td id="T_cf9a2_row3_col2" class="data row3 col2">0.9918</td>
<td id="T_cf9a2_row3_col3" class="data row3 col3">0.9733</td>
<td id="T_cf9a2_row3_col4" class="data row3 col4">0.9825</td>
<td id="T_cf9a2_row3_col5" class="data row3 col5">0.9645</td>
<td id="T_cf9a2_row3_col6" class="data row3 col6">0.9647</td>
</tr>
<tr class="odd">
<td id="T_cf9a2_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_cf9a2_row4_col0" class="data row4 col0">0.9864</td>
<td id="T_cf9a2_row4_col1" class="data row4 col1">0.9989</td>
<td id="T_cf9a2_row4_col2" class="data row4 col2">1.0000</td>
<td id="T_cf9a2_row4_col3" class="data row4 col3">0.9735</td>
<td id="T_cf9a2_row4_col4" class="data row4 col4">0.9866</td>
<td id="T_cf9a2_row4_col5" class="data row4 col5">0.9727</td>
<td id="T_cf9a2_row4_col6" class="data row4 col6">0.9731</td>
</tr>
<tr class="even">
<td id="T_cf9a2_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_cf9a2_row5_col0" class="data row5 col0">0.9877</td>
<td id="T_cf9a2_row5_col1" class="data row5 col1">0.9997</td>
<td id="T_cf9a2_row5_col2" class="data row5 col2">0.9973</td>
<td id="T_cf9a2_row5_col3" class="data row5 col3">0.9786</td>
<td id="T_cf9a2_row5_col4" class="data row5 col4">0.9878</td>
<td id="T_cf9a2_row5_col5" class="data row5 col5">0.9754</td>
<td id="T_cf9a2_row5_col6" class="data row5 col6">0.9756</td>
</tr>
<tr class="odd">
<td id="T_cf9a2_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_cf9a2_row6_col0" class="data row6 col0">0.9836</td>
<td id="T_cf9a2_row6_col1" class="data row6 col1">0.9983</td>
<td id="T_cf9a2_row6_col2" class="data row6 col2">0.9973</td>
<td id="T_cf9a2_row6_col3" class="data row6 col3">0.9707</td>
<td id="T_cf9a2_row6_col4" class="data row6 col4">0.9838</td>
<td id="T_cf9a2_row6_col5" class="data row6 col5">0.9673</td>
<td id="T_cf9a2_row6_col6" class="data row6 col6">0.9676</td>
</tr>
<tr class="even">
<td id="T_cf9a2_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_cf9a2_row7_col0" class="data row7 col0">0.9823</td>
<td id="T_cf9a2_row7_col1" class="data row7 col1">0.9982</td>
<td id="T_cf9a2_row7_col2" class="data row7 col2">0.9973</td>
<td id="T_cf9a2_row7_col3" class="data row7 col3">0.9682</td>
<td id="T_cf9a2_row7_col4" class="data row7 col4">0.9825</td>
<td id="T_cf9a2_row7_col5" class="data row7 col5">0.9645</td>
<td id="T_cf9a2_row7_col6" class="data row7 col6">0.9650</td>
</tr>
<tr class="odd">
<td id="T_cf9a2_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_cf9a2_row8_col0" class="data row8 col0">0.9877</td>
<td id="T_cf9a2_row8_col1" class="data row8 col1">0.9985</td>
<td id="T_cf9a2_row8_col2" class="data row8 col2">1.0000</td>
<td id="T_cf9a2_row8_col3" class="data row8 col3">0.9760</td>
<td id="T_cf9a2_row8_col4" class="data row8 col4">0.9879</td>
<td id="T_cf9a2_row8_col5" class="data row8 col5">0.9754</td>
<td id="T_cf9a2_row8_col6" class="data row8 col6">0.9757</td>
</tr>
<tr class="even">
<td id="T_cf9a2_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_cf9a2_row9_col0" class="data row9 col0">0.9836</td>
<td id="T_cf9a2_row9_col1" class="data row9 col1">0.9996</td>
<td id="T_cf9a2_row9_col2" class="data row9 col2">1.0000</td>
<td id="T_cf9a2_row9_col3" class="data row9 col3">0.9683</td>
<td id="T_cf9a2_row9_col4" class="data row9 col4">0.9839</td>
<td id="T_cf9a2_row9_col5" class="data row9 col5">0.9673</td>
<td id="T_cf9a2_row9_col6" class="data row9 col6">0.9678</td>
</tr>
<tr class="odd">
<td id="T_cf9a2_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">Mean</td>
<td id="T_cf9a2_row10_col0" class="data row10 col0">0.9835</td>
<td id="T_cf9a2_row10_col1" class="data row10 col1">0.9989</td>
<td id="T_cf9a2_row10_col2" class="data row10 col2">0.9984</td>
<td id="T_cf9a2_row10_col3" class="data row10 col3">0.9696</td>
<td id="T_cf9a2_row10_col4" class="data row10 col4">0.9837</td>
<td id="T_cf9a2_row10_col5" class="data row10 col5">0.9670</td>
<td id="T_cf9a2_row10_col6" class="data row10 col6">0.9674</td>
</tr>
<tr class="even">
<td id="T_cf9a2_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">Std</td>
<td id="T_cf9a2_row11_col0" class="data row11 col0">0.0033</td>
<td id="T_cf9a2_row11_col1" class="data row11 col1">0.0006</td>
<td id="T_cf9a2_row11_col2" class="data row11 col2">0.0025</td>
<td id="T_cf9a2_row11_col3" class="data row11 col3">0.0065</td>
<td id="T_cf9a2_row11_col4" class="data row11 col4">0.0032</td>
<td id="T_cf9a2_row11_col5" class="data row11 col5">0.0066</td>
<td id="T_cf9a2_row11_col6" class="data row11 col6">0.0064</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
</section>
<section id="gradient-boosting-classifier" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="gradient-boosting-classifier"><span class="header-section-number">3.6.2</span> Gradient Boosting Classifier</h3>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>gbc <span class="op">=</span> create_model(<span class="st">'gbc'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_59b05_row10_col0, #T_59b05_row10_col1, #T_59b05_row10_col2, #T_59b05_row10_col3, #T_59b05_row10_col4, #T_59b05_row10_col5, #T_59b05_row10_col6 {
  background: yellow;
}
</style>

<table id="T_59b05" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_59b05_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Accuracy</th>
<th id="T_59b05_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">AUC</th>
<th id="T_59b05_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Recall</th>
<th id="T_59b05_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Prec.</th>
<th id="T_59b05_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">F1</th>
<th id="T_59b05_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">Kappa</th>
<th id="T_59b05_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">MCC</th>
</tr>
<tr class="odd">
<th class="index_name level0" data-quarto-table-cell-role="th">Fold</th>
<th class="blank col0" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col1" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col2" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col3" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col4" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col5" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col6" data-quarto-table-cell-role="th">&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_59b05_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_59b05_row0_col0" class="data row0 col0">0.9591</td>
<td id="T_59b05_row0_col1" class="data row0 col1">0.9925</td>
<td id="T_59b05_row0_col2" class="data row0 col2">0.9700</td>
<td id="T_59b05_row0_col3" class="data row0 col3">0.9493</td>
<td id="T_59b05_row0_col4" class="data row0 col4">0.9596</td>
<td id="T_59b05_row0_col5" class="data row0 col5">0.9181</td>
<td id="T_59b05_row0_col6" class="data row0 col6">0.9184</td>
</tr>
<tr class="even">
<td id="T_59b05_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_59b05_row1_col0" class="data row1 col0">0.9386</td>
<td id="T_59b05_row1_col1" class="data row1 col1">0.9847</td>
<td id="T_59b05_row1_col2" class="data row1 col2">0.9564</td>
<td id="T_59b05_row1_col3" class="data row1 col3">0.9237</td>
<td id="T_59b05_row1_col4" class="data row1 col4">0.9398</td>
<td id="T_59b05_row1_col5" class="data row1 col5">0.8772</td>
<td id="T_59b05_row1_col6" class="data row1 col6">0.8778</td>
</tr>
<tr class="odd">
<td id="T_59b05_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_59b05_row2_col0" class="data row2 col0">0.9495</td>
<td id="T_59b05_row2_col1" class="data row2 col1">0.9906</td>
<td id="T_59b05_row2_col2" class="data row2 col2">0.9782</td>
<td id="T_59b05_row2_col3" class="data row2 col3">0.9253</td>
<td id="T_59b05_row2_col4" class="data row2 col4">0.9510</td>
<td id="T_59b05_row2_col5" class="data row2 col5">0.8990</td>
<td id="T_59b05_row2_col6" class="data row2 col6">0.9005</td>
</tr>
<tr class="even">
<td id="T_59b05_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_59b05_row3_col0" class="data row3 col0">0.9523</td>
<td id="T_59b05_row3_col1" class="data row3 col1">0.9927</td>
<td id="T_59b05_row3_col2" class="data row3 col2">0.9646</td>
<td id="T_59b05_row3_col3" class="data row3 col3">0.9415</td>
<td id="T_59b05_row3_col4" class="data row3 col4">0.9529</td>
<td id="T_59b05_row3_col5" class="data row3 col5">0.9045</td>
<td id="T_59b05_row3_col6" class="data row3 col6">0.9048</td>
</tr>
<tr class="odd">
<td id="T_59b05_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_59b05_row4_col0" class="data row4 col0">0.9482</td>
<td id="T_59b05_row4_col1" class="data row4 col1">0.9851</td>
<td id="T_59b05_row4_col2" class="data row4 col2">0.9728</td>
<td id="T_59b05_row4_col3" class="data row4 col3">0.9273</td>
<td id="T_59b05_row4_col4" class="data row4 col4">0.9495</td>
<td id="T_59b05_row4_col5" class="data row4 col5">0.8963</td>
<td id="T_59b05_row4_col6" class="data row4 col6">0.8974</td>
</tr>
<tr class="even">
<td id="T_59b05_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_59b05_row5_col0" class="data row5 col0">0.9563</td>
<td id="T_59b05_row5_col1" class="data row5 col1">0.9932</td>
<td id="T_59b05_row5_col2" class="data row5 col2">0.9699</td>
<td id="T_59b05_row5_col3" class="data row5 col3">0.9441</td>
<td id="T_59b05_row5_col4" class="data row5 col4">0.9569</td>
<td id="T_59b05_row5_col5" class="data row5 col5">0.9127</td>
<td id="T_59b05_row5_col6" class="data row5 col6">0.9130</td>
</tr>
<tr class="odd">
<td id="T_59b05_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_59b05_row6_col0" class="data row6 col0">0.9577</td>
<td id="T_59b05_row6_col1" class="data row6 col1">0.9879</td>
<td id="T_59b05_row6_col2" class="data row6 col2">0.9863</td>
<td id="T_59b05_row6_col3" class="data row6 col3">0.9328</td>
<td id="T_59b05_row6_col4" class="data row6 col4">0.9588</td>
<td id="T_59b05_row6_col5" class="data row6 col5">0.9154</td>
<td id="T_59b05_row6_col6" class="data row6 col6">0.9169</td>
</tr>
<tr class="even">
<td id="T_59b05_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_59b05_row7_col0" class="data row7 col0">0.9563</td>
<td id="T_59b05_row7_col1" class="data row7 col1">0.9903</td>
<td id="T_59b05_row7_col2" class="data row7 col2">0.9809</td>
<td id="T_59b05_row7_col3" class="data row7 col3">0.9349</td>
<td id="T_59b05_row7_col4" class="data row7 col4">0.9573</td>
<td id="T_59b05_row7_col5" class="data row7 col5">0.9127</td>
<td id="T_59b05_row7_col6" class="data row7 col6">0.9138</td>
</tr>
<tr class="odd">
<td id="T_59b05_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_59b05_row8_col0" class="data row8 col0">0.9536</td>
<td id="T_59b05_row8_col1" class="data row8 col1">0.9917</td>
<td id="T_59b05_row8_col2" class="data row8 col2">0.9727</td>
<td id="T_59b05_row8_col3" class="data row8 col3">0.9368</td>
<td id="T_59b05_row8_col4" class="data row8 col4">0.9544</td>
<td id="T_59b05_row8_col5" class="data row8 col5">0.9072</td>
<td id="T_59b05_row8_col6" class="data row8 col6">0.9079</td>
</tr>
<tr class="even">
<td id="T_59b05_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_59b05_row9_col0" class="data row9 col0">0.9523</td>
<td id="T_59b05_row9_col1" class="data row9 col1">0.9887</td>
<td id="T_59b05_row9_col2" class="data row9 col2">0.9918</td>
<td id="T_59b05_row9_col3" class="data row9 col3">0.9190</td>
<td id="T_59b05_row9_col4" class="data row9 col4">0.9540</td>
<td id="T_59b05_row9_col5" class="data row9 col5">0.9045</td>
<td id="T_59b05_row9_col6" class="data row9 col6">0.9074</td>
</tr>
<tr class="odd">
<td id="T_59b05_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">Mean</td>
<td id="T_59b05_row10_col0" class="data row10 col0">0.9524</td>
<td id="T_59b05_row10_col1" class="data row10 col1">0.9897</td>
<td id="T_59b05_row10_col2" class="data row10 col2">0.9744</td>
<td id="T_59b05_row10_col3" class="data row10 col3">0.9335</td>
<td id="T_59b05_row10_col4" class="data row10 col4">0.9534</td>
<td id="T_59b05_row10_col5" class="data row10 col5">0.9048</td>
<td id="T_59b05_row10_col6" class="data row10 col6">0.9058</td>
</tr>
<tr class="even">
<td id="T_59b05_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">Std</td>
<td id="T_59b05_row11_col0" class="data row11 col0">0.0057</td>
<td id="T_59b05_row11_col1" class="data row11 col1">0.0029</td>
<td id="T_59b05_row11_col2" class="data row11 col2">0.0098</td>
<td id="T_59b05_row11_col3" class="data row11 col3">0.0092</td>
<td id="T_59b05_row11_col4" class="data row11 col4">0.0055</td>
<td id="T_59b05_row11_col5" class="data row11 col5">0.0113</td>
<td id="T_59b05_row11_col6" class="data row11 col6">0.0114</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
</section>
<section id="random-forest" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="random-forest"><span class="header-section-number">3.6.3</span> Random Forest</h3>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> create_model(<span class="st">'rf'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_3804f_row10_col0, #T_3804f_row10_col1, #T_3804f_row10_col2, #T_3804f_row10_col3, #T_3804f_row10_col4, #T_3804f_row10_col5, #T_3804f_row10_col6 {
  background: yellow;
}
</style>

<table id="T_3804f" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_3804f_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Accuracy</th>
<th id="T_3804f_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">AUC</th>
<th id="T_3804f_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Recall</th>
<th id="T_3804f_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Prec.</th>
<th id="T_3804f_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">F1</th>
<th id="T_3804f_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">Kappa</th>
<th id="T_3804f_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">MCC</th>
</tr>
<tr class="odd">
<th class="index_name level0" data-quarto-table-cell-role="th">Fold</th>
<th class="blank col0" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col1" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col2" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col3" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col4" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col5" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col6" data-quarto-table-cell-role="th">&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_3804f_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_3804f_row0_col0" class="data row0 col0">0.9864</td>
<td id="T_3804f_row0_col1" class="data row0 col1">0.9999</td>
<td id="T_3804f_row0_col2" class="data row0 col2">0.9973</td>
<td id="T_3804f_row0_col3" class="data row0 col3">0.9760</td>
<td id="T_3804f_row0_col4" class="data row0 col4">0.9865</td>
<td id="T_3804f_row0_col5" class="data row0 col5">0.9727</td>
<td id="T_3804f_row0_col6" class="data row0 col6">0.9729</td>
</tr>
<tr class="even">
<td id="T_3804f_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_3804f_row1_col0" class="data row1 col0">0.9795</td>
<td id="T_3804f_row1_col1" class="data row1 col1">0.9997</td>
<td id="T_3804f_row1_col2" class="data row1 col2">1.0000</td>
<td id="T_3804f_row1_col3" class="data row1 col3">0.9607</td>
<td id="T_3804f_row1_col4" class="data row1 col4">0.9800</td>
<td id="T_3804f_row1_col5" class="data row1 col5">0.9591</td>
<td id="T_3804f_row1_col6" class="data row1 col6">0.9599</td>
</tr>
<tr class="odd">
<td id="T_3804f_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_3804f_row2_col0" class="data row2 col0">0.9850</td>
<td id="T_3804f_row2_col1" class="data row2 col1">0.9997</td>
<td id="T_3804f_row2_col2" class="data row2 col2">0.9973</td>
<td id="T_3804f_row2_col3" class="data row2 col3">0.9734</td>
<td id="T_3804f_row2_col4" class="data row2 col4">0.9852</td>
<td id="T_3804f_row2_col5" class="data row2 col5">0.9700</td>
<td id="T_3804f_row2_col6" class="data row2 col6">0.9703</td>
</tr>
<tr class="even">
<td id="T_3804f_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_3804f_row3_col0" class="data row3 col0">0.9850</td>
<td id="T_3804f_row3_col1" class="data row3 col1">0.9991</td>
<td id="T_3804f_row3_col2" class="data row3 col2">0.9891</td>
<td id="T_3804f_row3_col3" class="data row3 col3">0.9811</td>
<td id="T_3804f_row3_col4" class="data row3 col4">0.9851</td>
<td id="T_3804f_row3_col5" class="data row3 col5">0.9700</td>
<td id="T_3804f_row3_col6" class="data row3 col6">0.9700</td>
</tr>
<tr class="odd">
<td id="T_3804f_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_3804f_row4_col0" class="data row4 col0">0.9850</td>
<td id="T_3804f_row4_col1" class="data row4 col1">0.9998</td>
<td id="T_3804f_row4_col2" class="data row4 col2">1.0000</td>
<td id="T_3804f_row4_col3" class="data row4 col3">0.9709</td>
<td id="T_3804f_row4_col4" class="data row4 col4">0.9852</td>
<td id="T_3804f_row4_col5" class="data row4 col5">0.9700</td>
<td id="T_3804f_row4_col6" class="data row4 col6">0.9704</td>
</tr>
<tr class="even">
<td id="T_3804f_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_3804f_row5_col0" class="data row5 col0">0.9891</td>
<td id="T_3804f_row5_col1" class="data row5 col1">0.9999</td>
<td id="T_3804f_row5_col2" class="data row5 col2">1.0000</td>
<td id="T_3804f_row5_col3" class="data row5 col3">0.9786</td>
<td id="T_3804f_row5_col4" class="data row5 col4">0.9892</td>
<td id="T_3804f_row5_col5" class="data row5 col5">0.9782</td>
<td id="T_3804f_row5_col6" class="data row5 col6">0.9784</td>
</tr>
<tr class="odd">
<td id="T_3804f_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_3804f_row6_col0" class="data row6 col0">0.9795</td>
<td id="T_3804f_row6_col1" class="data row6 col1">0.9988</td>
<td id="T_3804f_row6_col2" class="data row6 col2">0.9918</td>
<td id="T_3804f_row6_col3" class="data row6 col3">0.9680</td>
<td id="T_3804f_row6_col4" class="data row6 col4">0.9798</td>
<td id="T_3804f_row6_col5" class="data row6 col5">0.9591</td>
<td id="T_3804f_row6_col6" class="data row6 col6">0.9594</td>
</tr>
<tr class="even">
<td id="T_3804f_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_3804f_row7_col0" class="data row7 col0">0.9795</td>
<td id="T_3804f_row7_col1" class="data row7 col1">0.9995</td>
<td id="T_3804f_row7_col2" class="data row7 col2">0.9918</td>
<td id="T_3804f_row7_col3" class="data row7 col3">0.9680</td>
<td id="T_3804f_row7_col4" class="data row7 col4">0.9798</td>
<td id="T_3804f_row7_col5" class="data row7 col5">0.9591</td>
<td id="T_3804f_row7_col6" class="data row7 col6">0.9594</td>
</tr>
<tr class="odd">
<td id="T_3804f_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_3804f_row8_col0" class="data row8 col0">0.9877</td>
<td id="T_3804f_row8_col1" class="data row8 col1">0.9999</td>
<td id="T_3804f_row8_col2" class="data row8 col2">1.0000</td>
<td id="T_3804f_row8_col3" class="data row8 col3">0.9760</td>
<td id="T_3804f_row8_col4" class="data row8 col4">0.9879</td>
<td id="T_3804f_row8_col5" class="data row8 col5">0.9754</td>
<td id="T_3804f_row8_col6" class="data row8 col6">0.9757</td>
</tr>
<tr class="even">
<td id="T_3804f_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_3804f_row9_col0" class="data row9 col0">0.9823</td>
<td id="T_3804f_row9_col1" class="data row9 col1">0.9999</td>
<td id="T_3804f_row9_col2" class="data row9 col2">1.0000</td>
<td id="T_3804f_row9_col3" class="data row9 col3">0.9657</td>
<td id="T_3804f_row9_col4" class="data row9 col4">0.9826</td>
<td id="T_3804f_row9_col5" class="data row9 col5">0.9645</td>
<td id="T_3804f_row9_col6" class="data row9 col6">0.9651</td>
</tr>
<tr class="odd">
<td id="T_3804f_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">Mean</td>
<td id="T_3804f_row10_col0" class="data row10 col0">0.9839</td>
<td id="T_3804f_row10_col1" class="data row10 col1">0.9996</td>
<td id="T_3804f_row10_col2" class="data row10 col2">0.9967</td>
<td id="T_3804f_row10_col3" class="data row10 col3">0.9718</td>
<td id="T_3804f_row10_col4" class="data row10 col4">0.9841</td>
<td id="T_3804f_row10_col5" class="data row10 col5">0.9678</td>
<td id="T_3804f_row10_col6" class="data row10 col6">0.9682</td>
</tr>
<tr class="even">
<td id="T_3804f_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">Std</td>
<td id="T_3804f_row11_col0" class="data row11 col0">0.0033</td>
<td id="T_3804f_row11_col1" class="data row11 col1">0.0004</td>
<td id="T_3804f_row11_col2" class="data row11 col2">0.0040</td>
<td id="T_3804f_row11_col3" class="data row11 col3">0.0060</td>
<td id="T_3804f_row11_col4" class="data row11 col4">0.0033</td>
<td id="T_3804f_row11_col5" class="data row11 col5">0.0067</td>
<td id="T_3804f_row11_col6" class="data row11 col6">0.0066</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
</section>
<section id="decision-tree-clasifier" class="level3" data-number="3.6.4">
<h3 data-number="3.6.4" class="anchored" data-anchor-id="decision-tree-clasifier"><span class="header-section-number">3.6.4</span> Decision Tree Clasifier</h3>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>dt <span class="op">=</span> create_model(<span class="st">'dt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_02c55_row10_col0, #T_02c55_row10_col1, #T_02c55_row10_col2, #T_02c55_row10_col3, #T_02c55_row10_col4, #T_02c55_row10_col5, #T_02c55_row10_col6 {
  background: yellow;
}
</style>

<table id="T_02c55" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_02c55_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Accuracy</th>
<th id="T_02c55_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">AUC</th>
<th id="T_02c55_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Recall</th>
<th id="T_02c55_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Prec.</th>
<th id="T_02c55_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">F1</th>
<th id="T_02c55_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">Kappa</th>
<th id="T_02c55_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">MCC</th>
</tr>
<tr class="odd">
<th class="index_name level0" data-quarto-table-cell-role="th">Fold</th>
<th class="blank col0" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col1" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col2" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col3" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col4" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col5" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col6" data-quarto-table-cell-role="th">&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_02c55_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_02c55_row0_col0" class="data row0 col0">0.9823</td>
<td id="T_02c55_row0_col1" class="data row0 col1">0.9822</td>
<td id="T_02c55_row0_col2" class="data row0 col2">0.9973</td>
<td id="T_02c55_row0_col3" class="data row0 col3">0.9683</td>
<td id="T_02c55_row0_col4" class="data row0 col4">0.9826</td>
<td id="T_02c55_row0_col5" class="data row0 col5">0.9645</td>
<td id="T_02c55_row0_col6" class="data row0 col6">0.9650</td>
</tr>
<tr class="even">
<td id="T_02c55_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_02c55_row1_col0" class="data row1 col0">0.9782</td>
<td id="T_02c55_row1_col1" class="data row1 col1">0.9781</td>
<td id="T_02c55_row1_col2" class="data row1 col2">0.9973</td>
<td id="T_02c55_row1_col3" class="data row1 col3">0.9606</td>
<td id="T_02c55_row1_col4" class="data row1 col4">0.9786</td>
<td id="T_02c55_row1_col5" class="data row1 col5">0.9563</td>
<td id="T_02c55_row1_col6" class="data row1 col6">0.9570</td>
</tr>
<tr class="odd">
<td id="T_02c55_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_02c55_row2_col0" class="data row2 col0">0.9782</td>
<td id="T_02c55_row2_col1" class="data row2 col1">0.9781</td>
<td id="T_02c55_row2_col2" class="data row2 col2">0.9973</td>
<td id="T_02c55_row2_col3" class="data row2 col3">0.9606</td>
<td id="T_02c55_row2_col4" class="data row2 col4">0.9786</td>
<td id="T_02c55_row2_col5" class="data row2 col5">0.9563</td>
<td id="T_02c55_row2_col6" class="data row2 col6">0.9570</td>
</tr>
<tr class="even">
<td id="T_02c55_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_02c55_row3_col0" class="data row3 col0">0.9768</td>
<td id="T_02c55_row3_col1" class="data row3 col1">0.9768</td>
<td id="T_02c55_row3_col2" class="data row3 col2">0.9973</td>
<td id="T_02c55_row3_col3" class="data row3 col3">0.9581</td>
<td id="T_02c55_row3_col4" class="data row3 col4">0.9773</td>
<td id="T_02c55_row3_col5" class="data row3 col5">0.9536</td>
<td id="T_02c55_row3_col6" class="data row3 col6">0.9544</td>
</tr>
<tr class="odd">
<td id="T_02c55_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_02c55_row4_col0" class="data row4 col0">0.9809</td>
<td id="T_02c55_row4_col1" class="data row4 col1">0.9809</td>
<td id="T_02c55_row4_col2" class="data row4 col2">1.0000</td>
<td id="T_02c55_row4_col3" class="data row4 col3">0.9633</td>
<td id="T_02c55_row4_col4" class="data row4 col4">0.9813</td>
<td id="T_02c55_row4_col5" class="data row4 col5">0.9618</td>
<td id="T_02c55_row4_col6" class="data row4 col6">0.9625</td>
</tr>
<tr class="even">
<td id="T_02c55_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_02c55_row5_col0" class="data row5 col0">0.9850</td>
<td id="T_02c55_row5_col1" class="data row5 col1">0.9850</td>
<td id="T_02c55_row5_col2" class="data row5 col2">0.9945</td>
<td id="T_02c55_row5_col3" class="data row5 col3">0.9759</td>
<td id="T_02c55_row5_col4" class="data row5 col4">0.9851</td>
<td id="T_02c55_row5_col5" class="data row5 col5">0.9700</td>
<td id="T_02c55_row5_col6" class="data row5 col6">0.9702</td>
</tr>
<tr class="odd">
<td id="T_02c55_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_02c55_row6_col0" class="data row6 col0">0.9768</td>
<td id="T_02c55_row6_col1" class="data row6 col1">0.9768</td>
<td id="T_02c55_row6_col2" class="data row6 col2">0.9973</td>
<td id="T_02c55_row6_col3" class="data row6 col3">0.9580</td>
<td id="T_02c55_row6_col4" class="data row6 col4">0.9772</td>
<td id="T_02c55_row6_col5" class="data row6 col5">0.9536</td>
<td id="T_02c55_row6_col6" class="data row6 col6">0.9544</td>
</tr>
<tr class="even">
<td id="T_02c55_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_02c55_row7_col0" class="data row7 col0">0.9823</td>
<td id="T_02c55_row7_col1" class="data row7 col1">0.9823</td>
<td id="T_02c55_row7_col2" class="data row7 col2">0.9973</td>
<td id="T_02c55_row7_col3" class="data row7 col3">0.9682</td>
<td id="T_02c55_row7_col4" class="data row7 col4">0.9825</td>
<td id="T_02c55_row7_col5" class="data row7 col5">0.9645</td>
<td id="T_02c55_row7_col6" class="data row7 col6">0.9650</td>
</tr>
<tr class="odd">
<td id="T_02c55_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_02c55_row8_col0" class="data row8 col0">0.9768</td>
<td id="T_02c55_row8_col1" class="data row8 col1">0.9768</td>
<td id="T_02c55_row8_col2" class="data row8 col2">1.0000</td>
<td id="T_02c55_row8_col3" class="data row8 col3">0.9556</td>
<td id="T_02c55_row8_col4" class="data row8 col4">0.9773</td>
<td id="T_02c55_row8_col5" class="data row8 col5">0.9536</td>
<td id="T_02c55_row8_col6" class="data row8 col6">0.9546</td>
</tr>
<tr class="even">
<td id="T_02c55_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_02c55_row9_col0" class="data row9 col0">0.9809</td>
<td id="T_02c55_row9_col1" class="data row9 col1">0.9809</td>
<td id="T_02c55_row9_col2" class="data row9 col2">1.0000</td>
<td id="T_02c55_row9_col3" class="data row9 col3">0.9632</td>
<td id="T_02c55_row9_col4" class="data row9 col4">0.9812</td>
<td id="T_02c55_row9_col5" class="data row9 col5">0.9618</td>
<td id="T_02c55_row9_col6" class="data row9 col6">0.9625</td>
</tr>
<tr class="odd">
<td id="T_02c55_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">Mean</td>
<td id="T_02c55_row10_col0" class="data row10 col0">0.9798</td>
<td id="T_02c55_row10_col1" class="data row10 col1">0.9798</td>
<td id="T_02c55_row10_col2" class="data row10 col2">0.9978</td>
<td id="T_02c55_row10_col3" class="data row10 col3">0.9632</td>
<td id="T_02c55_row10_col4" class="data row10 col4">0.9802</td>
<td id="T_02c55_row10_col5" class="data row10 col5">0.9596</td>
<td id="T_02c55_row10_col6" class="data row10 col6">0.9603</td>
</tr>
<tr class="even">
<td id="T_02c55_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">Std</td>
<td id="T_02c55_row11_col0" class="data row11 col0">0.0027</td>
<td id="T_02c55_row11_col1" class="data row11 col1">0.0027</td>
<td id="T_02c55_row11_col2" class="data row11 col2">0.0016</td>
<td id="T_02c55_row11_col3" class="data row11 col3">0.0058</td>
<td id="T_02c55_row11_col4" class="data row11 col4">0.0026</td>
<td id="T_02c55_row11_col5" class="data row11 col5">0.0054</td>
<td id="T_02c55_row11_col6" class="data row11 col6">0.0052</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
</section>
<section id="ada-boost-classifier" class="level3" data-number="3.6.5">
<h3 data-number="3.6.5" class="anchored" data-anchor-id="ada-boost-classifier"><span class="header-section-number">3.6.5</span> Ada Boost Classifier</h3>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>ada <span class="op">=</span> create_model(<span class="st">'ada'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<style type="text/css">
#T_b4d77_row10_col0, #T_b4d77_row10_col1, #T_b4d77_row10_col2, #T_b4d77_row10_col3, #T_b4d77_row10_col4, #T_b4d77_row10_col5, #T_b4d77_row10_col6 {
  background: yellow;
}
</style>

<table id="T_b4d77" data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_b4d77_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Accuracy</th>
<th id="T_b4d77_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">AUC</th>
<th id="T_b4d77_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Recall</th>
<th id="T_b4d77_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">Prec.</th>
<th id="T_b4d77_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">F1</th>
<th id="T_b4d77_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">Kappa</th>
<th id="T_b4d77_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">MCC</th>
</tr>
<tr class="odd">
<th class="index_name level0" data-quarto-table-cell-role="th">Fold</th>
<th class="blank col0" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col1" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col2" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col3" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col4" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col5" data-quarto-table-cell-role="th">&nbsp;</th>
<th class="blank col6" data-quarto-table-cell-role="th">&nbsp;</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_b4d77_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">0</td>
<td id="T_b4d77_row0_col0" class="data row0 col0">0.8936</td>
<td id="T_b4d77_row0_col1" class="data row0 col1">0.9591</td>
<td id="T_b4d77_row0_col2" class="data row0 col2">0.8937</td>
<td id="T_b4d77_row0_col3" class="data row0 col3">0.8937</td>
<td id="T_b4d77_row0_col4" class="data row0 col4">0.8937</td>
<td id="T_b4d77_row0_col5" class="data row0 col5">0.7872</td>
<td id="T_b4d77_row0_col6" class="data row0 col6">0.7872</td>
</tr>
<tr class="even">
<td id="T_b4d77_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">1</td>
<td id="T_b4d77_row1_col0" class="data row1 col0">0.8568</td>
<td id="T_b4d77_row1_col1" class="data row1 col1">0.9422</td>
<td id="T_b4d77_row1_col2" class="data row1 col2">0.8447</td>
<td id="T_b4d77_row1_col3" class="data row1 col3">0.8659</td>
<td id="T_b4d77_row1_col4" class="data row1 col4">0.8552</td>
<td id="T_b4d77_row1_col5" class="data row1 col5">0.7135</td>
<td id="T_b4d77_row1_col6" class="data row1 col6">0.7137</td>
</tr>
<tr class="odd">
<td id="T_b4d77_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">2</td>
<td id="T_b4d77_row2_col0" class="data row2 col0">0.8690</td>
<td id="T_b4d77_row2_col1" class="data row2 col1">0.9495</td>
<td id="T_b4d77_row2_col2" class="data row2 col2">0.8719</td>
<td id="T_b4d77_row2_col3" class="data row2 col3">0.8672</td>
<td id="T_b4d77_row2_col4" class="data row2 col4">0.8696</td>
<td id="T_b4d77_row2_col5" class="data row2 col5">0.7381</td>
<td id="T_b4d77_row2_col6" class="data row2 col6">0.7381</td>
</tr>
<tr class="even">
<td id="T_b4d77_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">3</td>
<td id="T_b4d77_row3_col0" class="data row3 col0">0.8677</td>
<td id="T_b4d77_row3_col1" class="data row3 col1">0.9522</td>
<td id="T_b4d77_row3_col2" class="data row3 col2">0.8665</td>
<td id="T_b4d77_row3_col3" class="data row3 col3">0.8689</td>
<td id="T_b4d77_row3_col4" class="data row3 col4">0.8677</td>
<td id="T_b4d77_row3_col5" class="data row3 col5">0.7353</td>
<td id="T_b4d77_row3_col6" class="data row3 col6">0.7353</td>
</tr>
<tr class="odd">
<td id="T_b4d77_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">4</td>
<td id="T_b4d77_row4_col0" class="data row4 col0">0.8677</td>
<td id="T_b4d77_row4_col1" class="data row4 col1">0.9485</td>
<td id="T_b4d77_row4_col2" class="data row4 col2">0.8501</td>
<td id="T_b4d77_row4_col3" class="data row4 col3">0.8814</td>
<td id="T_b4d77_row4_col4" class="data row4 col4">0.8655</td>
<td id="T_b4d77_row4_col5" class="data row4 col5">0.7353</td>
<td id="T_b4d77_row4_col6" class="data row4 col6">0.7358</td>
</tr>
<tr class="even">
<td id="T_b4d77_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">5</td>
<td id="T_b4d77_row5_col0" class="data row5 col0">0.8854</td>
<td id="T_b4d77_row5_col1" class="data row5 col1">0.9650</td>
<td id="T_b4d77_row5_col2" class="data row5 col2">0.8607</td>
<td id="T_b4d77_row5_col3" class="data row5 col3">0.9052</td>
<td id="T_b4d77_row5_col4" class="data row5 col4">0.8824</td>
<td id="T_b4d77_row5_col5" class="data row5 col5">0.7708</td>
<td id="T_b4d77_row5_col6" class="data row5 col6">0.7717</td>
</tr>
<tr class="odd">
<td id="T_b4d77_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">6</td>
<td id="T_b4d77_row6_col0" class="data row6 col0">0.8745</td>
<td id="T_b4d77_row6_col1" class="data row6 col1">0.9486</td>
<td id="T_b4d77_row6_col2" class="data row6 col2">0.8661</td>
<td id="T_b4d77_row6_col3" class="data row6 col3">0.8806</td>
<td id="T_b4d77_row6_col4" class="data row6 col4">0.8733</td>
<td id="T_b4d77_row6_col5" class="data row6 col5">0.7490</td>
<td id="T_b4d77_row6_col6" class="data row6 col6">0.7491</td>
</tr>
<tr class="even">
<td id="T_b4d77_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">7</td>
<td id="T_b4d77_row7_col0" class="data row7 col0">0.8799</td>
<td id="T_b4d77_row7_col1" class="data row7 col1">0.9569</td>
<td id="T_b4d77_row7_col2" class="data row7 col2">0.8743</td>
<td id="T_b4d77_row7_col3" class="data row7 col3">0.8840</td>
<td id="T_b4d77_row7_col4" class="data row7 col4">0.8791</td>
<td id="T_b4d77_row7_col5" class="data row7 col5">0.7599</td>
<td id="T_b4d77_row7_col6" class="data row7 col6">0.7599</td>
</tr>
<tr class="odd">
<td id="T_b4d77_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">8</td>
<td id="T_b4d77_row8_col0" class="data row8 col0">0.8990</td>
<td id="T_b4d77_row8_col1" class="data row8 col1">0.9629</td>
<td id="T_b4d77_row8_col2" class="data row8 col2">0.9016</td>
<td id="T_b4d77_row8_col3" class="data row8 col3">0.8967</td>
<td id="T_b4d77_row8_col4" class="data row8 col4">0.8992</td>
<td id="T_b4d77_row8_col5" class="data row8 col5">0.7981</td>
<td id="T_b4d77_row8_col6" class="data row8 col6">0.7981</td>
</tr>
<tr class="even">
<td id="T_b4d77_level0_row9" class="row_heading level0 row9" data-quarto-table-cell-role="th">9</td>
<td id="T_b4d77_row9_col0" class="data row9 col0">0.8799</td>
<td id="T_b4d77_row9_col1" class="data row9 col1">0.9565</td>
<td id="T_b4d77_row9_col2" class="data row9 col2">0.8770</td>
<td id="T_b4d77_row9_col3" class="data row9 col3">0.8819</td>
<td id="T_b4d77_row9_col4" class="data row9 col4">0.8795</td>
<td id="T_b4d77_row9_col5" class="data row9 col5">0.7599</td>
<td id="T_b4d77_row9_col6" class="data row9 col6">0.7599</td>
</tr>
<tr class="odd">
<td id="T_b4d77_level0_row10" class="row_heading level0 row10" data-quarto-table-cell-role="th">Mean</td>
<td id="T_b4d77_row10_col0" class="data row10 col0">0.8774</td>
<td id="T_b4d77_row10_col1" class="data row10 col1">0.9541</td>
<td id="T_b4d77_row10_col2" class="data row10 col2">0.8707</td>
<td id="T_b4d77_row10_col3" class="data row10 col3">0.8825</td>
<td id="T_b4d77_row10_col4" class="data row10 col4">0.8765</td>
<td id="T_b4d77_row10_col5" class="data row10 col5">0.7547</td>
<td id="T_b4d77_row10_col6" class="data row10 col6">0.7549</td>
</tr>
<tr class="even">
<td id="T_b4d77_level0_row11" class="row_heading level0 row11" data-quarto-table-cell-role="th">Std</td>
<td id="T_b4d77_row11_col0" class="data row11 col0">0.0123</td>
<td id="T_b4d77_row11_col1" class="data row11 col1">0.0068</td>
<td id="T_b4d77_row11_col2" class="data row11 col2">0.0167</td>
<td id="T_b4d77_row11_col3" class="data row11 col3">0.0124</td>
<td id="T_b4d77_row11_col4" class="data row11 col4">0.0125</td>
<td id="T_b4d77_row11_col5" class="data row11 col5">0.0245</td>
<td id="T_b4d77_row11_col6" class="data row11 col6">0.0245</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
</section>
</section>
<section id="feature-selection" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="feature-selection"><span class="header-section-number">3.7</span> Feature Selection</h2>
<p>Feature Selection (pemilihan fitur) adalah proses memilih subset fitur yang paling relevan dan informatif dari suatu dataset untuk digunakan dalam pembangunan model atau analisis data. Tujuan utama dari feature selection adalah untuk meningkatkan kinerja model dengan mengurangi kompleksitas dan meningkatkan interpretabilitas, sambil mempertahankan atau meningkatkan keakuratan prediksi. Pada proses seleksi fitur ini menggunakan fungsi Mutual Information.</p>
<p>Mutual Information (Informasi Timbal Balik) adalah suatu metrik yang digunakan untuk mengukur seberapa banyak pengetahuan tentang suatu variabel dapat memberikan wawasan tentang variabel lainnya. Dalam konteks feature selection atau pemilihan fitur, mutual information digunakan untuk mengukur seberapa informatif suatu fitur terhadap variabel target atau variabel kelas.</p>
<p>Rumus Mutual Information :</p>
<p><span class="math display">\[I(X;Y) = \sum_{x \in X} \sum_{y \in Y} p(x, y) \log\left(\frac{p(x, y)}{p(x)p(y)}\right)\]</span></p>
<p>dimana :<br>
- <span class="math inline">\(p(x,y)\)</span> adalah probabilitas bersama dari <span class="math inline">\(X\)</span> dan <span class="math inline">\(Y\)</span>. - <span class="math inline">\(p(x)\)</span> dan <span class="math inline">\(p(y)\)</span> adalah probabilitas marginal dari <span class="math inline">\(X\)</span> dan <span class="math inline">\(Y\)</span> masing - masing.</p>
<p>Information gain diukur sebagai perbedaan antara entropi set data awal dan entropi set data setelah pemisahan berdasarkan fitur A. Semakin tinggi information gain, semakin baik fitur A dalam memisahkan data.</p>
<p><strong>1) Berikut merupakan langkah-langkah dalam menghitung information gain :</strong></p>
<ul>
<li><p><strong>Hitung entropy awal (sebelum pemisahan):</strong></p>
<p>Hitung entropy dataset sebelum dilakukan pemisahan. Berikut merupakan formulanya :</p>
<p><span class="math display">\[ H(S) = -\sum_{i=1}^{n} p_i \cdot \log_2(p_i) \]</span></p>
<p><em>Keterangan :</em></p>
<p><em>H(S) = nilai entropy awal</em> <em>n = jumlah kelas</em> <em>Pi = proporsi kelas i dalam dataset</em></p></li>
<li><p><strong>Hitung entropy setelah pemisahan:</strong> Menghitung entropy tiap kelompok yang dihasilkan setelah pemisahan berdasarkan suatu fitur. Berikut merupakan formulanya :</p>
<p><span class="math display">\[ H(S|A) = \sum_{j=1}^{v} \frac{|S_j|}{|S|} \cdot H(S_j) \]</span></p>
<p><em>Keterangan :</em> <em>H(S|A) = entropy dataset setelah pemisahan pada fitur A</em> <em>v = jumlah nilai dalam fitur A</em> <em>| Sj | = ukuran subset dari fitur A yang mempunyai nilai j</em> <em>| S | = ukuran dataset</em> <em>H(Sj) = entropy subset untuk fitur A</em></p></li>
<li><p><strong>Hitung information gain:</strong> <span class="math display">\[ \text{Gain}(S, A) = H(S) - H(S|A) \]</span></p>
<p><em>Keterangan :</em> <em>H(S) = entropy awal dataset S</em> <em>H(S|A) = entropy dataset setelah pemisahan pada fitur A</em></p></li>
</ul>
<p><strong>2) Berikut merupakan contoh perhitungan manual menggunakan data dummy :</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>ID</th>
<th>Outlook</th>
<th>Temperature</th>
<th>Play Tennis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Sunny</td>
<td>Hot</td>
<td>No</td>
</tr>
<tr class="even">
<td>2</td>
<td>Sunny</td>
<td>Hot</td>
<td>No</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Overcast</td>
<td>Hot</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>4</td>
<td>Rainy</td>
<td>Mild</td>
<td>Yes</td>
</tr>
<tr class="odd">
<td>5</td>
<td>Rainy</td>
<td>Cool</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>6</td>
<td>Rainy</td>
<td>Cool</td>
<td>No</td>
</tr>
<tr class="odd">
<td>7</td>
<td>Overcast</td>
<td>Cool</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>8</td>
<td>Sunny</td>
<td>Mild</td>
<td>No</td>
</tr>
<tr class="odd">
<td>9</td>
<td>Sunny</td>
<td>Cool</td>
<td>Yes</td>
</tr>
<tr class="even">
<td>10</td>
<td>Rainy</td>
<td>Mild</td>
<td>Yes</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Menghitung entropy awal :</p>
<p><span class="math display">\[ H(S) = -p_{\text{Yes}} \cdot \log_2(p_{\text{Yes}}) - p_{\text{No}} \cdot \log_2(p_{\text{No}}) \]</span></p>
<p><span class="math display">\[ H(S) = -[\frac{6}{10} \cdot \log_2\left(\frac{6}{10}\right) + \frac{4}{10} \cdot \log_2\left(\frac{4}{10}\right) ] \]</span></p>
<p><span class="math display">\[ H(S) = -\left(\frac{6}{10} \log_2\left(\frac{3}{5}\right) + \frac{4}{10} \log_2\left(\frac{2}{5}\right)\right) \]</span></p>
<p><span class="math display">\[ H(S) = -\left(-0.4422 - 0.5288\right) \]</span></p>
<p><span class="math display">\[ H(S) = 0.971 \]</span></p></li>
<li><p>Menghitung entropy setelah pemisahan (berdasarkan outlook) :</p>
<p><strong>(a) Subset SUNNY</strong> <span class="math display">\[  [ H(S_{\text{Sunny}}) = -\left(\frac{3}{5} \cdot \log_2\left(\frac{3}{5}\right) + \frac{2}{5} \cdot \log_2\left(\frac{2}{5}\right)\right) ] \]</span></p>
<p><span class="math display">\[ H(S_{\text{Sunny}}) = -\left(\frac{3}{5} \cdot (-0.737) + \frac{2}{5} \cdot (-1.322)\right) \]</span></p>
<p><span class="math display">\[ [ H(S_{\text{Sunny}}) = 0.971 ] \]</span></p>
<p><strong>(b) Subset OVERCAST</strong> <span class="math display">\[ [ H(S_{\text{Overcast}}) = 0 ] (karena  semua instance positif) \]</span></p>
<p><strong>(c) Subset RAINY</strong> <span class="math display">\[ [ H(S_{\text{Rainy}}) = -\left(\frac{2}{5} \cdot \log_2\left(\frac{2}{5}\right) + \frac{3}{5} \cdot \log_2\left(\frac{3}{5}\right)\right) ] \]</span></p>
<p><span class="math display">\[ [ H(S_{\text{Rainy}}) = -\left(\frac{2}{5} \cdot (-0.737) + \frac{3}{5} \cdot (-0.971)\right) ] \]</span></p>
<p><span class="math display">\[ [ H(S_{\text{Rainy}}) = 0.971 ] \]</span></p>
<p><strong>(d) Entropy setelah pemisahan</strong> <span class="math display">\[  [ H(S|\text{Outlook}) = \frac{5}{10} \cdot H(S_{\text{Sunny}}) + \frac{4}{10} \cdot H(S_{\text{Overcast}}) + \frac{5}{10} \cdot H(S_{\text{Rainy}}) ] \]</span></p>
<p><span class="math display">\[ H(S_{\text{Overcast}}) + \frac{5}{10} \cdot H(S_{\text{Rainy}}) \]</span> <span class="math display">\[ H(S|\text{Outlook}) = \frac{5}{10} \cdot 0.971 + \frac{4}{10} \cdot 0 + \frac{5}{10} \cdot 0.971 \]</span></p>
<p><span class="math display">\[ [ H(S|\text{Outlook}) = 0.971 ] \]</span></p></li>
</ul>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_normalisasi.csv'</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'is_safe'</span>]</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghitung Information Gain untuk setiap fitur</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>information_gains <span class="op">=</span> mutual_info_classif(X, y)</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyusun hasil ke dalam DataFrame untuk analisis</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>feature_scores <span class="op">=</span> pd.DataFrame({<span class="st">'feature'</span>: X.columns, <span class="st">'information_gain'</span>: information_gains})</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>feature_scores <span class="op">=</span> feature_scores.sort_values(by<span class="op">=</span><span class="st">'information_gain'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil Information Gain untuk setiap fitur</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(feature_scores)</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting bar plot untuk perbandingan Information Gain</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>plt.barh(feature_scores[<span class="st">'feature'</span>], feature_scores[<span class="st">'information_gain'</span>], color<span class="op">=</span><span class="st">'lightgreen'</span>)</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Information Gain'</span>)</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Feature'</span>)</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Features by Information Gain'</span>)</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        feature  information_gain
15  perchlorate          0.331623
1       ammonia          0.301489
12     nitrates          0.222200
0     aluminium          0.216562
4       cadmium          0.193228
5    chloramine          0.180673
16       radium          0.142545
2       arsenic          0.119687
3        barium          0.092841
13     nitrites          0.087851
6      chromium          0.063050
7        copper          0.038504
11         lead          0.036719
10      viruses          0.035334
8      flouride          0.022959
18       silver          0.019000
9      bacteria          0.018768
19      uranium          0.011103
14      mercury          0.003603
17     selenium          0.000720</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-48-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="pencarian-fitur-terbaik-light-gradient-boosting-machine" class="level3" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="pencarian-fitur-terbaik-light-gradient-boosting-machine"><span class="header-section-number">3.7.1</span> Pencarian Fitur Terbaik Light Gradient Boosting Machine</h3>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>best_feature_scores <span class="op">=</span> <span class="va">None</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>best_selected_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>], <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menghitung nilai korelasi antara setiap fitur dengan target</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>    k_best_selector <span class="op">=</span> SelectKBest(f_classif, k<span class="op">=</span>k)</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>    X_train_selected <span class="op">=</span> k_best_selector.fit_transform(X_train, y_train)</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>    X_test_selected <span class="op">=</span> k_best_selector.transform(X_test)</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mendapatkan nama fitur terpilih</span></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    selected_feature_names <span class="op">=</span> X_ros.columns[k_best_selector.get_support(indices<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membuat model Light Gradient Boosting Machine</span></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>    lightgbm_model <span class="op">=</span> lightgbm</span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>    lightgbm_model.fit(X_train_selected, y_train)</span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a>    y_pred_lightgbm <span class="op">=</span> lightgbm_model.predict(X_test_selected)</span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mengukur akurasi model Light Gradient Boosting Machine</span></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a>    accuracy_lightgbm <span class="op">=</span> accuracy_score(y_test, y_pred_lightgbm)</span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membandingkan dengan akurasi terbaik sejauh ini</span></span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> accuracy_lightgbm <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> accuracy_lightgbm</span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a>        best_k <span class="op">=</span> k</span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a>        best_selected_feature_names <span class="op">=</span> selected_feature_names</span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> lightgbm_model</span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> k_best_selector</span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Menyimpan skor korelasi untuk fitur terpilih</span></span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a>        best_feature_scores <span class="op">=</span> k_best_selector.scores_</span>
<span id="cb66-39"><a href="#cb66-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-40"><a href="#cb66-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil terbaik</span></span>
<span id="cb66-41"><a href="#cb66-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah Fitur :"</span>, best_k)</span>
<span id="cb66-42"><a href="#cb66-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Fitur Light Gradient Boosting Machine :"</span>, best_selected_feature_names)</span>
<span id="cb66-43"><a href="#cb66-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Fitur Scores:"</span>)</span>
<span id="cb66-44"><a href="#cb66-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature_name, score <span class="kw">in</span> <span class="bu">zip</span>(best_selected_feature_names, best_feature_scores):</span>
<span id="cb66-45"><a href="#cb66-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb66-46"><a href="#cb66-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-47"><a href="#cb66-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan nama fitur terpilih</span></span>
<span id="cb66-48"><a href="#cb66-48" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_selected_feature_names, <span class="st">'fiturLightGradientBoostingMachine.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001877 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3034
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001930 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2834
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2683
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 18
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2582
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 17
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2571
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 16
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2316
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 15
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001375 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2115
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 14
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2104
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 13
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1860
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1605
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 11
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1353
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 10
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000245 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1098
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 9
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 843
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 8
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 833
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 7
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000615 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 782
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 721
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 5
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 630
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 4
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 524
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 3
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 269
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 2
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 23
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 1
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah Fitur : 20
Best Fitur Light Gradient Boosting Machine : Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',
       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',
       'silver', 'uranium'],
      dtype='object')

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>['fiturLightGradientBoostingMachine.pkl']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca DataFrame</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_balancing.csv'</span>)</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Memuat list fitur yang akan di-drop dari file pickle</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>LightGradientBoostingMachine_drop <span class="op">=</span> joblib.load(<span class="st">'fiturLightGradientBoostingMachine.pkl'</span>)</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghilangkan 'is_safe' dari setiap nama fitur</span></span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>LightGradientBoostingMachine_drop <span class="op">=</span> [feature.replace(<span class="st">'is_safe'</span>, <span class="st">''</span>) <span class="cf">for</span> feature <span class="kw">in</span> LightGradientBoostingMachine_drop]</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Memilih hanya kolom yang ada di pickle</span></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>data_LightGradientBoostingMachine_drop <span class="op">=</span> df[LightGradientBoostingMachine_drop <span class="op">+</span> [<span class="st">'is_safe'</span>]]</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan DataFrame setelah fitur di-drop</span></span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>data_LightGradientBoostingMachine_drop.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>5 rows × 21 columns</p>
</div>
</div>
</div>
</section>
<section id="pencarian-fitur-terbaik-gradient-boosting-classifier" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="pencarian-fitur-terbaik-gradient-boosting-classifier"><span class="header-section-number">3.7.2</span> Pencarian Fitur Terbaik Gradient Boosting Classifier</h3>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>best_selected_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>best_feature_scores <span class="op">=</span> <span class="va">None</span></span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>], <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menghitung nilai korelasi antara setiap fitur dengan target</span></span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    k_best_selector <span class="op">=</span> SelectKBest(f_classif, k<span class="op">=</span>k)</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    X_train_selected <span class="op">=</span> k_best_selector.fit_transform(X_train, y_train)</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>    X_test_selected <span class="op">=</span> k_best_selector.transform(X_test)</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mendapatkan nama fitur terpilih</span></span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>    selected_feature_names <span class="op">=</span> X_ros.columns[k_best_selector.get_support(indices<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membuat model Gradient Boosting</span></span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>    gb_model <span class="op">=</span> gbc</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb72-21"><a href="#cb72-21" aria-hidden="true" tabindex="-1"></a>    gb_model.fit(X_train_selected, y_train)</span>
<span id="cb72-22"><a href="#cb72-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-23"><a href="#cb72-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb72-24"><a href="#cb72-24" aria-hidden="true" tabindex="-1"></a>    y_pred_gb <span class="op">=</span> gb_model.predict(X_test_selected)</span>
<span id="cb72-25"><a href="#cb72-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-26"><a href="#cb72-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mengukur akurasi model Gradient Boosting</span></span>
<span id="cb72-27"><a href="#cb72-27" aria-hidden="true" tabindex="-1"></a>    accuracy_gb <span class="op">=</span> accuracy_score(y_test, y_pred_gb)</span>
<span id="cb72-28"><a href="#cb72-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-29"><a href="#cb72-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membandingkan dengan akurasi terbaik sejauh ini</span></span>
<span id="cb72-30"><a href="#cb72-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> accuracy_gb <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb72-31"><a href="#cb72-31" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> accuracy_gb</span>
<span id="cb72-32"><a href="#cb72-32" aria-hidden="true" tabindex="-1"></a>        best_k <span class="op">=</span> k</span>
<span id="cb72-33"><a href="#cb72-33" aria-hidden="true" tabindex="-1"></a>        best_selected_feature_names <span class="op">=</span> selected_feature_names</span>
<span id="cb72-34"><a href="#cb72-34" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> gb_model</span>
<span id="cb72-35"><a href="#cb72-35" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> k_best_selector</span>
<span id="cb72-36"><a href="#cb72-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-37"><a href="#cb72-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Menyimpan skor korelasi untuk fitur terpilih</span></span>
<span id="cb72-38"><a href="#cb72-38" aria-hidden="true" tabindex="-1"></a>        best_feature_scores <span class="op">=</span> k_best_selector.scores_</span>
<span id="cb72-39"><a href="#cb72-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-40"><a href="#cb72-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil terbaik</span></span>
<span id="cb72-41"><a href="#cb72-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah Fitur :"</span>, best_k)</span>
<span id="cb72-42"><a href="#cb72-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Fitur Gradient Boosting :"</span>, best_selected_feature_names)</span>
<span id="cb72-43"><a href="#cb72-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Fitur Scores:"</span>)</span>
<span id="cb72-44"><a href="#cb72-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature_name, score <span class="kw">in</span> <span class="bu">zip</span>(best_selected_feature_names, best_feature_scores):</span>
<span id="cb72-45"><a href="#cb72-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb72-46"><a href="#cb72-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-47"><a href="#cb72-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan nama fitur terpilih</span></span>
<span id="cb72-48"><a href="#cb72-48" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_selected_feature_names, <span class="st">'fiturgradientboosting.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah Fitur : 20
Best Fitur Gradient Boosting : Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',
       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',
       'silver', 'uranium'],
      dtype='object')

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>['fiturgradientboosting.pkl']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca DataFrame</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_balancing.csv'</span>)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Memuat list fitur yang akan di-drop dari file pickle</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>GradientBoostingClasifier_drop <span class="op">=</span> joblib.load(<span class="st">'fiturgradientboosting.pkl'</span>)</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghilangkan 'is_safe' dari setiap nama fitur</span></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>GradientBoostingClasifier_drop <span class="op">=</span> [feature.replace(<span class="st">'is_safe'</span>, <span class="st">''</span>) <span class="cf">for</span> feature <span class="kw">in</span> GradientBoostingClasifier_drop]</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Memilih hanya kolom yang ada di pickle</span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>data_GradientBoostingClasifier_drop <span class="op">=</span> df[GradientBoostingClasifier_drop <span class="op">+</span> [<span class="st">'is_safe'</span>]]</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan DataFrame setelah fitur di-drop</span></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>data_GradientBoostingClasifier_drop.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>5 rows × 21 columns</p>
</div>
</div>
</div>
</section>
<section id="pencarian-fitur-terbaik-random-forest" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="pencarian-fitur-terbaik-random-forest"><span class="header-section-number">3.7.3</span> Pencarian Fitur Terbaik Random Forest</h3>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>best_selected_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>best_feature_scores <span class="op">=</span> <span class="va">None</span></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>], <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menghitung nilai korelasi antara setiap fitur dengan target</span></span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>    k_best_selector <span class="op">=</span> SelectKBest(f_classif, k<span class="op">=</span>k)</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>    X_train_selected <span class="op">=</span> k_best_selector.fit_transform(X_train, y_train)</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>    X_test_selected <span class="op">=</span> k_best_selector.transform(X_test)</span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-14"><a href="#cb76-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mendapatkan nama fitur terpilih</span></span>
<span id="cb76-15"><a href="#cb76-15" aria-hidden="true" tabindex="-1"></a>    selected_feature_names <span class="op">=</span> X_ros.columns[k_best_selector.get_support(indices<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb76-16"><a href="#cb76-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-17"><a href="#cb76-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membuat model Random Forest</span></span>
<span id="cb76-18"><a href="#cb76-18" aria-hidden="true" tabindex="-1"></a>    rf_model <span class="op">=</span> rf</span>
<span id="cb76-19"><a href="#cb76-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-20"><a href="#cb76-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb76-21"><a href="#cb76-21" aria-hidden="true" tabindex="-1"></a>    rf_model.fit(X_train_selected, y_train)</span>
<span id="cb76-22"><a href="#cb76-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-23"><a href="#cb76-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb76-24"><a href="#cb76-24" aria-hidden="true" tabindex="-1"></a>    y_pred_rf <span class="op">=</span> rf_model.predict(X_test_selected)</span>
<span id="cb76-25"><a href="#cb76-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-26"><a href="#cb76-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mengukur akurasi model Random Forest</span></span>
<span id="cb76-27"><a href="#cb76-27" aria-hidden="true" tabindex="-1"></a>    accuracy_rf <span class="op">=</span> accuracy_score(y_test, y_pred_rf)</span>
<span id="cb76-28"><a href="#cb76-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-29"><a href="#cb76-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membandingkan dengan akurasi terbaik sejauh ini</span></span>
<span id="cb76-30"><a href="#cb76-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> accuracy_rf <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb76-31"><a href="#cb76-31" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> accuracy_rf</span>
<span id="cb76-32"><a href="#cb76-32" aria-hidden="true" tabindex="-1"></a>        best_k <span class="op">=</span> k</span>
<span id="cb76-33"><a href="#cb76-33" aria-hidden="true" tabindex="-1"></a>        best_selected_feature_names <span class="op">=</span> selected_feature_names</span>
<span id="cb76-34"><a href="#cb76-34" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> rf_model</span>
<span id="cb76-35"><a href="#cb76-35" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> k_best_selector</span>
<span id="cb76-36"><a href="#cb76-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-37"><a href="#cb76-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Menyimpan skor korelasi untuk fitur terpilih</span></span>
<span id="cb76-38"><a href="#cb76-38" aria-hidden="true" tabindex="-1"></a>        best_feature_scores <span class="op">=</span> k_best_selector.scores_</span>
<span id="cb76-39"><a href="#cb76-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-40"><a href="#cb76-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil terbaik</span></span>
<span id="cb76-41"><a href="#cb76-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah Fitur :"</span>, best_k)</span>
<span id="cb76-42"><a href="#cb76-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Fitur Random Forest:"</span>, best_selected_feature_names)</span>
<span id="cb76-43"><a href="#cb76-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Fitur Scores:"</span>)</span>
<span id="cb76-44"><a href="#cb76-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature_name, score <span class="kw">in</span> <span class="bu">zip</span>(best_selected_feature_names, best_feature_scores):</span>
<span id="cb76-45"><a href="#cb76-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb76-46"><a href="#cb76-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-47"><a href="#cb76-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan nama fitur terpilih</span></span>
<span id="cb76-48"><a href="#cb76-48" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_selected_feature_names, <span class="st">'fiturrandomforest.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah Fitur : 18
Best Fitur Random Forest: Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'bacteria', 'viruses', 'nitrates', 'nitrites',
       'mercury', 'perchlorate', 'radium', 'selenium', 'silver', 'uranium'],
      dtype='object')

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
bacteria: 2.422481294450292
viruses: 4.429129304026364
nitrates: 173.48651984813026
nitrites: 0.020259579232659978
mercury: 87.74346761883795
perchlorate: 78.22425346978895
radium: 33.07324163404674
selenium: 94.43379608807072
silver: 92.15581382719945
uranium: 14.847178481026724</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>['fiturrandomforest.pkl']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca DataFrame</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_balancing.csv'</span>)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Memuat list fitur yang akan di-drop dari file pickle</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>RandomForest_drop <span class="op">=</span> joblib.load(<span class="st">'fiturrandomforest.pkl'</span>)</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghilangkan 'is_safe' dari setiap nama fitur</span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>RandomForest_drop <span class="op">=</span> [feature.replace(<span class="st">'is_safe'</span>, <span class="st">''</span>) <span class="cf">for</span> feature <span class="kw">in</span> RandomForest_drop]</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Memilih hanya kolom yang ada di pickle</span></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>data_RandomForest_drop <span class="op">=</span> df[RandomForest_drop <span class="op">+</span> [<span class="st">'is_safe'</span>]]</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan DataFrame setelah fitur di-drop</span></span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>data_RandomForest_drop.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">viruses</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.20</td>
<td>0.000</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.65</td>
<td>0.650</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.05</td>
<td>0.003</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>0.71</td>
<td>0.710</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.13</td>
<td>0.001</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="decision-tree-clasifier-1" class="level3" data-number="3.7.4">
<h3 data-number="3.7.4" class="anchored" data-anchor-id="decision-tree-clasifier-1"><span class="header-section-number">3.7.4</span> Decision Tree Clasifier</h3>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>best_selected_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>best_feature_scores <span class="op">=</span> <span class="va">None</span></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>], <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menghitung nilai korelasi antara setiap fitur dengan target</span></span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>    k_best_selector <span class="op">=</span> SelectKBest(f_classif, k<span class="op">=</span>k)</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>    X_train_selected <span class="op">=</span> k_best_selector.fit_transform(X_train, y_train)</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>    X_test_selected <span class="op">=</span> k_best_selector.transform(X_test)</span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mendapatkan nama fitur terpilih</span></span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>    selected_feature_names <span class="op">=</span> X_ros.columns[k_best_selector.get_support(indices<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membuat model Decision Tree</span></span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a>    dt_model <span class="op">=</span> DecisionTreeClassifier()  <span class="co"># Ganti dengan parameter yang sesuai</span></span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a>    dt_model.fit(X_train_selected, y_train)</span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a>    y_pred_dt <span class="op">=</span> dt_model.predict(X_test_selected)</span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mengukur akurasi model Decision Tree</span></span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a>    accuracy_dt <span class="op">=</span> accuracy_score(y_test, y_pred_dt)</span>
<span id="cb80-28"><a href="#cb80-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-29"><a href="#cb80-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membandingkan dengan akurasi terbaik sejauh ini</span></span>
<span id="cb80-30"><a href="#cb80-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> accuracy_dt <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb80-31"><a href="#cb80-31" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> accuracy_dt</span>
<span id="cb80-32"><a href="#cb80-32" aria-hidden="true" tabindex="-1"></a>        best_k <span class="op">=</span> k</span>
<span id="cb80-33"><a href="#cb80-33" aria-hidden="true" tabindex="-1"></a>        best_selected_feature_names <span class="op">=</span> selected_feature_names</span>
<span id="cb80-34"><a href="#cb80-34" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> dt_model</span>
<span id="cb80-35"><a href="#cb80-35" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> k_best_selector</span>
<span id="cb80-36"><a href="#cb80-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-37"><a href="#cb80-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Menyimpan skor korelasi untuk fitur terpilih</span></span>
<span id="cb80-38"><a href="#cb80-38" aria-hidden="true" tabindex="-1"></a>        best_feature_scores <span class="op">=</span> k_best_selector.scores_</span>
<span id="cb80-39"><a href="#cb80-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-40"><a href="#cb80-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil terbaik</span></span>
<span id="cb80-41"><a href="#cb80-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah Fitur :"</span>, best_k)</span>
<span id="cb80-42"><a href="#cb80-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Fitur Decision Tree:"</span>, best_selected_feature_names)</span>
<span id="cb80-43"><a href="#cb80-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Fitur Scores:"</span>)</span>
<span id="cb80-44"><a href="#cb80-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature_name, score <span class="kw">in</span> <span class="bu">zip</span>(best_selected_feature_names, best_feature_scores):</span>
<span id="cb80-45"><a href="#cb80-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb80-46"><a href="#cb80-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-47"><a href="#cb80-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan nama fitur terpilih</span></span>
<span id="cb80-48"><a href="#cb80-48" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_selected_feature_names, <span class="st">'fiturdecisiontree.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah Fitur : 20
Best Fitur Decision Tree: Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',
       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',
       'silver', 'uranium'],
      dtype='object')

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>['fiturdecisiontree.pkl']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>best_selected_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>best_feature_scores <span class="op">=</span> <span class="va">None</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>], <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menghitung nilai korelasi antara setiap fitur dengan target</span></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>    k_best_selector <span class="op">=</span> SelectKBest(f_classif, k<span class="op">=</span>k)</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>    X_train_selected <span class="op">=</span> k_best_selector.fit_transform(X_train, y_train)</span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>    X_test_selected <span class="op">=</span> k_best_selector.transform(X_test)</span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mendapatkan nama fitur terpilih</span></span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a>    selected_feature_names <span class="op">=</span> X_ros.columns[k_best_selector.get_support(indices<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membuat model Random Forest</span></span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a>    dt_model <span class="op">=</span> dt</span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a>    dt_model.fit(X_train_selected, y_train)</span>
<span id="cb83-22"><a href="#cb83-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-23"><a href="#cb83-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb83-24"><a href="#cb83-24" aria-hidden="true" tabindex="-1"></a>    y_pred_dt <span class="op">=</span> dt_model.predict(X_test_selected)</span>
<span id="cb83-25"><a href="#cb83-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-26"><a href="#cb83-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mengukur akurasi model Random Forest</span></span>
<span id="cb83-27"><a href="#cb83-27" aria-hidden="true" tabindex="-1"></a>    accuracy_dt <span class="op">=</span> accuracy_score(y_test, y_pred_dt)</span>
<span id="cb83-28"><a href="#cb83-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-29"><a href="#cb83-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membandingkan dengan akurasi terbaik sejauh ini</span></span>
<span id="cb83-30"><a href="#cb83-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> accuracy_dt <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb83-31"><a href="#cb83-31" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> accuracy_dt</span>
<span id="cb83-32"><a href="#cb83-32" aria-hidden="true" tabindex="-1"></a>        best_k <span class="op">=</span> k</span>
<span id="cb83-33"><a href="#cb83-33" aria-hidden="true" tabindex="-1"></a>        best_selected_feature_names <span class="op">=</span> selected_feature_names</span>
<span id="cb83-34"><a href="#cb83-34" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> dt_model</span>
<span id="cb83-35"><a href="#cb83-35" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> k_best_selector</span>
<span id="cb83-36"><a href="#cb83-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-37"><a href="#cb83-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Menyimpan skor korelasi untuk fitur terpilih</span></span>
<span id="cb83-38"><a href="#cb83-38" aria-hidden="true" tabindex="-1"></a>        best_feature_scores <span class="op">=</span> k_best_selector.scores_</span>
<span id="cb83-39"><a href="#cb83-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-40"><a href="#cb83-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil terbaik</span></span>
<span id="cb83-41"><a href="#cb83-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah Fitur :"</span>, best_k)</span>
<span id="cb83-42"><a href="#cb83-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Fitur Decision Tree:"</span>, best_selected_feature_names)</span>
<span id="cb83-43"><a href="#cb83-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Fitur Scores:"</span>)</span>
<span id="cb83-44"><a href="#cb83-44" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature_name, score <span class="kw">in</span> <span class="bu">zip</span>(best_selected_feature_names, best_feature_scores):</span>
<span id="cb83-45"><a href="#cb83-45" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb83-46"><a href="#cb83-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-47"><a href="#cb83-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan nama fitur terpilih</span></span>
<span id="cb83-48"><a href="#cb83-48" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_selected_feature_names, <span class="st">'fiturdecisiontree.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah Fitur : 20
Best Fitur Decision Tree: Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',
       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',
       'silver', 'uranium'],
      dtype='object')

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>['fiturdecisiontree.pkl']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca DataFrame</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_balancing.csv'</span>)</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Memuat list fitur yang akan di-drop dari file pickle</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>DecisionTree_drop <span class="op">=</span> joblib.load(<span class="st">'fiturdecisiontree.pkl'</span>)</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghilangkan 'is_safe' dari setiap nama fitur</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>DecisionTree_drop <span class="op">=</span> [feature.replace(<span class="st">'is_safe'</span>, <span class="st">''</span>) <span class="cf">for</span> feature <span class="kw">in</span> DecisionTree_drop]</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Memilih hanya kolom yang ada di pickle</span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>data_DecisionTree_drop <span class="op">=</span> df[DecisionTree_drop <span class="op">+</span> [<span class="st">'is_safe'</span>]]</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan DataFrame setelah fitur di-drop</span></span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>data_DecisionTree_drop.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>5 rows × 21 columns</p>
</div>
</div>
</div>
</section>
<section id="ada-boost-classifier-1" class="level3" data-number="3.7.5">
<h3 data-number="3.7.5" class="anchored" data-anchor-id="ada-boost-classifier-1"><span class="header-section-number">3.7.5</span> Ada Boost Classifier</h3>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SelectKBest, f_classif</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostClassifier</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> joblib</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>best_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>best_k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>best_selected_feature_names <span class="op">=</span> <span class="va">None</span></span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>best_feature_scores <span class="op">=</span> <span class="va">None</span></span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="va">None</span></span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(X_train.shape[<span class="dv">1</span>], <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menghitung nilai korelasi antara setiap fitur dengan target</span></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>    k_best_selector <span class="op">=</span> SelectKBest(f_classif, k<span class="op">=</span>k)</span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>    X_train_selected <span class="op">=</span> k_best_selector.fit_transform(X_train, y_train)</span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>    X_test_selected <span class="op">=</span> k_best_selector.transform(X_test)</span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-19"><a href="#cb87-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mendapatkan nama fitur terpilih</span></span>
<span id="cb87-20"><a href="#cb87-20" aria-hidden="true" tabindex="-1"></a>    selected_feature_names <span class="op">=</span> X_ros.columns[k_best_selector.get_support(indices<span class="op">=</span><span class="va">True</span>)]</span>
<span id="cb87-21"><a href="#cb87-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-22"><a href="#cb87-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membuat model Adaboost</span></span>
<span id="cb87-23"><a href="#cb87-23" aria-hidden="true" tabindex="-1"></a>    adaboost_model <span class="op">=</span> AdaBoostClassifier(n_estimators<span class="op">=</span><span class="dv">50</span>, random_state<span class="op">=</span><span class="dv">42</span>)  <span class="co"># Ganti dengan parameter yang sesuai</span></span>
<span id="cb87-24"><a href="#cb87-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-25"><a href="#cb87-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melatih model menggunakan data training yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb87-26"><a href="#cb87-26" aria-hidden="true" tabindex="-1"></a>    adaboost_model.fit(X_train_selected, y_train)</span>
<span id="cb87-27"><a href="#cb87-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-28"><a href="#cb87-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Melakukan prediksi pada data testing yang telah dinormalisasi dan terpilih fiturnya</span></span>
<span id="cb87-29"><a href="#cb87-29" aria-hidden="true" tabindex="-1"></a>    y_pred_adaboost <span class="op">=</span> adaboost_model.predict(X_test_selected)</span>
<span id="cb87-30"><a href="#cb87-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-31"><a href="#cb87-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mengukur akurasi model Adaboost</span></span>
<span id="cb87-32"><a href="#cb87-32" aria-hidden="true" tabindex="-1"></a>    accuracy_adaboost <span class="op">=</span> accuracy_score(y_test, y_pred_adaboost)</span>
<span id="cb87-33"><a href="#cb87-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-34"><a href="#cb87-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Menyimpan skor korelasi untuk fitur terpilih</span></span>
<span id="cb87-35"><a href="#cb87-35" aria-hidden="true" tabindex="-1"></a>    feature_scores <span class="op">=</span> k_best_selector.scores_</span>
<span id="cb87-36"><a href="#cb87-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-37"><a href="#cb87-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Membandingkan dengan akurasi terbaik sejauh ini</span></span>
<span id="cb87-38"><a href="#cb87-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> accuracy_adaboost <span class="op">&gt;</span> best_accuracy:</span>
<span id="cb87-39"><a href="#cb87-39" aria-hidden="true" tabindex="-1"></a>        best_accuracy <span class="op">=</span> accuracy_adaboost</span>
<span id="cb87-40"><a href="#cb87-40" aria-hidden="true" tabindex="-1"></a>        best_k <span class="op">=</span> k</span>
<span id="cb87-41"><a href="#cb87-41" aria-hidden="true" tabindex="-1"></a>        best_selected_feature_names <span class="op">=</span> selected_feature_names</span>
<span id="cb87-42"><a href="#cb87-42" aria-hidden="true" tabindex="-1"></a>        best_feature_scores <span class="op">=</span> feature_scores</span>
<span id="cb87-43"><a href="#cb87-43" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> adaboost_model</span>
<span id="cb87-44"><a href="#cb87-44" aria-hidden="true" tabindex="-1"></a>        scaler <span class="op">=</span> k_best_selector</span>
<span id="cb87-45"><a href="#cb87-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-46"><a href="#cb87-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan hasil terbaik</span></span>
<span id="cb87-47"><a href="#cb87-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Jumlah Fitur :"</span>, best_k)</span>
<span id="cb87-48"><a href="#cb87-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Fitur Adaboost:"</span>, best_selected_feature_names)</span>
<span id="cb87-49"><a href="#cb87-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Fitur Scores:"</span>)</span>
<span id="cb87-50"><a href="#cb87-50" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> feature_name, score <span class="kw">in</span> <span class="bu">zip</span>(best_selected_feature_names, best_feature_scores):</span>
<span id="cb87-51"><a href="#cb87-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>feature_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb87-52"><a href="#cb87-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-53"><a href="#cb87-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Menyimpan nama fitur terpilih</span></span>
<span id="cb87-54"><a href="#cb87-54" aria-hidden="true" tabindex="-1"></a>joblib.dump(best_selected_feature_names, <span class="st">'fituradaboost.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Jumlah Fitur : 20
Best Fitur Adaboost: Index(['aluminium', 'ammonia', 'arsenic', 'barium', 'cadmium', 'chloramine',
       'chromium', 'copper', 'flouride', 'bacteria', 'viruses', 'lead',
       'nitrates', 'nitrites', 'mercury', 'perchlorate', 'radium', 'selenium',
       'silver', 'uranium'],
      dtype='object')

Best Fitur Scores:
aluminium: 1768.3190428266103
ammonia: 24.082352474449795
arsenic: 609.9877500155244
barium: 122.3111242384997
cadmium: 1961.2468311627367
chloramine: 705.6421255995247
chromium: 609.1375894392714
copper: 28.20858760070382
flouride: 2.422481294450292
bacteria: 4.429129304026364
viruses: 173.48651984813026
lead: 0.020259579232659978
nitrates: 87.74346761883795
nitrites: 78.22425346978895
mercury: 33.07324163404674
perchlorate: 94.43379608807072
radium: 92.15581382719945
selenium: 14.847178481026724
silver: 161.19923638886357
uranium: 153.99965019028522</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>['fituradaboost.pkl']</code></pre>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Membaca DataFrame</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'data_balancing.csv'</span>)</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Memuat list fitur yang akan di-drop dari file pickle</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>Adaboost_drop <span class="op">=</span> joblib.load(<span class="st">'fituradaboost.pkl'</span>)</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Menghilangkan 'is_safe' dari setiap nama fitur</span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>Adaboost_drop <span class="op">=</span> [feature.replace(<span class="st">'is_safe'</span>, <span class="st">''</span>) <span class="cf">for</span> feature <span class="kw">in</span> Adaboost_drop]</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Memilih hanya kolom yang ada di pickle</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>data_Adaboost_drop <span class="op">=</span> df[Adaboost_drop <span class="op">+</span> [<span class="st">'is_safe'</span>]]</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Menampilkan DataFrame setelah fitur di-drop</span></span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>data_Adaboost_drop.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">aluminium</th>
<th data-quarto-table-cell-role="th">ammonia</th>
<th data-quarto-table-cell-role="th">arsenic</th>
<th data-quarto-table-cell-role="th">barium</th>
<th data-quarto-table-cell-role="th">cadmium</th>
<th data-quarto-table-cell-role="th">chloramine</th>
<th data-quarto-table-cell-role="th">chromium</th>
<th data-quarto-table-cell-role="th">copper</th>
<th data-quarto-table-cell-role="th">flouride</th>
<th data-quarto-table-cell-role="th">bacteria</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">lead</th>
<th data-quarto-table-cell-role="th">nitrates</th>
<th data-quarto-table-cell-role="th">nitrites</th>
<th data-quarto-table-cell-role="th">mercury</th>
<th data-quarto-table-cell-role="th">perchlorate</th>
<th data-quarto-table-cell-role="th">radium</th>
<th data-quarto-table-cell-role="th">selenium</th>
<th data-quarto-table-cell-role="th">silver</th>
<th data-quarto-table-cell-role="th">uranium</th>
<th data-quarto-table-cell-role="th">is_safe</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.65</td>
<td>9.08</td>
<td>0.04</td>
<td>2.85</td>
<td>0.007</td>
<td>0.35</td>
<td>0.83</td>
<td>0.17</td>
<td>0.05</td>
<td>0.20</td>
<td>...</td>
<td>0.054</td>
<td>16.08</td>
<td>1.13</td>
<td>0.007</td>
<td>37.75</td>
<td>6.78</td>
<td>0.08</td>
<td>0.34</td>
<td>0.02</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.32</td>
<td>21.16</td>
<td>0.01</td>
<td>3.31</td>
<td>0.002</td>
<td>5.28</td>
<td>0.68</td>
<td>0.66</td>
<td>0.90</td>
<td>0.65</td>
<td>...</td>
<td>0.100</td>
<td>2.01</td>
<td>1.93</td>
<td>0.003</td>
<td>32.26</td>
<td>3.21</td>
<td>0.08</td>
<td>0.27</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.01</td>
<td>14.02</td>
<td>0.04</td>
<td>0.58</td>
<td>0.008</td>
<td>4.24</td>
<td>0.53</td>
<td>0.02</td>
<td>0.99</td>
<td>0.05</td>
<td>...</td>
<td>0.078</td>
<td>14.16</td>
<td>1.11</td>
<td>0.006</td>
<td>50.28</td>
<td>7.07</td>
<td>0.07</td>
<td>0.44</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.36</td>
<td>11.33</td>
<td>0.04</td>
<td>2.96</td>
<td>0.001</td>
<td>7.23</td>
<td>0.03</td>
<td>1.66</td>
<td>1.08</td>
<td>0.71</td>
<td>...</td>
<td>0.016</td>
<td>1.41</td>
<td>1.29</td>
<td>0.004</td>
<td>9.12</td>
<td>1.72</td>
<td>0.02</td>
<td>0.45</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.92</td>
<td>24.33</td>
<td>0.03</td>
<td>0.20</td>
<td>0.006</td>
<td>2.67</td>
<td>0.69</td>
<td>0.57</td>
<td>0.61</td>
<td>0.13</td>
<td>...</td>
<td>0.117</td>
<td>6.74</td>
<td>1.11</td>
<td>0.003</td>
<td>16.90</td>
<td>2.41</td>
<td>0.02</td>
<td>0.06</td>
<td>0.02</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>5 rows × 21 columns</p>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="modeling" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Modeling</h1>
<section id="light-gradient-boosting-machine-1" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="light-gradient-boosting-machine-1"><span class="header-section-number">4.1</span> Light Gradient Boosting Machine</h2>
<p>Metode Light Gradient Boosting Machine (LightGBM) merupakan salah satu algoritma machine learning yang termasuk dalam kategori ensemble learning, khususnya dalam keluarga algoritma gradient boosting. LightGBM dikembangkan oleh Microsoft dan dirancang untuk memberikan kinerja yang cepat dan efisien, terutama pada dataset yang besar.</p>
<p>Berikut adalah beberapa karakteristik utama dari LightGBM:</p>
<ol type="1">
<li>Gradient Boosting Framework, jadi LightGBM merupakan implementasi dari algoritma gradient boosting, yang berfokus pada membangun model prediktif dengan cara menggabungkan beberapa model lemah (weak learners) menjadi satu model yang kuat. Proses ini dilakukan secara iteratif, dengan setiap iterasi bertujuan untuk memperbaiki kesalahan prediksi yang dibuat oleh model sebelumnya.</li>
<li>Leaf-wise Growth Strategy, Salah satu fitur utama dari LightGBM adalah strategi pertumbuhan pohon secara daun (leaf-wise). Berbeda dengan pendekatan level-wise pada algoritma gradient boosting lainnya, LightGBM membangun pohon dengan mengekspansi daun yang memberikan kontribusi terbesar pada penurunan kesalahan (loss). Strategi ini membantu meningkatkan efisiensi karena hanya daun yang signifikan yang diperluas.</li>
<li>Histogram-Based Learning, LightGBM menggunakan histogram untuk memproses data pada setiap iterasi pembelajaran. Histogram adalah representasi diskrit dari distribusi data, yang membantu mengurangi waktu komputasi. Proses pembelajaran pada LightGBM membagi dataset ke dalam beberapa bucket histogram, dan kemudian menghitung statistik di setiap bucket untuk mempercepat pembelajaran.</li>
<li>Categorical Feature Support, LightGBM memiliki dukungan khusus untuk fitur kategorikal tanpa perlu melakukan pre-processing one-hot encoding. Ini membuatnya lebih efisien untuk menangani dataset dengan fitur kategorikal.</li>
<li>Distributed Training, LightGBM mendukung pelatihan terdistribusi, yang memungkinkan pengguna melatih model pada dataset yang sangat besar dengan menggunakan beberapa sumber daya komputasi secara bersamaan.</li>
<li>Regularization,LightGBM menyediakan opsi untuk menerapkan regularisasi pada pohon untuk mencegah overfitting. Regularisasi dapat diatur menggunakan parameter seperti lambda dan alpha.</li>
<li>Kecepatan dan Skalabilitas, Salah satu keunggulan utama LightGBM adalah kecepatan eksekusinya yang tinggi dan skalabilitasnya terhadap ukuran dataset. Hal ini membuatnya menjadi pilihan populer untuk tugas-tugas yang melibatkan data besar.</li>
</ol>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_LightGradientBoostingMachine_drop.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_LightGradientBoostingMachine_drop[<span class="st">'is_safe'</span>]</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>X_train_lgbm, X_test_lgbm, y_train_lgbm, y_test_lgbm <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>RobustScaler <span class="op">=</span> RobustScaler()</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>X_train_lightgbm <span class="op">=</span> RobustScaler.fit_transform(X_train_lgbm)</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>X_test_lightgbm <span class="op">=</span> RobustScaler.transform(X_test_lgbm)</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>lightgbm_model <span class="op">=</span> lightgbm</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>lightgbm_model.fit(X_train_lightgbm, y_train_lgbm)</span>
<span id="cb91-13"><a href="#cb91-13" aria-hidden="true" tabindex="-1"></a>y_pred_lightgbm <span class="op">=</span> lightgbm_model.predict(X_test_lightgbm)</span>
<span id="cb91-14"><a href="#cb91-14" aria-hidden="true" tabindex="-1"></a>accuracy_lightgbm <span class="op">=</span> accuracy_score(y_test_lgbm, y_pred_lightgbm)</span>
<span id="cb91-15"><a href="#cb91-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Accuracy metode Light Gradient Boosting Machine :"</span>,accuracy_lightgbm<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb91-16"><a href="#cb91-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-17"><a href="#cb91-17" aria-hidden="true" tabindex="-1"></a>joblib.dump(RobustScaler, <span class="st">'saclelightgbm.pkl'</span>)</span>
<span id="cb91-18"><a href="#cb91-18" aria-hidden="true" tabindex="-1"></a>joblib.dump(lightgbm_model, <span class="st">'modellightgbm.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Info] Number of positive: 4180, number of negative: 4197
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003947 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 3018
[LightGBM] [Info] Number of data points in the train set: 8377, number of used features: 20
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498985 -&gt; initscore=-0.004059
[LightGBM] [Info] Start training from score -0.004059

Accuracy metode Light Gradient Boosting Machine : 98.37708830548925</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>['modellightgbm.pkl']</code></pre>
</div>
</div>
</section>
<section id="gradient-boosting-classifier-1" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="gradient-boosting-classifier-1"><span class="header-section-number">4.2</span> Gradient Boosting Classifier</h2>
<p>Metode Gradient Boosting adalah salah satu pendekatan dalam machine learning yang termasuk dalam kategori ensemble learning. Ensemble learning melibatkan penggabungan beberapa model lemah (weak learners) untuk membentuk model yang lebih kuat. Gradient Boosting secara khusus fokus pada pengurangan kesalahan prediksi dengan memperhatikan kesalahan model sebelumnya.</p>
<p>Berikut adalah konsep dasar dari metode Gradient Boosting:</p>
<ol type="1">
<li>Weak learners adalah model prediktif yang memiliki performa yang sedikit di atas random chance. Contohnya termasuk decision trees dengan kedalaman yang sangat terbatas (stump) atau regresi linear sederhana. Dalam konteks Gradient Boosting, sejumlah besar weak learners akan digabungkan untuk membentuk model yang kuat. Sequential Model Building:</li>
<li>Proses Gradient Boosting melibatkan pembangunan model secara iteratif. Pada setiap iterasi, model baru ditambahkan untuk mengkompensasi kesalahan prediksi yang belum ditangani oleh model sebelumnya. Model yang baru ditambahkan harus “mengajar” untuk kesalahan yang ada. Ini dilakukan dengan meminimalkan residual error (selisih antara prediksi aktual dan prediksi model sebelumnya) menggunakan weak learner.</li>
<li>Loss function (fungsi kerugian) digunakan untuk mengukur sejauh mana model saat ini memberikan prediksi yang benar atau mendekati target aktual. Pada setiap iterasi, model berusaha meminimalkan nilai loss function. Contoh loss function untuk regresi adalah Mean Squared Error (MSE), sementara untuk klasifikasi bisa menggunakan log-likelihood atau Gini Index.</li>
<li>Gradient descent digunakan untuk menemukan parameter model yang meminimalkan loss function. Pada setiap iterasi, model baru ditambahkan dengan menyesuaikan parameter (misalnya, bobot pohon pada decision tree) dalam arah yang berlawanan dengan gradien loss function. Proses ini memungkinkan model untuk fokus pada bagian dataset yang sulit diprediksi oleh model sebelumnya.</li>
<li>Shrinkage adalah parameter yang mengontrol seberapa besar kita akan “mempelajari” dari setiap model tambahan. Nilai shrinkage yang lebih rendah memerlukan lebih banyak iterasi untuk mencapai kinerja yang baik, tetapi dapat meningkatkan kestabilan model.</li>
<li>Beberapa implementasi Gradient Boosting, seperti XGBoost atau LightGBM, memiliki opsi untuk menerapkan teknik regularisasi untuk mencegah overfitting. Regularisasi dapat diatur dengan menggunakan parameter tertentu, seperti lambda dan alpha.</li>
<li>Gradient Boosting mirip dengan metode AdaBoost, tetapi ada perbedaan kunci. Jika AdaBoost memberikan “perhatian lebih” pada contoh yang salah diprediksi sebelumnya, Gradient Boosting fokus pada residual errors atau gradien loss function.</li>
</ol>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_GradientBoostingClasifier_drop.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_GradientBoostingClasifier_drop[<span class="st">'is_safe'</span>]</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>X_train_gbc, X_test_gbc, y_train_gbc, y_test_gbc <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>RobustScaler <span class="op">=</span> RobustScaler()</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>X_train_GradientBoosting <span class="op">=</span> RobustScaler.fit_transform(X_train_gbc)</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>X_test_GradientBoosting <span class="op">=</span> RobustScaler.transform(X_test_gbc)</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>gbc_model <span class="op">=</span> gbc</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>gbc_model.fit(X_train_GradientBoosting, y_train_gbc)</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>y_pred_gbc <span class="op">=</span> gbc_model.predict(X_test_GradientBoosting)</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>accuracy_gbc <span class="op">=</span> accuracy_score(y_test_gbc, y_pred_gbc)</span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy metode Gradient Boosting Clasifier :"</span>,accuracy_gbc<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a>joblib.dump(RobustScaler, <span class="st">'saclergbc.pkl'</span>)</span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a>joblib.dump(gbc_model, <span class="st">'modelgbc.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy metode Gradient Boosting Clasifier : 95.13126491646779</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>['modelgbc.pkl']</code></pre>
</div>
</div>
</section>
<section id="random-forest-1" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="random-forest-1"><span class="header-section-number">4.3</span> Random Forest</h2>
<p>Random Forest adalah sebuah metode ensemble learning yang digunakan dalam pemodelan prediktif dan klasifikasi. Ensemble learning melibatkan penggabungan hasil dari beberapa model untuk meningkatkan kinerja dan akurasi keseluruhan. Random Forest khususnya menggunakan pohon keputusan sebagai model dasar dan menggabungkan prediksi dari beberapa pohon keputusan untuk membuat keputusan akhir.</p>
<p>Random Forest efektif untuk berbagai jenis tugas seperti klasifikasi dan regresi, dan sering digunakan karena kemampuannya yang baik dalam menangani data yang kompleks dan beragam. Keunggulan utamanya termasuk kemampuan untuk mengatasi overfitting, memberikan nilai penting untuk fitur, dan memberikan performa yang baik secara umum.</p>
<p>Berikut adalah contoh sederhana bagaimana kita bisa menghitung prediksi menggunakan Random Forest dengan tiga pohon:</p>
<p>Misalkan kita memiliki tiga pohon keputusan yang masing-masing memberikan prediksi sebagai berikut untuk suatu titik data:</p>
<table class="table">
<thead>
<tr class="header">
<th>Pohon</th>
<th>Prediksi</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>A</td>
</tr>
<tr class="even">
<td>2</td>
<td>B</td>
</tr>
<tr class="odd">
<td>3</td>
<td>A</td>
</tr>
</tbody>
</table>
<p>Dalam hal ini, Random Forest akan memberikan prediksi akhir “Kelas A” karena ini adalah kelas yang paling sering diprediksi oleh pohon-pohon dalam hutan.</p>
<ul>
<li><b>Contoh Penerapan</b></li>
</ul>
<p>Misalkan kita memiliki data kategori obesitas dengan fitur seperti Usia, Tinggi (TB), dan Berat Badan (BB), dan target kita adalah kategori obesitas. Kita bisa menggunakan Random Forest untuk memprediksi jumlah unit yang akan diproduksi berdasarkan fitur-fitur tersebut.</p>
<p><b>1. Persiapan Data</b></p>
<table class="table">
<thead>
<tr class="header">
<th>Usia</th>
<th>Tinggi Badan</th>
<th>Berat Badan</th>
<th>Target Kategori</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>25</td>
<td>170</td>
<td>70</td>
<td>Normal</td>
</tr>
<tr class="even">
<td>30</td>
<td>170</td>
<td>60</td>
<td>Normal</td>
</tr>
<tr class="odd">
<td>35</td>
<td>180</td>
<td>80</td>
<td>Obesitas</td>
</tr>
</tbody>
</table>
<p><b>2. Pelatihan Model</b></p>
<p>Kedua, kita melatih model Random Forest menggunakan data historis tersebut. Model akan mempelajari hubungan kompleks antara “Usia”, “Tinggi Badan”, “Berat Badan”, dan target “Kategori Obesitas”.</p>
<p><b>3. Penggunaan Model Untuk Prediksi</b></p>
<p>Setelah melatih model, kita dapat menggunakannya untuk memprediksi kategori obesitas berdasarkan fitur-fitur baru. Misalkan kita memiliki data baru seperti berikut:</p>
<table class="table">
<thead>
<tr class="header">
<th>Usia</th>
<th>Tinggi Badan</th>
<th>Berat Badan</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>28</td>
<td>175</td>
<td>75</td>
</tr>
</tbody>
</table>
<p><b>4. Hasil Prediksi</b> Model kita kemudian memberikan prediksi kategori obesitas berikut:</p>
<table class="table">
<thead>
<tr class="header">
<th>Usia</th>
<th>Tinggi Badan</th>
<th>Berat Badan</th>
<th>Target Kategori</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>28</td>
<td>175</td>
<td>75</td>
<td>Obesitas</td>
</tr>
</tbody>
</table>
<p>Dalam contoh ini, model Random Forest memprediksi bahwa dengan usia 28 tahun, tinggi badan 175 cm, dan berat badan 75 kg, seseorang termasuk dalam kategori “Obesitas”.</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_RandomForest_drop.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_RandomForest_drop[<span class="st">'is_safe'</span>]</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>X_train_rf, X_test_rf, y_train_rf, y_test_rf <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>RobustScaler <span class="op">=</span> RobustScaler()</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>X_train_RandomForest <span class="op">=</span> RobustScaler.fit_transform(X_train_rf)</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>X_test_RandomForest <span class="op">=</span> RobustScaler.transform(X_test_rf)</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> rf</span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train_RandomForest, y_train_rf)</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> rf_model.predict(X_test_RandomForest)</span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>accuracy_rf <span class="op">=</span> accuracy_score(y_test_rf, y_pred_rf)</span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy metode Random Forest :"</span>,accuracy_rf<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb97-16"><a href="#cb97-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-17"><a href="#cb97-17" aria-hidden="true" tabindex="-1"></a>joblib.dump(RobustScaler, <span class="st">'saclerrandomforest.pkl'</span>)</span>
<span id="cb97-18"><a href="#cb97-18" aria-hidden="true" tabindex="-1"></a>joblib.dump(rf_model, <span class="st">'modelrandomforest.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy metode Random Forest : 98.71121718377088</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>['modelrandomforest.pkl']</code></pre>
</div>
</div>
</section>
<section id="decision-tree-clasifier-2" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="decision-tree-clasifier-2"><span class="header-section-number">4.4</span> Decision Tree Clasifier</h2>
<p>Decision Tree, atau pohon keputusan, adalah salah satu algoritma pembelajaran mesin yang dapat digunakan untuk tugas klasifikasi dan regresi. Algoritma ini membangun struktur pohon di mana setiap simpul (node) mewakili keputusan berdasarkan fitur-fitur data. Pada setiap simpul, algoritma membuat keputusan berdasarkan fitur tertentu, sehingga memungkinkan pemisahan data menjadi kelompok yang semakin homogen.</p>
<p>Keunggulan Decision Tree: 1. Interpretabilitas: Pohon keputusan dapat dengan mudah diinterpretasikan oleh manusia karena strukturnya mirip dengan keputusan yang diambil berdasarkan aturan sederhana.</p>
<ol start="2" type="1">
<li><p>Penanganan Fitur Non-Lineer: Decision Tree dapat menangani hubungan non-linear antara fitur dan target.</p></li>
<li><p>Skalabilitas: Cocok untuk dataset dengan banyak fitur dan data yang cukup besar.</p></li>
</ol>
<ul>
<li>Contoh Penerapan:</li>
</ul>
<ol type="1">
<li>Persiapan Data Misalkan kita memiliki data mengenai konsumen yang ingin kita kelompokkan berdasarkan keputusan pembelian suatu produk. Data tersebut mungkin terlihat seperti ini:</li>
</ol>
<table class="table">
<thead>
<tr class="header">
<th>Umur</th>
<th>Pendapatan</th>
<th>Pendidikan</th>
<th>Keputusan Pembelian</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>25</td>
<td>50000</td>
<td>Sarjana</td>
<td>Ya</td>
</tr>
<tr class="even">
<td>35</td>
<td>75000</td>
<td>Master</td>
<td>Tidak</td>
</tr>
<tr class="odd">
<td>45</td>
<td>100000</td>
<td>Doktor</td>
<td>Ya</td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li><p>Pelatihan Model Selanjutnya, kita melatih model Decision Tree menggunakan data historis tersebut. Model akan mempelajari aturan-aturan keputusan berdasarkan fitur-fitur seperti “Umur”, “Pendapatan”, dan “Pendidikan”.</p></li>
<li><p>Penggunaan Model Untuk Prediksi Setelah pelatihan, kita dapat menggunakan model untuk memprediksi keputusan pembelian konsumen baru. Misalkan kita memiliki data baru:</p></li>
</ol>
<table class="table">
<thead>
<tr class="header">
<th>Umur</th>
<th>Pendapatan</th>
<th>Pendidikan</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>30</td>
<td>60000</td>
<td>Diploma</td>
</tr>
</tbody>
</table>
<ol start="4" type="1">
<li>Hasil Prediksi</li>
</ol>
<p>Model Decision Tree kemudian memberikan prediksi keputusan pembelian, misalnya, “Ya” atau “Tidak”, berdasarkan aturan yang telah dipelajari dari data historis.</p>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_DecisionTree_drop.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_DecisionTree_drop[<span class="st">'is_safe'</span>]</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>X_train_dt, X_test_dt, y_train_dt, y_test_dt <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>RobustScaler <span class="op">=</span> RobustScaler()</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>X_train_DecisionTree <span class="op">=</span> RobustScaler.fit_transform(X_train_dt)</span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>X_test_DecisionTree <span class="op">=</span> RobustScaler.transform(X_test_dt)</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a>dt_model <span class="op">=</span> dt</span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a>dt_model.fit(X_train_DecisionTree, y_train_dt)</span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a>y_pred_dt <span class="op">=</span> dt_model.predict(X_test_DecisionTree)</span>
<span id="cb100-14"><a href="#cb100-14" aria-hidden="true" tabindex="-1"></a>accuracy_dt <span class="op">=</span> accuracy_score(y_test_dt, y_pred_dt)</span>
<span id="cb100-15"><a href="#cb100-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy metode Decision Tree :"</span>,accuracy_dt<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb100-16"><a href="#cb100-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-17"><a href="#cb100-17" aria-hidden="true" tabindex="-1"></a>joblib.dump(RobustScaler, <span class="st">'saclerdecisiontree.pkl'</span>)</span>
<span id="cb100-18"><a href="#cb100-18" aria-hidden="true" tabindex="-1"></a>joblib.dump(dt_model, <span class="st">'modeldecisiontree.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy metode Decision Tree : 98.18615751789976</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>['modeldecisiontree.pkl']</code></pre>
</div>
</div>
</section>
<section id="ada-boost-classifier-2" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="ada-boost-classifier-2"><span class="header-section-number">4.5</span> Ada Boost Classifier</h2>
<p>Adaboost menggabungkan hasil dari sejumlah besar weak classifiers (misalnya, pohon keputusan yang sangat sederhana) untuk membentuk model yang kuat. Setiap weak classifier diberi bobot berdasarkan seberapa baik mereka menangani sampel pada iterasi sebelumnya. Proses ini dilakukan secara iteratif, dan pada setiap iterasi, bobot baru diberikan pada sampel yang salah diprediksi pada iterasi sebelumnya.</p>
<p>Dengan kata lain, jika kita memiliki M weak classifiers, prediksi model ensemble Adaboost (( F(x) )) dapat dihitung dengan:</p>
<p><span class="math display">\[  F(x) = \sum_{m=1}^{M} \alpha_m \cdot f_m(x)  \]</span></p>
<p>di mana: - $ F(x) $ adalah prediksi model ensemble. - $ _m $ adalah bobot yang diberikan pada weak classifier ke-m. - $ f_m(x) $ adalah prediksi dari weak classifier ke-m.</p>
<p>Bobot $ _m $ dihitung berdasarkan tingkat kesalahan weak classifier pada iterasi sebelumnya. Semakin baik weak classifier menangani sampel, semakin besar bobotnya.</p>
<p>Bentuk umum ini mencerminkan kombinasi linear dari weak classifiers, dan dengan strategi ini, Adaboost dapat memperbaiki performa model terhadap sampel yang sulit diprediksi oleh model sebelumnya.</p>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> RobustScaler</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_Adaboost_drop.drop(<span class="st">'is_safe'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_Adaboost_drop[<span class="st">'is_safe'</span>]</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>X_train_ada, X_test_ada, y_train_ada, y_test_ada <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>RobustScaler <span class="op">=</span> RobustScaler()</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>X_train_adaboost <span class="op">=</span> RobustScaler.fit_transform(X_train_ada)</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>X_test_adaboost <span class="op">=</span> RobustScaler.transform(X_test_ada)</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>ada_model <span class="op">=</span> ada</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>ada_model.fit(X_train_adaboost, y_train_ada)</span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>y_pred_ada <span class="op">=</span> ada_model.predict(X_test_adaboost)</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a>accuracy_ada <span class="op">=</span> accuracy_score(y_test_ada, y_pred_ada)</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy metode Adaboost :"</span>,accuracy_ada<span class="op">*</span><span class="dv">100</span>)</span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>joblib.dump(RobustScaler, <span class="st">'sacleradaboost.pkl'</span>)</span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>joblib.dump(ada_model, <span class="st">'modeladaboost.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy metode Adaboost : 87.9236276849642</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>['modeladaboost.pkl']</code></pre>
</div>
</div>
</section>
<section id="perbandingan-metode" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="perbandingan-metode"><span class="header-section-number">4.6</span> Perbandingan Metode</h2>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>methods <span class="op">=</span> [<span class="st">'Light Gradient Boosting Machine'</span>, <span class="st">'Gradient Boosting'</span>, <span class="st">'Random Forest'</span>, <span class="st">'Decision Tree'</span>, <span class="st">'Adaboost'</span>]</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Daftar akurasi dari setiap metode</span></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>accuracies <span class="op">=</span> [accuracy_lightgbm<span class="op">*</span><span class="dv">100</span>, accuracy_gbc<span class="op">*</span><span class="dv">100</span>, accuracy_rf<span class="op">*</span><span class="dv">100</span>, accuracy_dt<span class="op">*</span><span class="dv">100</span>, accuracy_ada<span class="op">*</span><span class="dv">100</span>]</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Membuat dataframe dari data</span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'Metode'</span>: methods, <span class="st">'Akurasi (%)'</span>: accuracies}</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>dataa <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Membuat grafik bar dengan Seaborn</span></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">8</span>))</span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.barplot(x<span class="op">=</span><span class="st">'Metode'</span>, y<span class="op">=</span><span class="st">'Akurasi (%)'</span>, data<span class="op">=</span>dataa, palette<span class="op">=</span><span class="st">'pastel'</span>)</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Metode'</span>)</span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Akurasi (%)'</span>)</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Perbandingan Akurasi antara Metode'</span>)</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Menambahkan nilai-nilai akurasi di atas setiap batang</span></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index, value <span class="kw">in</span> <span class="bu">enumerate</span>(accuracies):</span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>    plt.text(index, value <span class="op">-</span> <span class="dv">50</span>, <span class="ss">f'</span><span class="sc">{</span>value<span class="sc">:.2f}</span><span class="ss">%'</span>, ha<span class="op">=</span><span class="st">'center'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb106-20"><a href="#cb106-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-21"><a href="#cb106-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-65-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="evaluasi" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Evaluasi</h1>
<p>Evaluasi dalam konteks model prediktif dan klasifikasi merujuk pada penilaian kinerja model terhadap data yang belum pernah dilihat sebelumnya atau data uji. Tujuan evaluasi adalah untuk memahami sejauh mana model dapat menggeneralis ke data baru dan seberapa baik model dapat melakukan tugasnya, seperti klasifikasi dengan akurasi tinggi atau regresi dengan presisi yang baik. Berikut adalah beberapa metrik evaluasi umum:</p>
<ol type="1">
<li><p>Akurasi (Accuracy) mengukur sejauh mana model dapat mengklasifikasikan data dengan benar. Akurasi dinyatakan sebagai persentase dari total prediksi yang benar. <span class="math display">\[\text{Accuracy} = \frac{\text{True Positive} + \text{True Negative}}{\text{Total Data}}\]</span></p></li>
<li><p>Recall (Sensitivitas atau True Positive Rate) mengukur sejauh mana model dapat mengidentifikasi semua instance yang benar positif dari kelas tertentu. Recall berguna ketika menghindari false negatives sangat penting. <span class="math display">\[\text{Recall} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}}\]</span></p></li>
<li><p>Precision mengukur sejauh mana prediksi positif model yang benar-benar benar. Precision berguna ketika menghindari false positives sangat penting. <span class="math display">\[\text{Precision} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Positive}}\]</span></p></li>
<li><p>F1 Score adalah harmonic mean dari precision dan recall. Ini memberikan keseimbangan antara precision dan recall. F1 Score tinggi menunjukkan keseimbangan yang baik antara precision dan recall. <span class="math display">\[\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}\]</span></p></li>
<li><p>Classification Report:</p>
<ul>
<li>Menyajikan statistik klasifikasi seperti precision, recall, dan f1-score untuk setiap kelas.</li>
<li>Dalam classification report, Anda akan mendapatkan informasi ini untuk setiap kelas.</li>
</ul></li>
</ol>
<section id="light-gradient-boosting-machine-2" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="light-gradient-boosting-machine-2"><span class="header-section-number">5.1</span> Light Gradient Boosting Machine</h2>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_lgbm, y_pred_lightgbm))</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_lgbm, y_pred_lightgbm)</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> np.unique(np.concatenate((y_test_lgbm, y_pred_lightgbm)))</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span>class_labels, yticklabels<span class="op">=</span>class_labels)</span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.97      0.98      1039
           1       0.97      1.00      0.98      1056

    accuracy                           0.98      2095
   macro avg       0.98      0.98      0.98      2095
weighted avg       0.98      0.98      0.98      2095
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-66-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="gradient-boosting-classifier-2" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="gradient-boosting-classifier-2"><span class="header-section-number">5.2</span> Gradient Boosting Classifier</h2>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_gbc, y_pred_gbc))</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_gbc, y_pred_gbc)</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> np.unique(np.concatenate((y_test_gbc, y_pred_gbc)))</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span>class_labels, yticklabels<span class="op">=</span>class_labels)</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.97      0.93      0.95      1039
           1       0.93      0.97      0.95      1056

    accuracy                           0.95      2095
   macro avg       0.95      0.95      0.95      2095
weighted avg       0.95      0.95      0.95      2095
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-67-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="random-forest-2" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="random-forest-2"><span class="header-section-number">5.3</span> Random Forest</h2>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_rf, y_pred_rf))</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_rf, y_pred_rf)</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> np.unique(np.concatenate((y_test_rf, y_pred_rf)))</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span>class_labels, yticklabels<span class="op">=</span>class_labels)</span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.97      0.99      1039
           1       0.98      1.00      0.99      1056

    accuracy                           0.99      2095
   macro avg       0.99      0.99      0.99      2095
weighted avg       0.99      0.99      0.99      2095
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-68-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="decision-tree-clasifier-3" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="decision-tree-clasifier-3"><span class="header-section-number">5.4</span> Decision Tree Clasifier</h2>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_dt, y_pred_dt))</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_dt, y_pred_dt)</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> np.unique(np.concatenate((y_test_dt, y_pred_dt)))</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span>class_labels, yticklabels<span class="op">=</span>class_labels)</span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       1.00      0.97      0.98      1039
           1       0.97      1.00      0.98      1056

    accuracy                           0.98      2095
   macro avg       0.98      0.98      0.98      2095
weighted avg       0.98      0.98      0.98      2095
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-69-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="ada-boost-classifier-3" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="ada-boost-classifier-3"><span class="header-section-number">5.5</span> Ada Boost Classifier</h2>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_ada, y_pred_ada))</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_test_ada, y_pred_ada)</span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a>class_labels <span class="op">=</span> np.unique(np.concatenate((y_test_ada, y_pred_ada)))</span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">"d"</span>, cmap<span class="op">=</span><span class="st">"Blues"</span>, xticklabels<span class="op">=</span>class_labels, yticklabels<span class="op">=</span>class_labels)</span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual'</span>)</span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.87      0.89      0.88      1039
           1       0.89      0.87      0.88      1056

    accuracy                           0.88      2095
   macro avg       0.88      0.88      0.88      2095
weighted avg       0.88      0.88      0.88      2095
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="PSD_Mubessirul Ummah_210411100140_Water Quality_files/figure-html/cell-70-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="deployment" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Deployment</h1>
<p>Silahkan klik <a href="https://210411100140-mubessirulummah-psd-mubessir-1-randomforest-yibzz4.streamlit.app/">Disini</a> untuk melihat deploynya.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>